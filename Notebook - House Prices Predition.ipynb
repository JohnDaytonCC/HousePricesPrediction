{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95a3847a",
   "metadata": {},
   "source": [
    "# House Prices Predition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dba24e",
   "metadata": {},
   "source": [
    "Este Notebook será utilizado para a elaboração de modelos matemáticos, baseado em regressão linear, para a predição de valores de casas à partir de um conjunto de variáveis (features)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05386d58",
   "metadata": {},
   "source": [
    "# Bibliotecas Necessárias para o desenvolvimento do modelo.\n",
    "\n",
    "Serão carregadas as principais bibliotecas para a construção do modelo de Regressão Linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b06c3444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas e módulos utilizados no caderno.\n",
    "import numpy as np                                  # Pacote para Computação Científica (Manipulação de matrizes)\n",
    "import pandas as pd                                 # Pacote para auxílio em Análise de Dados\n",
    "import statistics as sts\n",
    "import statsmodels.api as sm                        # Pacote para manipulação de operações estatísticas\n",
    "import matplotlib.pyplot as plt                     # Biblioteca para criação de gráficos e visualizações de dados em geral.\n",
    "from sklearn.linear_model import LinearRegression   # Módulo para a regressão linear com a biblioteca de ferramentas para o Aprendizado de máquinas.\n",
    "from sklearn.model_selection import train_test_split # Importa uma função da biblioteca sklearn para a separação dos dados de teste e de validação.\n",
    "from sklearn.metrics import accuracy_score          # Método de verificação da acurácia do modelo.\n",
    "import seaborn as sns                               # Biblioteca de visualização de dados baseado na biblioteca marplotlib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import Lasso, Ridge       # Biblioteca para a aplicação da regularização L1 e L2.\n",
    "sns.set()     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c4e80b",
   "metadata": {},
   "source": [
    "# Carregamento do arquivo.\n",
    "\n",
    "Neste tópico será carregado o arquivo que contém os dados que serão utilizados tanto para treinamento do modelo, quando para a validação.\n",
    "\n",
    "Inicialmente esses dados então em uma estrutura separada por vírgulas e serão importados para o padrão de data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7e4e509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando o arquivo .csv para um data frame\n",
    "dados = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae88d639",
   "metadata": {},
   "source": [
    "Lembrando que o arquivo que foi importado encontra-se na mesma pasta do arquivo Notebook, por isso não foi necessário passar o caminho."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a032e9fd",
   "metadata": {},
   "source": [
    "# Visualização Geral do Conjunto de Dados\n",
    "\n",
    "Inicialmente será verificada, visualmente, de como está a distribuição dos dados no Data Frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2a49a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>HouseStyle</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>RoofStyle</th>\n",
       "      <th>RoofMatl</th>\n",
       "      <th>Exterior1st</th>\n",
       "      <th>Exterior2nd</th>\n",
       "      <th>MasVnrType</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>ExterCond</th>\n",
       "      <th>Foundation</th>\n",
       "      <th>BsmtQual</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>Heating</th>\n",
       "      <th>HeatingQC</th>\n",
       "      <th>CentralAir</th>\n",
       "      <th>Electrical</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Functional</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>FireplaceQu</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>196.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>706</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>856</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>1710</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>8</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>548</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Veenker</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>978</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>284</td>\n",
       "      <td>1262</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>6</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>162.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Mn</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>486</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>434</td>\n",
       "      <td>920</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>0</td>\n",
       "      <td>1786</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>6</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>608</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities LotConfig LandSlope Neighborhood Condition1  \\\n",
       "0         Lvl    AllPub    Inside       Gtl      CollgCr       Norm   \n",
       "1         Lvl    AllPub       FR2       Gtl      Veenker      Feedr   \n",
       "2         Lvl    AllPub    Inside       Gtl      CollgCr       Norm   \n",
       "\n",
       "  Condition2 BldgType HouseStyle  OverallQual  OverallCond  YearBuilt  \\\n",
       "0       Norm     1Fam     2Story            7            5       2003   \n",
       "1       Norm     1Fam     1Story            6            8       1976   \n",
       "2       Norm     1Fam     2Story            7            5       2001   \n",
       "\n",
       "   YearRemodAdd RoofStyle RoofMatl Exterior1st Exterior2nd MasVnrType  \\\n",
       "0          2003     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
       "1          1976     Gable  CompShg     MetalSd     MetalSd       None   \n",
       "2          2002     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
       "\n",
       "   MasVnrArea ExterQual ExterCond Foundation BsmtQual BsmtCond BsmtExposure  \\\n",
       "0       196.0        Gd        TA      PConc       Gd       TA           No   \n",
       "1         0.0        TA        TA     CBlock       Gd       TA           Gd   \n",
       "2       162.0        Gd        TA      PConc       Gd       TA           Mn   \n",
       "\n",
       "  BsmtFinType1  BsmtFinSF1 BsmtFinType2  BsmtFinSF2  BsmtUnfSF  TotalBsmtSF  \\\n",
       "0          GLQ         706          Unf           0        150          856   \n",
       "1          ALQ         978          Unf           0        284         1262   \n",
       "2          GLQ         486          Unf           0        434          920   \n",
       "\n",
       "  Heating HeatingQC CentralAir Electrical  1stFlrSF  2ndFlrSF  LowQualFinSF  \\\n",
       "0    GasA        Ex          Y      SBrkr       856       854             0   \n",
       "1    GasA        Ex          Y      SBrkr      1262         0             0   \n",
       "2    GasA        Ex          Y      SBrkr       920       866             0   \n",
       "\n",
       "   GrLivArea  BsmtFullBath  BsmtHalfBath  FullBath  HalfBath  BedroomAbvGr  \\\n",
       "0       1710             1             0         2         1             3   \n",
       "1       1262             0             1         2         0             3   \n",
       "2       1786             1             0         2         1             3   \n",
       "\n",
       "   KitchenAbvGr KitchenQual  TotRmsAbvGrd Functional  Fireplaces FireplaceQu  \\\n",
       "0             1          Gd             8        Typ           0         NaN   \n",
       "1             1          TA             6        Typ           1          TA   \n",
       "2             1          Gd             6        Typ           1          TA   \n",
       "\n",
       "  GarageType  GarageYrBlt GarageFinish  GarageCars  GarageArea GarageQual  \\\n",
       "0     Attchd       2003.0          RFn           2         548         TA   \n",
       "1     Attchd       1976.0          RFn           2         460         TA   \n",
       "2     Attchd       2001.0          RFn           2         608         TA   \n",
       "\n",
       "  GarageCond PavedDrive  WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  \\\n",
       "0         TA          Y           0           61              0          0   \n",
       "1         TA          Y         298            0              0          0   \n",
       "2         TA          Y           0           42              0          0   \n",
       "\n",
       "   ScreenPorch  PoolArea PoolQC Fence MiscFeature  MiscVal  MoSold  YrSold  \\\n",
       "0            0         0    NaN   NaN         NaN        0       2    2008   \n",
       "1            0         0    NaN   NaN         NaN        0       5    2007   \n",
       "2            0         0    NaN   NaN         NaN        0       9    2008   \n",
       "\n",
       "  SaleType SaleCondition  SalePrice  \n",
       "0       WD        Normal     208500  \n",
       "1       WD        Normal     181500  \n",
       "2       WD        Normal     223500  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuração inicial para que sejam mostradas todas as colunas do data frame\n",
    "pd.set_option('display.max_columns', 82)\n",
    "# Visualização das 3 primeiras linhas\n",
    "dados.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e847471",
   "metadata": {},
   "source": [
    "# Separação dos Dados de treinamento dos dados de Validação\n",
    "\n",
    "Inicialmente serão separados os dados de treinamento do modelo dos dados que serão utilizados para o treinamento.\n",
    "Após essa separação iremos manipular apenas os dados de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c15effbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separação das targets e das features.\n",
    "features = dados.drop(columns=['SalePrice'])       # Separa apenas os dados característicos\n",
    "targets = dados['SalePrice']                       # Separa os dados de referência\n",
    "\n",
    "\n",
    "# Função de separação dos dados de treinamento e dos dados de validação\n",
    "X_treinamento, X_validacao, y_treinamento, y_validacao = train_test_split(features, targets, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Criação de um Data frame apenas com os valores de treino.\n",
    "dados_treino = pd.concat([X_treinamento,y_treinamento], axis = 1)\n",
    "\n",
    "# Cópia do dataframe dados_treino para a eliminação de valores considerados anómalos. \n",
    "df_sem_outlier = dados_treino\n",
    "# df_sem_outlier = dados_treino.copy()\n",
    "\n",
    "# Atribuindo um nome \n",
    "nome_target = 'SalePrice'\n",
    "\n",
    "# dados_treino.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc00a47",
   "metadata": {},
   "source": [
    "# Declaração de Data Frames\n",
    "\n",
    "Serão declarados Data frames que servirão para armazenar os dados para a regressão linear e que auxiliarão nas equações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e6c70c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data frame que armazenará os valores finais da features para a regressão linear\n",
    "features_numericas = pd.DataFrame()\n",
    "\n",
    "# Data frame que armazenará os dados da features aplicada o logarítimo neperiano para a regressão linear\n",
    "features_ln_numericas = pd.DataFrame()\n",
    "\n",
    "# Data frame com as features numericas sem outlier - \n",
    "# Outlier sendo qualquer valor fora do intervalo (< mediana - 3* std e > mediana +3* std)\n",
    "features_numericas_sem_outlier = pd.DataFrame()\n",
    "\n",
    "# Data frame para features sem outlier com aplicação do logarítimo neperiano.\n",
    "features_ln_numericas_sem_outlier = pd.DataFrame()\n",
    "\n",
    "\n",
    "# Data frame que armezenará os dados de todas as features com a aplicação do logarítmo neperiano\n",
    "df_ln = pd.DataFrame()\n",
    "\n",
    "# Data frame que armezenará os dados de todas as features com a aplicação do logarítmo neperiano com a eliminação de alguns valores\n",
    "df_ln_sem_outlier = pd.DataFrame()\n",
    "\n",
    "\n",
    "nome_linhas = ['Regressão Linear Teste', 'Regressão Linear Validação',\\\n",
    "               'Regressão Linear L1 Teste', 'Regressão Linear L1 Validação',\\\n",
    "               'Regressão Linear L2 Teste', 'Regressão Linear L2 Validação']\n",
    "nome_colunas = ['Numéricas', 'Tranformada ln', 'Numéricas sem Outlier', 'Transformada ln sem Outlier']\n",
    "\n",
    "# Data frame de armazenamento dos valores de R^2(coeficiente de determinação) dos modelos\n",
    "score_df = pd.DataFrame(index=nome_linhas, columns=nome_colunas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4ae523",
   "metadata": {},
   "source": [
    "# VISUALIZAÇÃO GERAL DO DATA FRAME DE TREINAMENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "203d332e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>HouseStyle</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>RoofStyle</th>\n",
       "      <th>RoofMatl</th>\n",
       "      <th>Exterior1st</th>\n",
       "      <th>Exterior2nd</th>\n",
       "      <th>MasVnrType</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>ExterCond</th>\n",
       "      <th>Foundation</th>\n",
       "      <th>BsmtQual</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>Heating</th>\n",
       "      <th>HeatingQC</th>\n",
       "      <th>CentralAir</th>\n",
       "      <th>Electrical</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Functional</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>FireplaceQu</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>255</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>70.0</td>\n",
       "      <td>8400</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1957</td>\n",
       "      <td>1957</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>Rec</td>\n",
       "      <td>922</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>392</td>\n",
       "      <td>1314</td>\n",
       "      <td>GasA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1314</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1314</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>5</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1957.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>1</td>\n",
       "      <td>294</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>1067</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>59.0</td>\n",
       "      <td>7837</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Gilbert</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1993</td>\n",
       "      <td>1994</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>799</td>\n",
       "      <td>799</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>799</td>\n",
       "      <td>772</td>\n",
       "      <td>0</td>\n",
       "      <td>1571</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>7</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>380</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>178000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>639</td>\n",
       "      <td>30</td>\n",
       "      <td>RL</td>\n",
       "      <td>67.0</td>\n",
       "      <td>8777</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Edwards</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1910</td>\n",
       "      <td>1950</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>Wd Sdng</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>Fa</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>796</td>\n",
       "      <td>796</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Y</td>\n",
       "      <td>FuseA</td>\n",
       "      <td>796</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>796</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>4</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>328</td>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>85000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>800</td>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7200</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>SWISU</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1.5Fin</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1937</td>\n",
       "      <td>1950</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>Wd Sdng</td>\n",
       "      <td>Wd Sdng</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>252.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>BrkTil</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>569</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>731</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>981</td>\n",
       "      <td>787</td>\n",
       "      <td>0</td>\n",
       "      <td>1768</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>7</td>\n",
       "      <td>Typ</td>\n",
       "      <td>2</td>\n",
       "      <td>TA</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>1939.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>1</td>\n",
       "      <td>240</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>381</td>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>50.0</td>\n",
       "      <td>5000</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>SWISU</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1.5Fin</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1924</td>\n",
       "      <td>1950</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>Wd Sdng</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>BrkTil</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>LwQ</td>\n",
       "      <td>218</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>808</td>\n",
       "      <td>1026</td>\n",
       "      <td>GasA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1026</td>\n",
       "      <td>665</td>\n",
       "      <td>0</td>\n",
       "      <td>1691</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>6</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>1924.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>1</td>\n",
       "      <td>308</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>127000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>1096</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9317</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2006</td>\n",
       "      <td>2006</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>24</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>1290</td>\n",
       "      <td>1314</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1314</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1314</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>6</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>440</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>176432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>1131</td>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>7804</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>SWISU</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1.5Fin</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1928</td>\n",
       "      <td>1950</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>WdShing</td>\n",
       "      <td>Plywood</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>BrkTil</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>BLQ</td>\n",
       "      <td>622</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>1122</td>\n",
       "      <td>GasA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1328</td>\n",
       "      <td>653</td>\n",
       "      <td>0</td>\n",
       "      <td>1981</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>7</td>\n",
       "      <td>Min2</td>\n",
       "      <td>2</td>\n",
       "      <td>TA</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>2</td>\n",
       "      <td>576</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>431</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>1295</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>8172</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Edwards</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1955</td>\n",
       "      <td>1990</td>\n",
       "      <td>Hip</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>WdShing</td>\n",
       "      <td>Plywood</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>Rec</td>\n",
       "      <td>167</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>697</td>\n",
       "      <td>864</td>\n",
       "      <td>GasA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>864</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>864</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>5</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>1957.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>2</td>\n",
       "      <td>572</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>115000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>861</td>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>55.0</td>\n",
       "      <td>7642</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Crawfor</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1.5Fin</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1918</td>\n",
       "      <td>1998</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>Wd Sdng</td>\n",
       "      <td>Wd Sdng</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>BrkTil</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>912</td>\n",
       "      <td>912</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>912</td>\n",
       "      <td>514</td>\n",
       "      <td>0</td>\n",
       "      <td>1426</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>7</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>1925.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>1</td>\n",
       "      <td>216</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>189950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>1127</td>\n",
       "      <td>120</td>\n",
       "      <td>RL</td>\n",
       "      <td>53.0</td>\n",
       "      <td>3684</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Blmngtn</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>TwnhsE</td>\n",
       "      <td>1Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>2007</td>\n",
       "      <td>Hip</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>130.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>1373</td>\n",
       "      <td>1373</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1555</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1555</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>7</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>Fin</td>\n",
       "      <td>3</td>\n",
       "      <td>660</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>143</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>174000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1168 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "254    255          20       RL         70.0     8400   Pave   NaN      Reg   \n",
       "1066  1067          60       RL         59.0     7837   Pave   NaN      IR1   \n",
       "638    639          30       RL         67.0     8777   Pave   NaN      Reg   \n",
       "799    800          50       RL         60.0     7200   Pave   NaN      Reg   \n",
       "380    381          50       RL         50.0     5000   Pave  Pave      Reg   \n",
       "...    ...         ...      ...          ...      ...    ...   ...      ...   \n",
       "1095  1096          20       RL         78.0     9317   Pave   NaN      IR1   \n",
       "1130  1131          50       RL         65.0     7804   Pave   NaN      Reg   \n",
       "1294  1295          20       RL         60.0     8172   Pave   NaN      Reg   \n",
       "860    861          50       RL         55.0     7642   Pave   NaN      Reg   \n",
       "1126  1127         120       RL         53.0     3684   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities LotConfig LandSlope Neighborhood Condition1  \\\n",
       "254          Lvl    AllPub    Inside       Gtl        NAmes       Norm   \n",
       "1066         Lvl    AllPub    Inside       Gtl      Gilbert       Norm   \n",
       "638          Lvl    AllPub    Inside       Gtl      Edwards      Feedr   \n",
       "799          Lvl    AllPub    Corner       Gtl        SWISU      Feedr   \n",
       "380          Lvl    AllPub    Inside       Gtl        SWISU       Norm   \n",
       "...          ...       ...       ...       ...          ...        ...   \n",
       "1095         Lvl    AllPub    Inside       Gtl      CollgCr       Norm   \n",
       "1130         Lvl    AllPub    Inside       Gtl        SWISU       Norm   \n",
       "1294         Lvl    AllPub    Inside       Gtl      Edwards       Norm   \n",
       "860          Lvl    AllPub    Corner       Gtl      Crawfor       Norm   \n",
       "1126         Lvl    AllPub    Inside       Gtl      Blmngtn       Norm   \n",
       "\n",
       "     Condition2 BldgType HouseStyle  OverallQual  OverallCond  YearBuilt  \\\n",
       "254        Norm     1Fam     1Story            5            6       1957   \n",
       "1066       Norm     1Fam     2Story            6            7       1993   \n",
       "638        Norm     1Fam     1Story            5            7       1910   \n",
       "799        Norm     1Fam     1.5Fin            5            7       1937   \n",
       "380        Norm     1Fam     1.5Fin            5            6       1924   \n",
       "...         ...      ...        ...          ...          ...        ...   \n",
       "1095       Norm     1Fam     1Story            6            5       2006   \n",
       "1130       Norm     1Fam     1.5Fin            4            3       1928   \n",
       "1294       Norm     1Fam     1Story            5            7       1955   \n",
       "860        Norm     1Fam     1.5Fin            7            8       1918   \n",
       "1126       Norm   TwnhsE     1Story            7            5       2007   \n",
       "\n",
       "      YearRemodAdd RoofStyle RoofMatl Exterior1st Exterior2nd MasVnrType  \\\n",
       "254           1957     Gable  CompShg     MetalSd     MetalSd       None   \n",
       "1066          1994     Gable  CompShg     VinylSd     VinylSd       None   \n",
       "638           1950     Gable  CompShg     MetalSd     Wd Sdng       None   \n",
       "799           1950     Gable  CompShg     Wd Sdng     Wd Sdng    BrkFace   \n",
       "380           1950     Gable  CompShg     BrkFace     Wd Sdng       None   \n",
       "...            ...       ...      ...         ...         ...        ...   \n",
       "1095          2006     Gable  CompShg     VinylSd     VinylSd       None   \n",
       "1130          1950     Gable  CompShg     WdShing     Plywood       None   \n",
       "1294          1990       Hip  CompShg     WdShing     Plywood       None   \n",
       "860           1998     Gable  CompShg     Wd Sdng     Wd Sdng       None   \n",
       "1126          2007       Hip  CompShg     VinylSd     VinylSd    BrkFace   \n",
       "\n",
       "      MasVnrArea ExterQual ExterCond Foundation BsmtQual BsmtCond  \\\n",
       "254          0.0        TA        Gd     CBlock       TA       TA   \n",
       "1066         0.0        Gd        TA      PConc       Gd       TA   \n",
       "638          0.0        TA        TA     CBlock       Fa       TA   \n",
       "799        252.0        TA        TA     BrkTil       Gd       TA   \n",
       "380          0.0        TA        TA     BrkTil       TA       TA   \n",
       "...          ...       ...       ...        ...      ...      ...   \n",
       "1095         0.0        Gd        TA      PConc       Gd       TA   \n",
       "1130         0.0        TA        TA     BrkTil       TA       TA   \n",
       "1294         0.0        TA        TA     CBlock       TA       TA   \n",
       "860          0.0        Gd        TA     BrkTil       TA       TA   \n",
       "1126       130.0        Gd        TA      PConc       Gd       TA   \n",
       "\n",
       "     BsmtExposure BsmtFinType1  BsmtFinSF1 BsmtFinType2  BsmtFinSF2  \\\n",
       "254            No          Rec         922          Unf           0   \n",
       "1066           No          Unf           0          Unf           0   \n",
       "638            No          Unf           0          Unf           0   \n",
       "799            No          ALQ         569          Unf           0   \n",
       "380            No          LwQ         218          Unf           0   \n",
       "...           ...          ...         ...          ...         ...   \n",
       "1095           No          GLQ          24          Unf           0   \n",
       "1130           No          BLQ         622          Unf           0   \n",
       "1294           No          Rec         167          Unf           0   \n",
       "860            No          Unf           0          Unf           0   \n",
       "1126           No          Unf           0          Unf           0   \n",
       "\n",
       "      BsmtUnfSF  TotalBsmtSF Heating HeatingQC CentralAir Electrical  \\\n",
       "254         392         1314    GasA        TA          Y      SBrkr   \n",
       "1066        799          799    GasA        Gd          Y      SBrkr   \n",
       "638         796          796    GasA        Gd          Y      FuseA   \n",
       "799         162          731    GasA        Ex          Y      SBrkr   \n",
       "380         808         1026    GasA        TA          Y      SBrkr   \n",
       "...         ...          ...     ...       ...        ...        ...   \n",
       "1095       1290         1314    GasA        Gd          Y      SBrkr   \n",
       "1130        500         1122    GasA        TA          Y      SBrkr   \n",
       "1294        697          864    GasA        TA          Y      SBrkr   \n",
       "860         912          912    GasA        Gd          Y      SBrkr   \n",
       "1126       1373         1373    GasA        Ex          Y      SBrkr   \n",
       "\n",
       "      1stFlrSF  2ndFlrSF  LowQualFinSF  GrLivArea  BsmtFullBath  BsmtHalfBath  \\\n",
       "254       1314         0             0       1314             1             0   \n",
       "1066       799       772             0       1571             0             0   \n",
       "638        796         0             0        796             0             0   \n",
       "799        981       787             0       1768             1             0   \n",
       "380       1026       665             0       1691             0             0   \n",
       "...        ...       ...           ...        ...           ...           ...   \n",
       "1095      1314         0             0       1314             0             0   \n",
       "1130      1328       653             0       1981             1             0   \n",
       "1294       864         0             0        864             1             0   \n",
       "860        912       514             0       1426             0             0   \n",
       "1126      1555         0             0       1555             0             0   \n",
       "\n",
       "      FullBath  HalfBath  BedroomAbvGr  KitchenAbvGr KitchenQual  \\\n",
       "254          1         0             3             1          TA   \n",
       "1066         2         1             3             1          TA   \n",
       "638          1         0             2             1          TA   \n",
       "799          1         1             3             1          Gd   \n",
       "380          2         0             3             1          Gd   \n",
       "...        ...       ...           ...           ...         ...   \n",
       "1095         2         0             3             1          Gd   \n",
       "1130         2         0             4             1          Gd   \n",
       "1294         1         0             2             1          TA   \n",
       "860          1         1             3             1          Gd   \n",
       "1126         2         0             2             1          Gd   \n",
       "\n",
       "      TotRmsAbvGrd Functional  Fireplaces FireplaceQu GarageType  GarageYrBlt  \\\n",
       "254              5        Typ           0         NaN     Attchd       1957.0   \n",
       "1066             7        Typ           1          TA     Attchd       1993.0   \n",
       "638              4        Typ           0         NaN        NaN          NaN   \n",
       "799              7        Typ           2          TA     Detchd       1939.0   \n",
       "380              6        Typ           1          Gd     Detchd       1924.0   \n",
       "...            ...        ...         ...         ...        ...          ...   \n",
       "1095             6        Typ           1          Gd     Attchd       2006.0   \n",
       "1130             7       Min2           2          TA     Detchd       1981.0   \n",
       "1294             5        Typ           0         NaN     Detchd       1957.0   \n",
       "860              7        Typ           1          Gd     Detchd       1925.0   \n",
       "1126             7        Typ           1          TA     Attchd       2007.0   \n",
       "\n",
       "     GarageFinish  GarageCars  GarageArea GarageQual GarageCond PavedDrive  \\\n",
       "254           RFn           1         294         TA         TA          Y   \n",
       "1066          RFn           2         380         TA         TA          Y   \n",
       "638           NaN           0           0        NaN        NaN          P   \n",
       "799           Unf           1         240         TA         TA          Y   \n",
       "380           Unf           1         308         TA         TA          Y   \n",
       "...           ...         ...         ...        ...        ...        ...   \n",
       "1095          RFn           2         440         TA         TA          Y   \n",
       "1130          Unf           2         576         TA         TA          Y   \n",
       "1294          Unf           2         572         TA         TA          N   \n",
       "860           Unf           1         216         TA         TA          Y   \n",
       "1126          Fin           3         660         TA         TA          Y   \n",
       "\n",
       "      WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  \\\n",
       "254          250            0              0          0            0   \n",
       "1066           0           40              0          0            0   \n",
       "638          328            0            164          0            0   \n",
       "799            0            0            264          0            0   \n",
       "380            0            0            242          0            0   \n",
       "...          ...          ...            ...        ...          ...   \n",
       "1095           0           22              0          0            0   \n",
       "1130         431           44              0          0            0   \n",
       "1294           0            0              0          0            0   \n",
       "860            0          240              0          0            0   \n",
       "1126         143           20              0          0            0   \n",
       "\n",
       "      PoolArea PoolQC  Fence MiscFeature  MiscVal  MoSold  YrSold SaleType  \\\n",
       "254          0    NaN    NaN         NaN        0       6    2010       WD   \n",
       "1066         0    NaN    NaN         NaN        0       5    2009       WD   \n",
       "638          0    NaN  MnPrv         NaN        0       5    2008       WD   \n",
       "799          0    NaN  MnPrv         NaN        0       6    2007       WD   \n",
       "380          0    NaN    NaN         NaN        0       5    2010       WD   \n",
       "...        ...    ...    ...         ...      ...     ...     ...      ...   \n",
       "1095         0    NaN    NaN         NaN        0       3    2007       WD   \n",
       "1130         0    NaN  MnPrv         NaN        0      12    2009       WD   \n",
       "1294         0    NaN    NaN         NaN        0       4    2006       WD   \n",
       "860          0    NaN  GdPrv         NaN        0       6    2007       WD   \n",
       "1126         0    NaN    NaN         NaN        0       6    2009       WD   \n",
       "\n",
       "     SaleCondition  SalePrice  \n",
       "254         Normal     145000  \n",
       "1066        Normal     178000  \n",
       "638         Normal      85000  \n",
       "799         Normal     175000  \n",
       "380         Normal     127000  \n",
       "...            ...        ...  \n",
       "1095        Normal     176432  \n",
       "1130        Normal     135000  \n",
       "1294        Normal     115000  \n",
       "860         Normal     189950  \n",
       "1126        Normal     174000  \n",
       "\n",
       "[1168 rows x 81 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Configuração inicial para que sejam mostradas todas as colunas do data frame\n",
    "pd.set_option('display.max_rows', 81)\n",
    "# VERIFICAÇÃO DE VALORES NÃO VÁLIDOS DO DATA FRAME\n",
    "display(dados_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e3a3d5",
   "metadata": {},
   "source": [
    "# Tratamento individual das variáveis.\n",
    "\n",
    "Nesse tópico cada variável (feature) será avaliada individualmente. Essa análise incluirá: o valor semântico de cada 'feature'; a disposição dos dados da variável; a eliminação (ou substituição) de valores não válidos; a substituição de valores anormais quando comparado ao conjunto de dados; a verificação dessa feature com a variável alvo do modelo. \n",
    "\n",
    "Serão armazenados valores sem transformação e valores com a aplicação do logarítmo neperiano às features.\n",
    "\n",
    "Como referência para a escolha, serão selecionados apenas as features que possuírem uma correlação >= 0.1 ou <= -0.1. \n",
    "\n",
    "Tanto para as variáveis não transformadas quanto para as transformadas. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4702e2d9",
   "metadata": {},
   "source": [
    "## MSSubClass (Numérica)\n",
    "\n",
    "Variável que indica o tipo de habitação envolvida na venda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f700b0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "\n",
      "Correlação entre MSSubClass e SalePrice\n",
      "\n",
      "            MSSubClass  SalePrice\n",
      "MSSubClass    1.000000  -0.088081\n",
      "SalePrice    -0.088081   1.000000\n",
      "\n",
      "Correlação entre ln<MSSubClass> e ln<SalePrice>\n",
      "\n",
      "            MSSubClass  SalePrice\n",
      "MSSubClass    1.000000  -0.023143\n",
      "SalePrice    -0.023143   1.000000\n",
      "\n",
      "Correlação entre MSSubClass e SalePrice SEM OUTLIER\n",
      "\n",
      "            MSSubClass  SalePrice\n",
      "MSSubClass    1.000000  -0.021937\n",
      "SalePrice    -0.021937   1.000000\n",
      "\n",
      "Correlação entre ln<MSSubClass> e ln<SalePrice> SEM OUTLIER\n",
      "\n",
      "            MSSubClass  SalePrice\n",
      "MSSubClass    1.000000   0.025657\n",
      "SalePrice     0.025657   1.000000\n",
      "\n",
      "Quantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "\n",
      "Quantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nome_feature = 'MSSubClass'\n",
    "\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Substituição de valores não válidos pela mediana da variável.\n",
    "dados_treino[nome_feature].fillna(dados_treino[nome_feature].median(), inplace = True)\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target}\\n\")\n",
    "print(dados_treino[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}>\\n\")\n",
    "\n",
    "df_ln[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores maiores que mediana + 3 vezes o desvio padrão.\n",
    "med = df_sem_outlier[nome_feature].median()\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] >= (df_sem_outlier[nome_feature].median() + 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores MENOR que mediana - 3 vezes o desvio padrão.\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] <= (df_sem_outlier[nome_feature].median() - 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target} SEM OUTLIER\\n\")\n",
    "print(df_sem_outlier[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}> SEM OUTLIER\\n\")\n",
    "\n",
    "df_ln_sem_outlier[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln_sem_outlier[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln_sem_outlier[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# # ARMAZENAMENTO DAS FEATURES CASO SEJAM UTILIZADAS NO MODELO DE REGRESSÃO LINEAR.\n",
    "\n",
    "# # Armazenamento da feature não transformada.\n",
    "# features_numericas[nome_feature] = dados_treino[nome_feature]\n",
    "\n",
    "# # Armazenamento da feature transformada com ln.\n",
    "# features_ln_numericas[nome_feature] = df_ln[nome_feature]\n",
    "\n",
    "# # Armazenamento da feature não transformada.\n",
    "# features_numericas_sem_outlier[nome_feature] = df_sem_outlier[nome_feature]\n",
    "\n",
    "# # Armazenamento da feature transformada com ln.\n",
    "# features_ln_numericas_sem_outlier[nome_feature] = df_ln_sem_outlier[nome_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4af241",
   "metadata": {},
   "source": [
    "## MSZoning (Categórica)\n",
    "\n",
    "Identifica a classificação geral de zoneamento da venda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d79954c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "Verficação da disposição da variável em agurpamento:\n",
      "MSZoning\n",
      "C (all)      4\n",
      "FV          53\n",
      "RH          15\n",
      "RL         924\n",
      "RM         172\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>SalePrice</td>    <th>  R-squared:         </th> <td>   0.096</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.093</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   31.03</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 05 Dec 2023</td> <th>  Prob (F-statistic):</th> <td>1.41e-24</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>07:17:25</td>     <th>  Log-Likelihood:    </th> <td> -14743.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.950e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1163</td>      <th>  BIC:               </th> <td>2.952e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td> 9.045e+04</td> <td> 3.68e+04</td> <td>    2.459</td> <td> 0.014</td> <td> 1.83e+04</td> <td> 1.63e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FV</th>        <td> 1.256e+05</td> <td> 3.81e+04</td> <td>    3.291</td> <td> 0.001</td> <td> 5.07e+04</td> <td>    2e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RH</th>        <td> 4.101e+04</td> <td> 4.14e+04</td> <td>    0.991</td> <td> 0.322</td> <td>-4.02e+04</td> <td> 1.22e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RL</th>        <td> 9.989e+04</td> <td> 3.69e+04</td> <td>    2.710</td> <td> 0.007</td> <td> 2.76e+04</td> <td> 1.72e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RM</th>        <td> 3.901e+04</td> <td> 3.72e+04</td> <td>    1.048</td> <td> 0.295</td> <td> -3.4e+04</td> <td> 1.12e+05</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>494.400</td> <th>  Durbin-Watson:     </th> <td>   1.984</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2786.498</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.889</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 9.556</td>  <th>  Cond. No.          </th> <td>    50.2</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              SalePrice   R-squared:                       0.096\n",
       "Model:                            OLS   Adj. R-squared:                  0.093\n",
       "Method:                 Least Squares   F-statistic:                     31.03\n",
       "Date:                Tue, 05 Dec 2023   Prob (F-statistic):           1.41e-24\n",
       "Time:                        07:17:25   Log-Likelihood:                -14743.\n",
       "No. Observations:                1168   AIC:                         2.950e+04\n",
       "Df Residuals:                    1163   BIC:                         2.952e+04\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept   9.045e+04   3.68e+04      2.459      0.014    1.83e+04    1.63e+05\n",
       "FV          1.256e+05   3.81e+04      3.291      0.001    5.07e+04       2e+05\n",
       "RH          4.101e+04   4.14e+04      0.991      0.322   -4.02e+04    1.22e+05\n",
       "RL          9.989e+04   3.69e+04      2.710      0.007    2.76e+04    1.72e+05\n",
       "RM          3.901e+04   3.72e+04      1.048      0.295    -3.4e+04    1.12e+05\n",
       "==============================================================================\n",
       "Omnibus:                      494.400   Durbin-Watson:                   1.984\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2786.498\n",
       "Skew:                           1.889   Prob(JB):                         0.00\n",
       "Kurtosis:                       9.556   Cond. No.                         50.2\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nome_feature = 'MSZoning'\n",
    "\n",
    "# Verificação de valores nulos na variável\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Estatística univariádas pela variável\n",
    "print('Verficação da disposição da variável em agurpamento:')\n",
    "agrupado = dados_treino.groupby([nome_feature]).size()\n",
    "print(agrupado)\n",
    "\n",
    "# Conversão da variável categórica em dicotômica com a exclusão da primeira variável dicotômica.\n",
    "df_dummies_auxiliar = pd.get_dummies(dados_treino[nome_feature], columns=[nome_feature], drop_first=True)\n",
    "\n",
    "# Inclusão da variável dependente ao data frame de variáveis dicotômicas.\n",
    "df_dummies_auxiliar[nome_target] = dados_treino[nome_target].copy()\n",
    "\n",
    "# Verificação do data frame.\n",
    "df_dummies_auxiliar.head(6)\n",
    "\n",
    "# Estimação do modelo de regressão linear múltipla com n-1 dummies\n",
    "modelo_dummies = sm.OLS.from_formula(\"SalePrice ~ FV + RH + RL + RM\", df_dummies_auxiliar).fit()\n",
    "\n",
    "# Verificação dos parâmetros do modelo.\n",
    "modelo_dummies.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bd9172",
   "metadata": {},
   "source": [
    "Analisando os dados da regressão linear apenas com essa variável categórica, tem-se: \n",
    "\n",
    "**R-squared:** 0.096. -> Isso significa que essa regressão representa aproximadamente 10% da variável dependente.\n",
    "**F-statistic:** 31,03 -> Não podemos excluir a hipótese H0, ou seja, não podemos garantir que alguma variável indepente seja significante para a variável dependente.\n",
    "\n",
    "Os valores de **P>|t|** nos ajudar na informação de que as variáveis RH e RM não são significativas para a variável dependente. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0b0814",
   "metadata": {},
   "source": [
    "## LotFrontage (Numérica)\n",
    "\n",
    "Perímetro de conexão do imóvel com a rua."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b4f6f35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 217\n",
      "\n",
      "\n",
      "Correlação entre LotFrontage e SalePrice\n",
      "\n",
      "             LotFrontage  SalePrice\n",
      "LotFrontage     1.000000   0.312157\n",
      "SalePrice       0.312157   1.000000\n",
      "\n",
      "Correlação entre ln<LotFrontage> e ln<SalePrice>\n",
      "\n",
      "             LotFrontage  SalePrice\n",
      "LotFrontage      1.00000    0.32806\n",
      "SalePrice        0.32806    1.00000\n",
      "\n",
      "Correlação entre LotFrontage e SalePrice SEM OUTLIER\n",
      "\n",
      "             LotFrontage  SalePrice\n",
      "LotFrontage     1.000000   0.326944\n",
      "SalePrice       0.326944   1.000000\n",
      "\n",
      "Correlação entre ln<LotFrontage> e ln<SalePrice> SEM OUTLIER\n",
      "\n",
      "             LotFrontage  SalePrice\n",
      "LotFrontage     1.000000   0.324734\n",
      "SalePrice       0.324734   1.000000\n",
      "\n",
      "Quantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "\n",
      "Quantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nome_feature = 'LotFrontage'\n",
    "\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Substituição de valores não válidos pela mediana da variável em ambos os data frames.\n",
    "dados_treino[nome_feature].fillna(dados_treino[nome_feature].median(), inplace = True)\n",
    "df_sem_outlier[nome_feature].fillna(df_sem_outlier[nome_feature].median(), inplace = True)\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target}\\n\")\n",
    "print(dados_treino[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}>\\n\")\n",
    "\n",
    "df_ln[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores maiores que mediana + 3 vezes o desvio padrão.\n",
    "med = df_sem_outlier[nome_feature].median()\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] >= (df_sem_outlier[nome_feature].median() + 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores MENOR que mediana - 3 vezes o desvio padrão.\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] <= (df_sem_outlier[nome_feature].median() - 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target} SEM OUTLIER\\n\")\n",
    "print(df_sem_outlier[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}> SEM OUTLIER\\n\")\n",
    "\n",
    "df_ln_sem_outlier[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln_sem_outlier[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln_sem_outlier[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# ARMAZENAMENTO DAS FEATURES CASO SEJAM UTILIZADAS NO MODELO DE REGRESSÃO LINEAR.\n",
    "\n",
    "# Armazenamento da feature não transformada.\n",
    "features_numericas[nome_feature] = dados_treino[nome_feature]\n",
    "\n",
    "# Armezenamento da feature transformada com ln.\n",
    "features_ln_numericas[nome_feature] = df_ln[nome_feature]\n",
    "\n",
    "# Armazenamento da feature não transformada.\n",
    "features_numericas_sem_outlier[nome_feature] = df_sem_outlier[nome_feature]\n",
    "\n",
    "# Armezenamento da feature transformada com ln.\n",
    "features_ln_numericas_sem_outlier[nome_feature] = df_ln_sem_outlier[nome_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1337a9a",
   "metadata": {},
   "source": [
    "## LotArea (Numérica)\n",
    "\n",
    "Área do imóvel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f98dd69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "\n",
      "Correlação entre LotArea e SalePrice\n",
      "\n",
      "            LotArea  SalePrice\n",
      "LotArea    1.000000   0.266204\n",
      "SalePrice  0.266204   1.000000\n",
      "\n",
      "Correlação entre ln<LotArea> e ln<SalePrice>\n",
      "\n",
      "           LotArea  SalePrice\n",
      "LotArea     1.0000     0.4113\n",
      "SalePrice   0.4113     1.0000\n",
      "\n",
      "Correlação entre LotArea e SalePrice SEM OUTLIER\n",
      "\n",
      "            LotArea  SalePrice\n",
      "LotArea    1.000000   0.379244\n",
      "SalePrice  0.379244   1.000000\n",
      "\n",
      "Correlação entre ln<LotArea> e ln<SalePrice> SEM OUTLIER\n",
      "\n",
      "            LotArea  SalePrice\n",
      "LotArea    1.000000   0.395981\n",
      "SalePrice  0.395981   1.000000\n",
      "\n",
      "Quantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "\n",
      "Quantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nome_feature = 'LotArea'\n",
    "\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# # Substituição de valores não válidos pela mediana da variável em ambos os data frames.\n",
    "# dados_treino[nome_feature].fillna(dados_treino[nome_feature].median(), inplace = True)\n",
    "# df_sem_outlier[nome_feature].fillna(df_sem_outlier[nome_feature].median(), inplace = True)\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target}\\n\")\n",
    "print(dados_treino[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}>\\n\")\n",
    "\n",
    "df_ln[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores maiores que mediana + 3 vezes o desvio padrão.\n",
    "med = df_sem_outlier[nome_feature].median()\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] >= (df_sem_outlier[nome_feature].median() + 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores MENOR que mediana - 3 vezes o desvio padrão.\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] <= (df_sem_outlier[nome_feature].median() - 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target} SEM OUTLIER\\n\")\n",
    "print(df_sem_outlier[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}> SEM OUTLIER\\n\")\n",
    "\n",
    "df_ln_sem_outlier[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln_sem_outlier[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln_sem_outlier[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# ARMAZENAMENTO DAS FEATURES CASO SEJAM UTILIZADAS NO MODELO DE REGRESSÃO LINEAR.\n",
    "\n",
    "# Armazenamento da feature não transformada.\n",
    "features_numericas[nome_feature] = dados_treino[nome_feature]\n",
    "\n",
    "# Armezenamento da feature transformada com ln.\n",
    "features_ln_numericas[nome_feature] = df_ln[nome_feature]\n",
    "\n",
    "# Armazenamento da feature não transformada.\n",
    "features_numericas_sem_outlier[nome_feature] = df_sem_outlier[nome_feature]\n",
    "\n",
    "# Armezenamento da feature transformada com ln.\n",
    "features_ln_numericas_sem_outlier[nome_feature] = df_ln_sem_outlier[nome_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2c215e",
   "metadata": {},
   "source": [
    "## Street (Categórica)\n",
    "\n",
    "Tipo de estrada de acesso à propriedade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1c7f752",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "Verficação da disposição da variável em agurpamento:\n",
      "Street\n",
      "Grvl       4\n",
      "Pave    1164\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>SalePrice</td>    <th>  R-squared:         </th> <td>   0.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>  -0.001</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>  0.2797</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 05 Dec 2023</td> <th>  Prob (F-statistic):</th>  <td> 0.597</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>07:17:25</td>     <th>  Log-Likelihood:    </th> <td> -14802.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.961e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1166</td>      <th>  BIC:               </th> <td>2.962e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>  1.61e+05</td> <td> 3.86e+04</td> <td>    4.167</td> <td> 0.000</td> <td> 8.52e+04</td> <td> 2.37e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pave</th>      <td> 2.047e+04</td> <td> 3.87e+04</td> <td>    0.529</td> <td> 0.597</td> <td>-5.55e+04</td> <td> 9.64e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>443.143</td> <th>  Durbin-Watson:     </th> <td>   2.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2031.760</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.740</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.444</td>  <th>  Cond. No.          </th> <td>    34.1</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              SalePrice   R-squared:                       0.000\n",
       "Model:                            OLS   Adj. R-squared:                 -0.001\n",
       "Method:                 Least Squares   F-statistic:                    0.2797\n",
       "Date:                Tue, 05 Dec 2023   Prob (F-statistic):              0.597\n",
       "Time:                        07:17:25   Log-Likelihood:                -14802.\n",
       "No. Observations:                1168   AIC:                         2.961e+04\n",
       "Df Residuals:                    1166   BIC:                         2.962e+04\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept    1.61e+05   3.86e+04      4.167      0.000    8.52e+04    2.37e+05\n",
       "Pave        2.047e+04   3.87e+04      0.529      0.597   -5.55e+04    9.64e+04\n",
       "==============================================================================\n",
       "Omnibus:                      443.143   Durbin-Watson:                   2.032\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2031.760\n",
       "Skew:                           1.740   Prob(JB):                         0.00\n",
       "Kurtosis:                       8.444   Cond. No.                         34.1\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nome_feature = 'Street'\n",
    "\n",
    "# Verificação de valores nulos na variável\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Estatística univariádas pela variável\n",
    "print('Verficação da disposição da variável em agurpamento:')\n",
    "agrupado = dados_treino.groupby([nome_feature]).size()\n",
    "print(agrupado)\n",
    "\n",
    "# Conversão da variável categórica em dicotômica com a exclusão da primeira variável dicotômica.\n",
    "df_dummies_auxiliar = pd.get_dummies(dados_treino[nome_feature], columns=[nome_feature], drop_first=True)\n",
    "\n",
    "# Inclusão da variável dependente ao data frame de variáveis dicotômicas.\n",
    "df_dummies_auxiliar[nome_target] = dados_treino[nome_target].copy()\n",
    "\n",
    "# Verificação do data frame.\n",
    "df_dummies_auxiliar.head(6)\n",
    "\n",
    "# Estimação do modelo de regressão linear múltipla com n-1 dummies\n",
    "modelo_dummies = sm.OLS.from_formula(\"SalePrice ~ Pave\", df_dummies_auxiliar).fit()\n",
    "\n",
    "# Verificação dos parâmetros do modelo.\n",
    "modelo_dummies.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96dbeb3",
   "metadata": {},
   "source": [
    "Analisando de forma geral, tanto pela quantidade de dados quanto pelos valores característico da regressão linear construído apenas com essa variável, é perceptível pelos valores de \"R-squared\", \"F-statistic\" e t que essa variável não é significativa para a variável dependente. SalePrice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351f4736",
   "metadata": {},
   "source": [
    "## Alley (Categórica)\n",
    "\n",
    "Tipo de rua de acesso à propriedade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "637c63d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 1094\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nome_feature = 'Alley'\n",
    "\n",
    "# Verificação de valores nulos na variável\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1d3de0",
   "metadata": {},
   "source": [
    "Devido a grande quantidade de valores não válidos nessa variável iremos eliminá-la das análises."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b751dd",
   "metadata": {},
   "source": [
    "## LotShape (Categórica)\n",
    "\n",
    "Forma geral da propriedade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3108e309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "Verficação da disposição da variável em agurpamento:\n",
      "LotShape\n",
      "IR1    394\n",
      "IR2     37\n",
      "IR3      8\n",
      "Reg    729\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>SalePrice</td>    <th>  R-squared:         </th> <td>   0.070</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.068</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   29.31</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 05 Dec 2023</td> <th>  Prob (F-statistic):</th> <td>2.84e-18</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>07:17:25</td>     <th>  Log-Likelihood:    </th> <td> -14760.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.953e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1164</td>      <th>  BIC:               </th> <td>2.955e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td> 2.029e+05</td> <td> 3758.112</td> <td>   53.982</td> <td> 0.000</td> <td> 1.95e+05</td> <td>  2.1e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>IR2</th>       <td> 3.732e+04</td> <td> 1.28e+04</td> <td>    2.910</td> <td> 0.004</td> <td> 1.22e+04</td> <td> 6.25e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>IR3</th>       <td> 2.272e+04</td> <td> 2.66e+04</td> <td>    0.853</td> <td> 0.394</td> <td>-2.95e+04</td> <td>  7.5e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Reg</th>       <td>-3.648e+04</td> <td> 4664.400</td> <td>   -7.821</td> <td> 0.000</td> <td>-4.56e+04</td> <td>-2.73e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>455.945</td> <th>  Durbin-Watson:     </th> <td>   2.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2216.674</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.774</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.741</td>  <th>  Cond. No.          </th> <td>    14.8</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              SalePrice   R-squared:                       0.070\n",
       "Model:                            OLS   Adj. R-squared:                  0.068\n",
       "Method:                 Least Squares   F-statistic:                     29.31\n",
       "Date:                Tue, 05 Dec 2023   Prob (F-statistic):           2.84e-18\n",
       "Time:                        07:17:25   Log-Likelihood:                -14760.\n",
       "No. Observations:                1168   AIC:                         2.953e+04\n",
       "Df Residuals:                    1164   BIC:                         2.955e+04\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept   2.029e+05   3758.112     53.982      0.000    1.95e+05     2.1e+05\n",
       "IR2         3.732e+04   1.28e+04      2.910      0.004    1.22e+04    6.25e+04\n",
       "IR3         2.272e+04   2.66e+04      0.853      0.394   -2.95e+04     7.5e+04\n",
       "Reg        -3.648e+04   4664.400     -7.821      0.000   -4.56e+04   -2.73e+04\n",
       "==============================================================================\n",
       "Omnibus:                      455.945   Durbin-Watson:                   2.031\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2216.674\n",
       "Skew:                           1.774   Prob(JB):                         0.00\n",
       "Kurtosis:                       8.741   Cond. No.                         14.8\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nome_feature = 'LotShape'\n",
    "\n",
    "# Verificação de valores nulos na variável\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Estatística univariádas pela variável\n",
    "print('Verficação da disposição da variável em agurpamento:')\n",
    "agrupado = dados_treino.groupby([nome_feature]).size()\n",
    "print(agrupado)\n",
    "\n",
    "# Conversão da variável categórica em dicotômica com a exclusão da primeira variável dicotômica.\n",
    "df_dummies_auxiliar = pd.get_dummies(dados_treino[nome_feature], columns=[nome_feature], drop_first=True)\n",
    "\n",
    "# Inclusão da variável dependente ao data frame de variáveis dicotômicas.\n",
    "df_dummies_auxiliar[nome_target] = dados_treino[nome_target].copy()\n",
    "\n",
    "# Verificação do data frame.\n",
    "df_dummies_auxiliar.head(6)\n",
    "\n",
    "# Estimação do modelo de regressão linear múltipla com n-1 dummies\n",
    "modelo_dummies = sm.OLS.from_formula(\"SalePrice ~ IR2 + IR3 + Reg\", df_dummies_auxiliar).fit()\n",
    "\n",
    "# Verificação dos parâmetros do modelo.\n",
    "modelo_dummies.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a918ad10",
   "metadata": {},
   "source": [
    "## LandContour (Categórica)\n",
    "\n",
    "Planicidade da propriedade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7773b9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "Verficação da disposição da variável em agurpamento:\n",
      "\n",
      "LandContour\n",
      "Bnk      48\n",
      "HLS      35\n",
      "Low      26\n",
      "Lvl    1059\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>SalePrice</td>    <th>  R-squared:         </th> <td>   0.032</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.030</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   12.95</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 05 Dec 2023</td> <th>  Prob (F-statistic):</th> <td>2.51e-08</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>07:17:25</td>     <th>  Log-Likelihood:    </th> <td> -14783.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.957e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1164</td>      <th>  BIC:               </th> <td>2.960e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td> 1.425e+05</td> <td>  1.1e+04</td> <td>   12.975</td> <td> 0.000</td> <td> 1.21e+05</td> <td> 1.64e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HLS</th>       <td> 1.026e+05</td> <td> 1.69e+04</td> <td>    6.063</td> <td> 0.000</td> <td> 6.94e+04</td> <td> 1.36e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Low</th>       <td> 5.841e+04</td> <td> 1.85e+04</td> <td>    3.152</td> <td> 0.002</td> <td>  2.2e+04</td> <td> 9.48e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lvl</th>       <td> 3.809e+04</td> <td> 1.12e+04</td> <td>    3.392</td> <td> 0.001</td> <td> 1.61e+04</td> <td> 6.01e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>442.006</td> <th>  Durbin-Watson:     </th> <td>   2.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2126.470</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.715</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.651</td>  <th>  Cond. No.          </th> <td>    15.0</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              SalePrice   R-squared:                       0.032\n",
       "Model:                            OLS   Adj. R-squared:                  0.030\n",
       "Method:                 Least Squares   F-statistic:                     12.95\n",
       "Date:                Tue, 05 Dec 2023   Prob (F-statistic):           2.51e-08\n",
       "Time:                        07:17:25   Log-Likelihood:                -14783.\n",
       "No. Observations:                1168   AIC:                         2.957e+04\n",
       "Df Residuals:                    1164   BIC:                         2.960e+04\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept   1.425e+05    1.1e+04     12.975      0.000    1.21e+05    1.64e+05\n",
       "HLS         1.026e+05   1.69e+04      6.063      0.000    6.94e+04    1.36e+05\n",
       "Low         5.841e+04   1.85e+04      3.152      0.002     2.2e+04    9.48e+04\n",
       "Lvl         3.809e+04   1.12e+04      3.392      0.001    1.61e+04    6.01e+04\n",
       "==============================================================================\n",
       "Omnibus:                      442.006   Durbin-Watson:                   2.059\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2126.470\n",
       "Skew:                           1.715   Prob(JB):                         0.00\n",
       "Kurtosis:                       8.651   Cond. No.                         15.0\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nome_feature = 'LandContour'\n",
    "\n",
    "# Verificação de valores nulos na variável\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Estatística univariádas pela variável\n",
    "print('Verficação da disposição da variável em agurpamento:\\n')\n",
    "agrupado = dados_treino.groupby([nome_feature]).size()\n",
    "print(agrupado)\n",
    "\n",
    "# Conversão da variável categórica em dicotômica com a exclusão da primeira variável dicotômica.\n",
    "df_dummies_auxiliar = pd.get_dummies(dados_treino[nome_feature], columns=[nome_feature], drop_first=True)\n",
    "\n",
    "# Inclusão da variável dependente ao data frame de variáveis dicotômicas.\n",
    "df_dummies_auxiliar[nome_target] = dados_treino[nome_target].copy()\n",
    "\n",
    "# Verificação do data frame.\n",
    "df_dummies_auxiliar.head(6)\n",
    "\n",
    "# Estimação do modelo de regressão linear múltipla com n-1 dummies\n",
    "modelo_dummies = sm.OLS.from_formula(\"SalePrice ~ HLS + Low + Lvl\", df_dummies_auxiliar).fit()\n",
    "\n",
    "# Verificação dos parâmetros do modelo.\n",
    "modelo_dummies.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1c6819",
   "metadata": {},
   "source": [
    "## Utilities (Categórica)\n",
    "\n",
    "Tipo de utilitários disponíveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d525537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "Verficação da disposição da variável em agurpamento:\n",
      "\n",
      "Utilities\n",
      "AllPub    1167\n",
      "NoSeWa       1\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>SalePrice</td>    <th>  R-squared:         </th> <td>   0.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>  -0.001</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>  0.3235</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 05 Dec 2023</td> <th>  Prob (F-statistic):</th>  <td> 0.570</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>07:17:25</td>     <th>  Log-Likelihood:    </th> <td> -14802.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.961e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1166</td>      <th>  BIC:               </th> <td>2.962e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td> 1.815e+05</td> <td> 2262.379</td> <td>   80.216</td> <td> 0.000</td> <td> 1.77e+05</td> <td> 1.86e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NoSeWa</th>    <td>-4.398e+04</td> <td> 7.73e+04</td> <td>   -0.569</td> <td> 0.570</td> <td>-1.96e+05</td> <td> 1.08e+05</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>443.291</td> <th>  Durbin-Watson:     </th> <td>   2.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2034.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.740</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.448</td>  <th>  Cond. No.          </th> <td>    34.2</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              SalePrice   R-squared:                       0.000\n",
       "Model:                            OLS   Adj. R-squared:                 -0.001\n",
       "Method:                 Least Squares   F-statistic:                    0.3235\n",
       "Date:                Tue, 05 Dec 2023   Prob (F-statistic):              0.570\n",
       "Time:                        07:17:25   Log-Likelihood:                -14802.\n",
       "No. Observations:                1168   AIC:                         2.961e+04\n",
       "Df Residuals:                    1166   BIC:                         2.962e+04\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept   1.815e+05   2262.379     80.216      0.000    1.77e+05    1.86e+05\n",
       "NoSeWa     -4.398e+04   7.73e+04     -0.569      0.570   -1.96e+05    1.08e+05\n",
       "==============================================================================\n",
       "Omnibus:                      443.291   Durbin-Watson:                   2.033\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2034.029\n",
       "Skew:                           1.740   Prob(JB):                         0.00\n",
       "Kurtosis:                       8.448   Cond. No.                         34.2\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nome_feature = 'Utilities'\n",
    "\n",
    "# Verificação de valores nulos na variável\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Estatística univariádas pela variável\n",
    "print('Verficação da disposição da variável em agurpamento:\\n')\n",
    "agrupado = dados_treino.groupby([nome_feature]).size()\n",
    "print(agrupado)\n",
    "\n",
    "# Conversão da variável categórica em dicotômica com a exclusão da primeira variável dicotômica.\n",
    "df_dummies_auxiliar = pd.get_dummies(dados_treino[nome_feature], columns=[nome_feature], drop_first=True)\n",
    "\n",
    "# Inclusão da variável dependente ao data frame de variáveis dicotômicas.\n",
    "df_dummies_auxiliar[nome_target] = dados_treino[nome_target].copy()\n",
    "\n",
    "# Verificação do data frame.\n",
    "df_dummies_auxiliar.head(6)\n",
    "\n",
    "# Estimação do modelo de regressão linear múltipla com n-1 dummies\n",
    "modelo_dummies = sm.OLS.from_formula(\"SalePrice ~ NoSeWa\", df_dummies_auxiliar).fit()\n",
    "\n",
    "# Verificação dos parâmetros do modelo.\n",
    "modelo_dummies.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0989f2",
   "metadata": {},
   "source": [
    "## LotConfig (Categórica)\n",
    "\n",
    "Configuração do Lote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26ea0ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "Verficação da disposição da variável em agurpamento:\n",
      "\n",
      "LotConfig\n",
      "Corner     221\n",
      "CulDSac     84\n",
      "FR2         38\n",
      "FR3          3\n",
      "Inside     822\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>SalePrice</td>    <th>  R-squared:         </th> <td>   0.023</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.020</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   6.971</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 05 Dec 2023</td> <th>  Prob (F-statistic):</th> <td>1.52e-05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>07:17:25</td>     <th>  Log-Likelihood:    </th> <td> -14789.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.959e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1163</td>      <th>  BIC:               </th> <td>2.961e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td> 1.767e+05</td> <td> 5144.928</td> <td>   34.345</td> <td> 0.000</td> <td> 1.67e+05</td> <td> 1.87e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CulDSac</th>   <td> 4.654e+04</td> <td> 9803.690</td> <td>    4.747</td> <td> 0.000</td> <td> 2.73e+04</td> <td> 6.58e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FR2</th>       <td> 1633.7870</td> <td> 1.34e+04</td> <td>    0.122</td> <td> 0.903</td> <td>-2.47e+04</td> <td>  2.8e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FR3</th>       <td> 3.997e+04</td> <td> 4.45e+04</td> <td>    0.899</td> <td> 0.369</td> <td>-4.73e+04</td> <td> 1.27e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Inside</th>    <td> 1758.6229</td> <td> 5795.428</td> <td>    0.303</td> <td> 0.762</td> <td>-9612.041</td> <td> 1.31e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>438.875</td> <th>  Durbin-Watson:     </th> <td>   2.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1980.485</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.727</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.363</td>  <th>  Cond. No.          </th> <td>    24.9</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              SalePrice   R-squared:                       0.023\n",
       "Model:                            OLS   Adj. R-squared:                  0.020\n",
       "Method:                 Least Squares   F-statistic:                     6.971\n",
       "Date:                Tue, 05 Dec 2023   Prob (F-statistic):           1.52e-05\n",
       "Time:                        07:17:25   Log-Likelihood:                -14789.\n",
       "No. Observations:                1168   AIC:                         2.959e+04\n",
       "Df Residuals:                    1163   BIC:                         2.961e+04\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept   1.767e+05   5144.928     34.345      0.000    1.67e+05    1.87e+05\n",
       "CulDSac     4.654e+04   9803.690      4.747      0.000    2.73e+04    6.58e+04\n",
       "FR2         1633.7870   1.34e+04      0.122      0.903   -2.47e+04     2.8e+04\n",
       "FR3         3.997e+04   4.45e+04      0.899      0.369   -4.73e+04    1.27e+05\n",
       "Inside      1758.6229   5795.428      0.303      0.762   -9612.041    1.31e+04\n",
       "==============================================================================\n",
       "Omnibus:                      438.875   Durbin-Watson:                   2.037\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1980.485\n",
       "Skew:                           1.727   Prob(JB):                         0.00\n",
       "Kurtosis:                       8.363   Cond. No.                         24.9\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nome_feature = 'LotConfig'\n",
    "\n",
    "# Verificação de valores nulos na variável\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Estatística univariádas pela variável\n",
    "print('Verficação da disposição da variável em agurpamento:\\n')\n",
    "agrupado = dados_treino.groupby([nome_feature]).size()\n",
    "print(agrupado)\n",
    "\n",
    "# Conversão da variável categórica em dicotômica com a exclusão da primeira variável dicotômica.\n",
    "df_dummies_auxiliar = pd.get_dummies(dados_treino[nome_feature], columns=[nome_feature], drop_first=True)\n",
    "\n",
    "# Inclusão da variável dependente ao data frame de variáveis dicotômicas.\n",
    "df_dummies_auxiliar[nome_target] = dados_treino[nome_target].copy()\n",
    "\n",
    "# Verificação do data frame.\n",
    "df_dummies_auxiliar.head(6)\n",
    "\n",
    "# Estimação do modelo de regressão linear múltipla com n-1 dummies\n",
    "modelo_dummies = sm.OLS.from_formula(\"SalePrice ~ CulDSac + FR2 + FR3 + Inside\", df_dummies_auxiliar).fit()\n",
    "\n",
    "# Verificação dos parâmetros do modelo.\n",
    "modelo_dummies.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c917773",
   "metadata": {},
   "source": [
    "## LandSlope (Categórica)\n",
    "\n",
    "Inclinação da Propriedade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eddbd8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "Verficação da disposição da variável em agurpamento:\n",
      "\n",
      "LandSlope\n",
      "Gtl    1108\n",
      "Mod      51\n",
      "Sev       9\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>SalePrice</td>    <th>  R-squared:         </th> <td>   0.005</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.003</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   2.918</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 05 Dec 2023</td> <th>  Prob (F-statistic):</th>  <td>0.0544</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>07:17:25</td>     <th>  Log-Likelihood:    </th> <td> -14800.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.961e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1165</td>      <th>  BIC:               </th> <td>2.962e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td> 1.803e+05</td> <td> 2317.353</td> <td>   77.793</td> <td> 0.000</td> <td> 1.76e+05</td> <td> 1.85e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Mod</th>       <td> 1.877e+04</td> <td>  1.1e+04</td> <td>    1.699</td> <td> 0.090</td> <td>-2908.388</td> <td> 4.04e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sev</th>       <td> 4.516e+04</td> <td> 2.58e+04</td> <td>    1.749</td> <td> 0.080</td> <td>-5487.291</td> <td> 9.58e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>442.664</td> <th>  Durbin-Watson:     </th> <td>   2.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2061.157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.731</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.510</td>  <th>  Cond. No.          </th> <td>    11.5</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              SalePrice   R-squared:                       0.005\n",
       "Model:                            OLS   Adj. R-squared:                  0.003\n",
       "Method:                 Least Squares   F-statistic:                     2.918\n",
       "Date:                Tue, 05 Dec 2023   Prob (F-statistic):             0.0544\n",
       "Time:                        07:17:25   Log-Likelihood:                -14800.\n",
       "No. Observations:                1168   AIC:                         2.961e+04\n",
       "Df Residuals:                    1165   BIC:                         2.962e+04\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept   1.803e+05   2317.353     77.793      0.000    1.76e+05    1.85e+05\n",
       "Mod         1.877e+04    1.1e+04      1.699      0.090   -2908.388    4.04e+04\n",
       "Sev         4.516e+04   2.58e+04      1.749      0.080   -5487.291    9.58e+04\n",
       "==============================================================================\n",
       "Omnibus:                      442.664   Durbin-Watson:                   2.036\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2061.157\n",
       "Skew:                           1.731   Prob(JB):                         0.00\n",
       "Kurtosis:                       8.510   Cond. No.                         11.5\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nome_feature = 'LandSlope'\n",
    "\n",
    "# Verificação de valores nulos na variável\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Estatística univariádas pela variável\n",
    "print('Verficação da disposição da variável em agurpamento:\\n')\n",
    "agrupado = dados_treino.groupby([nome_feature]).size()\n",
    "print(agrupado)\n",
    "\n",
    "# Conversão da variável categórica em dicotômica com a exclusão da primeira variável dicotômica.\n",
    "df_dummies_auxiliar = pd.get_dummies(dados_treino[nome_feature], columns=[nome_feature], drop_first=True)\n",
    "\n",
    "# Inclusão da variável dependente ao data frame de variáveis dicotômicas.\n",
    "df_dummies_auxiliar[nome_target] = dados_treino[nome_target].copy()\n",
    "\n",
    "# Verificação do data frame.\n",
    "df_dummies_auxiliar.head(6)\n",
    "\n",
    "# Estimação do modelo de regressão linear múltipla com n-1 dummies\n",
    "modelo_dummies = sm.OLS.from_formula(\"SalePrice ~ Mod + Sev\", df_dummies_auxiliar).fit()\n",
    "\n",
    "# Verificação dos parâmetros do modelo.\n",
    "modelo_dummies.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842bd198",
   "metadata": {},
   "source": [
    "## Neighborhood (Categórica)\n",
    "\n",
    "Locais físicos dentro dos limites da cidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aef0680f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "Verficação da disposição da variável em agurpamento:\n",
      "\n",
      "Neighborhood\n",
      "Blmngtn     15\n",
      "Blueste      1\n",
      "BrDale      13\n",
      "BrkSide     45\n",
      "ClearCr     19\n",
      "CollgCr    115\n",
      "Crawfor     44\n",
      "Edwards     87\n",
      "Gilbert     65\n",
      "IDOTRR      26\n",
      "MeadowV     10\n",
      "Mitchel     40\n",
      "NAmes      181\n",
      "NPkVill      7\n",
      "NWAmes      66\n",
      "NoRidge     33\n",
      "NridgHt     61\n",
      "OldTown     91\n",
      "SWISU       21\n",
      "Sawyer      58\n",
      "SawyerW     44\n",
      "Somerst     69\n",
      "StoneBr     20\n",
      "Timber      28\n",
      "Veenker      9\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>SalePrice</td>    <th>  R-squared:         </th> <td>   0.530</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.521</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   58.69</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 05 Dec 2023</td> <th>  Prob (F-statistic):</th> <td>3.93e-170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>07:17:26</td>     <th>  Log-Likelihood:    </th> <td> -14362.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.877e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1145</td>      <th>  BIC:               </th> <td>2.889e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    22</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td> 1.862e+05</td> <td> 5700.635</td> <td>   32.671</td> <td> 0.000</td> <td> 1.75e+05</td> <td> 1.97e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Blueste</th>   <td>-6.225e+04</td> <td> 5.38e+04</td> <td>   -1.157</td> <td> 0.247</td> <td>-1.68e+05</td> <td> 4.33e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BrDale</th>    <td>-8.533e+04</td> <td> 1.59e+04</td> <td>   -5.370</td> <td> 0.000</td> <td>-1.17e+05</td> <td>-5.42e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BrkSide</th>   <td>-6.361e+04</td> <td> 9800.378</td> <td>   -6.490</td> <td> 0.000</td> <td>-8.28e+04</td> <td>-4.44e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ClearCr</th>   <td> 3.559e+04</td> <td> 1.35e+04</td> <td>    2.631</td> <td> 0.009</td> <td> 9051.854</td> <td> 6.21e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CollgCr</th>   <td> 1.486e+04</td> <td> 7573.948</td> <td>    1.963</td> <td> 0.050</td> <td>    4.123</td> <td> 2.97e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Crawfor</th>   <td> 2.534e+04</td> <td> 9873.790</td> <td>    2.566</td> <td> 0.010</td> <td> 5966.943</td> <td> 4.47e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Edwards</th>   <td>-5.834e+04</td> <td> 8085.049</td> <td>   -7.216</td> <td> 0.000</td> <td>-7.42e+04</td> <td>-4.25e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Gilbert</th>   <td> 1.029e+04</td> <td> 8746.057</td> <td>    1.177</td> <td> 0.239</td> <td>-6866.961</td> <td> 2.75e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>IDOTRR</th>    <td>-7.962e+04</td> <td> 1.19e+04</td> <td>   -6.670</td> <td> 0.000</td> <td>-1.03e+05</td> <td>-5.62e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MeadowV</th>   <td>-8.436e+04</td> <td> 1.78e+04</td> <td>   -4.727</td> <td> 0.000</td> <td>-1.19e+05</td> <td>-4.93e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Mitchel</th>   <td>-2.928e+04</td> <td> 1.02e+04</td> <td>   -2.871</td> <td> 0.004</td> <td>-4.93e+04</td> <td>-9271.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NAmes</th>     <td>-3.884e+04</td> <td> 6949.605</td> <td>   -5.589</td> <td> 0.000</td> <td>-5.25e+04</td> <td>-2.52e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NoRidge</th>   <td> 1.369e+05</td> <td> 1.09e+04</td> <td>   12.545</td> <td> 0.000</td> <td> 1.16e+05</td> <td> 1.58e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NridgHt</th>   <td> 1.259e+05</td> <td> 8909.462</td> <td>   14.132</td> <td> 0.000</td> <td> 1.08e+05</td> <td> 1.43e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OldTown</th>   <td>-5.336e+04</td> <td> 7995.195</td> <td>   -6.674</td> <td> 0.000</td> <td> -6.9e+04</td> <td>-3.77e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SWISU</th>     <td>-4.142e+04</td> <td>  1.3e+04</td> <td>   -3.190</td> <td> 0.001</td> <td>-6.69e+04</td> <td>-1.59e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sawyer</th>    <td>-4.938e+04</td> <td> 9044.523</td> <td>   -5.460</td> <td> 0.000</td> <td>-6.71e+04</td> <td>-3.16e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SawyerW</th>   <td>-5789.9205</td> <td> 9873.790</td> <td>   -0.586</td> <td> 0.558</td> <td>-2.52e+04</td> <td> 1.36e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Somerst</th>   <td> 4.016e+04</td> <td> 8599.011</td> <td>    4.670</td> <td> 0.000</td> <td> 2.33e+04</td> <td>  5.7e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>StoneBr</th>   <td> 1.164e+05</td> <td> 1.32e+04</td> <td>    8.784</td> <td> 0.000</td> <td> 9.04e+04</td> <td> 1.42e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Timber</th>    <td> 4.989e+04</td> <td> 1.16e+04</td> <td>    4.300</td> <td> 0.000</td> <td> 2.71e+04</td> <td> 7.27e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Veenker</th>   <td>  6.57e+04</td> <td> 1.87e+04</td> <td>    3.510</td> <td> 0.000</td> <td>  2.9e+04</td> <td> 1.02e+05</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>462.641</td> <th>  Durbin-Watson:     </th> <td>   2.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3513.155</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.636</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>10.841</td>  <th>  Cond. No.          </th> <td>    35.6</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              SalePrice   R-squared:                       0.530\n",
       "Model:                            OLS   Adj. R-squared:                  0.521\n",
       "Method:                 Least Squares   F-statistic:                     58.69\n",
       "Date:                Tue, 05 Dec 2023   Prob (F-statistic):          3.93e-170\n",
       "Time:                        07:17:26   Log-Likelihood:                -14362.\n",
       "No. Observations:                1168   AIC:                         2.877e+04\n",
       "Df Residuals:                    1145   BIC:                         2.889e+04\n",
       "Df Model:                          22                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept   1.862e+05   5700.635     32.671      0.000    1.75e+05    1.97e+05\n",
       "Blueste    -6.225e+04   5.38e+04     -1.157      0.247   -1.68e+05    4.33e+04\n",
       "BrDale     -8.533e+04   1.59e+04     -5.370      0.000   -1.17e+05   -5.42e+04\n",
       "BrkSide    -6.361e+04   9800.378     -6.490      0.000   -8.28e+04   -4.44e+04\n",
       "ClearCr     3.559e+04   1.35e+04      2.631      0.009    9051.854    6.21e+04\n",
       "CollgCr     1.486e+04   7573.948      1.963      0.050       4.123    2.97e+04\n",
       "Crawfor     2.534e+04   9873.790      2.566      0.010    5966.943    4.47e+04\n",
       "Edwards    -5.834e+04   8085.049     -7.216      0.000   -7.42e+04   -4.25e+04\n",
       "Gilbert     1.029e+04   8746.057      1.177      0.239   -6866.961    2.75e+04\n",
       "IDOTRR     -7.962e+04   1.19e+04     -6.670      0.000   -1.03e+05   -5.62e+04\n",
       "MeadowV    -8.436e+04   1.78e+04     -4.727      0.000   -1.19e+05   -4.93e+04\n",
       "Mitchel    -2.928e+04   1.02e+04     -2.871      0.004   -4.93e+04   -9271.021\n",
       "NAmes      -3.884e+04   6949.605     -5.589      0.000   -5.25e+04   -2.52e+04\n",
       "NoRidge     1.369e+05   1.09e+04     12.545      0.000    1.16e+05    1.58e+05\n",
       "NridgHt     1.259e+05   8909.462     14.132      0.000    1.08e+05    1.43e+05\n",
       "OldTown    -5.336e+04   7995.195     -6.674      0.000    -6.9e+04   -3.77e+04\n",
       "SWISU      -4.142e+04    1.3e+04     -3.190      0.001   -6.69e+04   -1.59e+04\n",
       "Sawyer     -4.938e+04   9044.523     -5.460      0.000   -6.71e+04   -3.16e+04\n",
       "SawyerW    -5789.9205   9873.790     -0.586      0.558   -2.52e+04    1.36e+04\n",
       "Somerst     4.016e+04   8599.011      4.670      0.000    2.33e+04     5.7e+04\n",
       "StoneBr     1.164e+05   1.32e+04      8.784      0.000    9.04e+04    1.42e+05\n",
       "Timber      4.989e+04   1.16e+04      4.300      0.000    2.71e+04    7.27e+04\n",
       "Veenker      6.57e+04   1.87e+04      3.510      0.000     2.9e+04    1.02e+05\n",
       "==============================================================================\n",
       "Omnibus:                      462.641   Durbin-Watson:                   2.093\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3513.155\n",
       "Skew:                           1.636   Prob(JB):                         0.00\n",
       "Kurtosis:                      10.841   Cond. No.                         35.6\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nome_feature = 'Neighborhood'\n",
    "\n",
    "# Verificação de valores nulos na variável\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Estatística univariádas pela variável\n",
    "print('Verficação da disposição da variável em agurpamento:\\n')\n",
    "agrupado = dados_treino.groupby([nome_feature]).size()\n",
    "print(agrupado)\n",
    "\n",
    "# Conversão da variável categórica em dicotômica com a exclusão da primeira variável dicotômica.\n",
    "df_dummies_auxiliar = pd.get_dummies(dados_treino[nome_feature], columns=[nome_feature], drop_first=True)\n",
    "\n",
    "# Inclusão da variável dependente ao data frame de variáveis dicotômicas.\n",
    "df_dummies_auxiliar[nome_target] = dados_treino[nome_target].copy()\n",
    "\n",
    "# Verificação do data frame.\n",
    "df_dummies_auxiliar.head(6)\n",
    "\n",
    "# Estimação do modelo de regressão linear múltipla com n-1 dummies\n",
    "modelo_dummies = sm.OLS.from_formula(\"SalePrice ~ Blueste + BrDale + BrkSide + ClearCr + CollgCr + Crawfor + Edwards + Gilbert + IDOTRR + MeadowV + Mitchel + NAmes + NoRidge + NridgHt + OldTown + SWISU + Sawyer + SawyerW + Somerst + StoneBr + Timber + Veenker\", df_dummies_auxiliar).fit()\n",
    "\n",
    "# Verificação dos parâmetros do modelo.\n",
    "modelo_dummies.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f22bcd8",
   "metadata": {},
   "source": [
    "## Condition1 (Categórica)\n",
    "\n",
    "Proximidade com pontos de referências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e7915c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "Verficação da disposição da variável em agurpamento:\n",
      "\n",
      "Condition1\n",
      "Artery      40\n",
      "Feedr       66\n",
      "Norm      1004\n",
      "PosA         8\n",
      "PosN        15\n",
      "RRAe        10\n",
      "RRAn        19\n",
      "RRNe         1\n",
      "RRNn         5\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>SalePrice</td>    <th>  R-squared:         </th> <td>   0.036</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.029</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   5.414</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 05 Dec 2023</td> <th>  Prob (F-statistic):</th> <td>1.03e-06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>07:17:26</td>     <th>  Log-Likelihood:    </th> <td> -14781.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.958e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1159</td>      <th>  BIC:               </th> <td>2.963e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     8</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td> 1.399e+05</td> <td>  1.2e+04</td> <td>   11.621</td> <td> 0.000</td> <td> 1.16e+05</td> <td> 1.63e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Feedr</th>     <td> 2042.9242</td> <td> 1.53e+04</td> <td>    0.134</td> <td> 0.893</td> <td>-2.79e+04</td> <td>  3.2e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Norm</th>      <td> 4.477e+04</td> <td> 1.23e+04</td> <td>    3.648</td> <td> 0.000</td> <td> 2.07e+04</td> <td> 6.89e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PosA</th>      <td> 8.601e+04</td> <td> 2.95e+04</td> <td>    2.917</td> <td> 0.004</td> <td> 2.82e+04</td> <td> 1.44e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PosN</th>      <td> 8.295e+04</td> <td>  2.3e+04</td> <td>    3.599</td> <td> 0.000</td> <td> 3.77e+04</td> <td> 1.28e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RRAe</th>      <td> 1175.0000</td> <td> 2.69e+04</td> <td>    0.044</td> <td> 0.965</td> <td>-5.16e+04</td> <td>  5.4e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RRAn</th>      <td> 5.909e+04</td> <td> 2.12e+04</td> <td>    2.786</td> <td> 0.005</td> <td> 1.75e+04</td> <td> 1.01e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RRNe</th>      <td> 4.713e+04</td> <td> 7.71e+04</td> <td>    0.612</td> <td> 0.541</td> <td>-1.04e+05</td> <td> 1.98e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RRNn</th>      <td> 7.253e+04</td> <td> 3.61e+04</td> <td>    2.009</td> <td> 0.045</td> <td> 1692.466</td> <td> 1.43e+05</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>457.209</td> <th>  Durbin-Watson:     </th> <td>   2.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2267.567</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.771</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.835</td>  <th>  Cond. No.          </th> <td>    46.5</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              SalePrice   R-squared:                       0.036\n",
       "Model:                            OLS   Adj. R-squared:                  0.029\n",
       "Method:                 Least Squares   F-statistic:                     5.414\n",
       "Date:                Tue, 05 Dec 2023   Prob (F-statistic):           1.03e-06\n",
       "Time:                        07:17:26   Log-Likelihood:                -14781.\n",
       "No. Observations:                1168   AIC:                         2.958e+04\n",
       "Df Residuals:                    1159   BIC:                         2.963e+04\n",
       "Df Model:                           8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept   1.399e+05    1.2e+04     11.621      0.000    1.16e+05    1.63e+05\n",
       "Feedr       2042.9242   1.53e+04      0.134      0.893   -2.79e+04     3.2e+04\n",
       "Norm        4.477e+04   1.23e+04      3.648      0.000    2.07e+04    6.89e+04\n",
       "PosA        8.601e+04   2.95e+04      2.917      0.004    2.82e+04    1.44e+05\n",
       "PosN        8.295e+04    2.3e+04      3.599      0.000    3.77e+04    1.28e+05\n",
       "RRAe        1175.0000   2.69e+04      0.044      0.965   -5.16e+04     5.4e+04\n",
       "RRAn        5.909e+04   2.12e+04      2.786      0.005    1.75e+04    1.01e+05\n",
       "RRNe        4.713e+04   7.71e+04      0.612      0.541   -1.04e+05    1.98e+05\n",
       "RRNn        7.253e+04   3.61e+04      2.009      0.045    1692.466    1.43e+05\n",
       "==============================================================================\n",
       "Omnibus:                      457.209   Durbin-Watson:                   2.034\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2267.567\n",
       "Skew:                           1.771   Prob(JB):                         0.00\n",
       "Kurtosis:                       8.835   Cond. No.                         46.5\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nome_feature = 'Condition1'\n",
    "\n",
    "# Verificação de valores nulos na variável\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Estatística univariádas pela variável\n",
    "print('Verficação da disposição da variável em agurpamento:\\n')\n",
    "agrupado = dados_treino.groupby([nome_feature]).size()\n",
    "print(agrupado)\n",
    "\n",
    "# Conversão da variável categórica em dicotômica com a exclusão da primeira variável dicotômica.\n",
    "df_dummies_auxiliar = pd.get_dummies(dados_treino[nome_feature], columns=[nome_feature], drop_first=True)\n",
    "\n",
    "# Inclusão da variável dependente ao data frame de variáveis dicotômicas.\n",
    "df_dummies_auxiliar[nome_target] = dados_treino[nome_target].copy()\n",
    "\n",
    "# Verificação do data frame.\n",
    "df_dummies_auxiliar.head(6)\n",
    "\n",
    "# Estimação do modelo de regressão linear múltipla com n-1 dummies\n",
    "modelo_dummies = sm.OLS.from_formula(\"SalePrice ~ Feedr + Norm + PosA + PosN + RRAe + RRAn + RRNe + RRNn\", df_dummies_auxiliar).fit()\n",
    "\n",
    "# Verificação dos parâmetros do modelo.\n",
    "modelo_dummies.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e61cab0",
   "metadata": {},
   "source": [
    "## Condition2 (Categórica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ebbc19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "Verficação da disposição da variável em agurpamento:\n",
      "\n",
      "Condition2\n",
      "Artery       2\n",
      "Feedr        3\n",
      "Norm      1157\n",
      "PosA         1\n",
      "PosN         2\n",
      "RRAe         1\n",
      "RRAn         1\n",
      "RRNn         1\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>SalePrice</td>    <th>  R-squared:         </th> <td>   0.010</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.004</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1.620</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 05 Dec 2023</td> <th>  Prob (F-statistic):</th>  <td> 0.126</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>07:17:26</td>     <th>  Log-Likelihood:    </th> <td> -14797.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.961e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1160</td>      <th>  BIC:               </th> <td>2.965e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     7</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td> 1.065e+05</td> <td> 5.45e+04</td> <td>    1.953</td> <td> 0.051</td> <td> -493.094</td> <td> 2.13e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Feedr</th>     <td> 2.033e+04</td> <td> 7.04e+04</td> <td>    0.289</td> <td> 0.773</td> <td>-1.18e+05</td> <td> 1.58e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Norm</th>      <td> 7.499e+04</td> <td> 5.46e+04</td> <td>    1.374</td> <td> 0.170</td> <td>-3.21e+04</td> <td> 1.82e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PosA</th>      <td> 2.185e+05</td> <td> 9.45e+04</td> <td>    2.313</td> <td> 0.021</td> <td> 3.32e+04</td> <td> 4.04e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PosN</th>      <td> 1.784e+05</td> <td> 7.71e+04</td> <td>    2.313</td> <td> 0.021</td> <td> 2.71e+04</td> <td>  3.3e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RRAe</th>      <td>  8.35e+04</td> <td> 9.45e+04</td> <td>    0.884</td> <td> 0.377</td> <td>-1.02e+05</td> <td> 2.69e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RRAn</th>      <td> 3.041e+04</td> <td> 9.45e+04</td> <td>    0.322</td> <td> 0.748</td> <td>-1.55e+05</td> <td> 2.16e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RRNn</th>      <td>  1.85e+04</td> <td> 9.45e+04</td> <td>    0.196</td> <td> 0.845</td> <td>-1.67e+05</td> <td> 2.04e+05</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>446.873</td> <th>  Durbin-Watson:     </th> <td>   2.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2096.833</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.747</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.556</td>  <th>  Cond. No.          </th> <td>    104.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              SalePrice   R-squared:                       0.010\n",
       "Model:                            OLS   Adj. R-squared:                  0.004\n",
       "Method:                 Least Squares   F-statistic:                     1.620\n",
       "Date:                Tue, 05 Dec 2023   Prob (F-statistic):              0.126\n",
       "Time:                        07:17:26   Log-Likelihood:                -14797.\n",
       "No. Observations:                1168   AIC:                         2.961e+04\n",
       "Df Residuals:                    1160   BIC:                         2.965e+04\n",
       "Df Model:                           7                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept   1.065e+05   5.45e+04      1.953      0.051    -493.094    2.13e+05\n",
       "Feedr       2.033e+04   7.04e+04      0.289      0.773   -1.18e+05    1.58e+05\n",
       "Norm        7.499e+04   5.46e+04      1.374      0.170   -3.21e+04    1.82e+05\n",
       "PosA        2.185e+05   9.45e+04      2.313      0.021    3.32e+04    4.04e+05\n",
       "PosN        1.784e+05   7.71e+04      2.313      0.021    2.71e+04     3.3e+05\n",
       "RRAe         8.35e+04   9.45e+04      0.884      0.377   -1.02e+05    2.69e+05\n",
       "RRAn        3.041e+04   9.45e+04      0.322      0.748   -1.55e+05    2.16e+05\n",
       "RRNn         1.85e+04   9.45e+04      0.196      0.845   -1.67e+05    2.04e+05\n",
       "==============================================================================\n",
       "Omnibus:                      446.873   Durbin-Watson:                   2.027\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2096.833\n",
       "Skew:                           1.747   Prob(JB):                         0.00\n",
       "Kurtosis:                       8.556   Cond. No.                         104.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nome_feature = 'Condition2'\n",
    "\n",
    "# Verificação de valores nulos na variável\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Estatística univariádas pela variável\n",
    "print('Verficação da disposição da variável em agurpamento:\\n')\n",
    "agrupado = dados_treino.groupby([nome_feature]).size()\n",
    "print(agrupado)\n",
    "\n",
    "# Conversão da variável categórica em dicotômica com a exclusão da primeira variável dicotômica.\n",
    "df_dummies_auxiliar = pd.get_dummies(dados_treino[nome_feature], columns=[nome_feature], drop_first=True)\n",
    "\n",
    "# Inclusão da variável dependente ao data frame de variáveis dicotômicas.\n",
    "df_dummies_auxiliar[nome_target] = dados_treino[nome_target].copy()\n",
    "\n",
    "# Verificação do data frame.\n",
    "df_dummies_auxiliar.head(6)\n",
    "\n",
    "# Estimação do modelo de regressão linear múltipla com n-1 dummies\n",
    "modelo_dummies = sm.OLS.from_formula(\"SalePrice ~ Feedr + Norm + PosA + PosN + RRAe + RRAn + RRNn\", df_dummies_auxiliar).fit()\n",
    "\n",
    "# Verificação dos parâmetros do modelo.\n",
    "modelo_dummies.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb00339",
   "metadata": {},
   "source": [
    "## BldgType (Categórica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "470e4fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "Verficação da disposição da variável em agurpamento:\n",
      "\n",
      "BldgType\n",
      "1Fam      978\n",
      "2fmCon     29\n",
      "Duplex     41\n",
      "Twnhs      32\n",
      "TwnhsE     88\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>SalePrice</td>    <th>  R-squared:         </th> <td>   0.036</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.033</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   10.93</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 05 Dec 2023</td> <th>  Prob (F-statistic):</th> <td>1.06e-08</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>07:17:26</td>     <th>  Log-Likelihood:    </th> <td> -14781.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.957e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1163</td>      <th>  BIC:               </th> <td>2.960e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>   <td> 1.861e+05</td> <td> 2429.623</td> <td>   76.610</td> <td> 0.000</td> <td> 1.81e+05</td> <td> 1.91e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q('2fmCon')</th> <td>-5.755e+04</td> <td> 1.43e+04</td> <td>   -4.020</td> <td> 0.000</td> <td>-8.56e+04</td> <td>-2.95e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Duplex</th>      <td>-5.025e+04</td> <td> 1.21e+04</td> <td>   -4.149</td> <td> 0.000</td> <td> -7.4e+04</td> <td>-2.65e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Twnhs</th>       <td>-4.942e+04</td> <td> 1.36e+04</td> <td>   -3.621</td> <td> 0.000</td> <td>-7.62e+04</td> <td>-2.26e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TwnhsE</th>      <td>-1926.4400</td> <td> 8456.219</td> <td>   -0.228</td> <td> 0.820</td> <td>-1.85e+04</td> <td> 1.47e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>441.685</td> <th>  Durbin-Watson:     </th> <td>   2.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2102.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.718</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.602</td>  <th>  Cond. No.          </th> <td>    6.52</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              SalePrice   R-squared:                       0.036\n",
       "Model:                            OLS   Adj. R-squared:                  0.033\n",
       "Method:                 Least Squares   F-statistic:                     10.93\n",
       "Date:                Tue, 05 Dec 2023   Prob (F-statistic):           1.06e-08\n",
       "Time:                        07:17:26   Log-Likelihood:                -14781.\n",
       "No. Observations:                1168   AIC:                         2.957e+04\n",
       "Df Residuals:                    1163   BIC:                         2.960e+04\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "Intercept    1.861e+05   2429.623     76.610      0.000    1.81e+05    1.91e+05\n",
       "Q('2fmCon') -5.755e+04   1.43e+04     -4.020      0.000   -8.56e+04   -2.95e+04\n",
       "Duplex      -5.025e+04   1.21e+04     -4.149      0.000    -7.4e+04   -2.65e+04\n",
       "Twnhs       -4.942e+04   1.36e+04     -3.621      0.000   -7.62e+04   -2.26e+04\n",
       "TwnhsE      -1926.4400   8456.219     -0.228      0.820   -1.85e+04    1.47e+04\n",
       "==============================================================================\n",
       "Omnibus:                      441.685   Durbin-Watson:                   2.050\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2102.068\n",
       "Skew:                           1.718   Prob(JB):                         0.00\n",
       "Kurtosis:                       8.602   Cond. No.                         6.52\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nome_feature = 'BldgType'\n",
    "\n",
    "# Verificação de valores nulos na variável\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Estatística univariádas pela variável\n",
    "print('Verficação da disposição da variável em agurpamento:\\n')\n",
    "agrupado = dados_treino.groupby([nome_feature]).size()\n",
    "print(agrupado)\n",
    "\n",
    "# Conversão da variável categórica em dicotômica com a exclusão da primeira variável dicotômica.\n",
    "df_dummies_auxiliar = pd.get_dummies(dados_treino[nome_feature], columns=[nome_feature], drop_first=True)\n",
    "\n",
    "# Inclusão da variável dependente ao data frame de variáveis dicotômicas.\n",
    "df_dummies_auxiliar[nome_target] = dados_treino[nome_target].copy()\n",
    "\n",
    "# Verificação do data frame.\n",
    "df_dummies_auxiliar.head(6)\n",
    "\n",
    "# Estimação do modelo de regressão linear múltipla com n-1 dummies\n",
    "modelo_dummies = sm.OLS.from_formula(\"SalePrice ~ Q('2fmCon') + Duplex + Twnhs + TwnhsE\", df_dummies_auxiliar).fit()\n",
    "\n",
    "# Verificação dos parâmetros do modelo.\n",
    "modelo_dummies.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9036614",
   "metadata": {},
   "source": [
    "## HouseStyle (Categórica)\n",
    "\n",
    "**Estilo da moradia.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e788aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "Verficação da disposição da variável em agurpamento:\n",
      "\n",
      "HouseStyle\n",
      "1.5Fin    121\n",
      "1.5Unf     12\n",
      "1Story    577\n",
      "2.5Fin      7\n",
      "2.5Unf     11\n",
      "2Story    360\n",
      "SFoyer     28\n",
      "SLvl       52\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>SalePrice</td>    <th>  R-squared:         </th> <td>   0.090</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.085</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   16.45</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 05 Dec 2023</td> <th>  Prob (F-statistic):</th> <td>9.18e-21</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>07:17:26</td>     <th>  Log-Likelihood:    </th> <td> -14747.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.951e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1160</td>      <th>  BIC:               </th> <td>2.955e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     7</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>   <td> 1.416e+05</td> <td> 6719.559</td> <td>   21.066</td> <td> 0.000</td> <td> 1.28e+05</td> <td> 1.55e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q('1.5Unf')</th> <td>-3.265e+04</td> <td> 2.24e+04</td> <td>   -1.459</td> <td> 0.145</td> <td>-7.65e+04</td> <td> 1.12e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q('1Story')</th> <td>  3.56e+04</td> <td> 7390.615</td> <td>    4.817</td> <td> 0.000</td> <td> 2.11e+04</td> <td> 5.01e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q('2.5Fin')</th> <td> 9.502e+04</td> <td> 2.87e+04</td> <td>    3.307</td> <td> 0.001</td> <td> 3.86e+04</td> <td> 1.51e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q('2.5Unf')</th> <td>  1.58e+04</td> <td> 2.33e+04</td> <td>    0.679</td> <td> 0.497</td> <td>-2.99e+04</td> <td> 6.15e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q('2Story')</th> <td> 6.764e+04</td> <td> 7767.157</td> <td>    8.708</td> <td> 0.000</td> <td> 5.24e+04</td> <td> 8.29e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SFoyer</th>      <td> -271.4354</td> <td> 1.55e+04</td> <td>   -0.018</td> <td> 0.986</td> <td>-3.07e+04</td> <td> 3.01e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SLvl</th>        <td> 2.423e+04</td> <td> 1.23e+04</td> <td>    1.977</td> <td> 0.048</td> <td>  184.377</td> <td> 4.83e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>450.157</td> <th>  Durbin-Watson:     </th> <td>   2.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2178.492</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.749</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.703</td>  <th>  Cond. No.          </th> <td>    16.0</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              SalePrice   R-squared:                       0.090\n",
       "Model:                            OLS   Adj. R-squared:                  0.085\n",
       "Method:                 Least Squares   F-statistic:                     16.45\n",
       "Date:                Tue, 05 Dec 2023   Prob (F-statistic):           9.18e-21\n",
       "Time:                        07:17:26   Log-Likelihood:                -14747.\n",
       "No. Observations:                1168   AIC:                         2.951e+04\n",
       "Df Residuals:                    1160   BIC:                         2.955e+04\n",
       "Df Model:                           7                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "Intercept    1.416e+05   6719.559     21.066      0.000    1.28e+05    1.55e+05\n",
       "Q('1.5Unf') -3.265e+04   2.24e+04     -1.459      0.145   -7.65e+04    1.12e+04\n",
       "Q('1Story')   3.56e+04   7390.615      4.817      0.000    2.11e+04    5.01e+04\n",
       "Q('2.5Fin')  9.502e+04   2.87e+04      3.307      0.001    3.86e+04    1.51e+05\n",
       "Q('2.5Unf')   1.58e+04   2.33e+04      0.679      0.497   -2.99e+04    6.15e+04\n",
       "Q('2Story')  6.764e+04   7767.157      8.708      0.000    5.24e+04    8.29e+04\n",
       "SFoyer       -271.4354   1.55e+04     -0.018      0.986   -3.07e+04    3.01e+04\n",
       "SLvl         2.423e+04   1.23e+04      1.977      0.048     184.377    4.83e+04\n",
       "==============================================================================\n",
       "Omnibus:                      450.157   Durbin-Watson:                   2.022\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2178.492\n",
       "Skew:                           1.749   Prob(JB):                         0.00\n",
       "Kurtosis:                       8.703   Cond. No.                         16.0\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nome_feature = 'HouseStyle'\n",
    "\n",
    "# Verificação de valores nulos na variável\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Estatística univariádas pela variável\n",
    "print('Verficação da disposição da variável em agurpamento:\\n')\n",
    "agrupado = dados_treino.groupby([nome_feature]).size()\n",
    "print(agrupado)\n",
    "\n",
    "# Conversão da variável categórica em dicotômica com a exclusão da primeira variável dicotômica.\n",
    "df_dummies_auxiliar = pd.get_dummies(dados_treino[nome_feature], columns=[nome_feature], drop_first=True)\n",
    "\n",
    "# Inclusão da variável dependente ao data frame de variáveis dicotômicas.\n",
    "df_dummies_auxiliar[nome_target] = dados_treino[nome_target].copy()\n",
    "\n",
    "# Verificação do data frame.\n",
    "df_dummies_auxiliar.head(6)\n",
    "\n",
    "# Estimação do modelo de regressão linear múltipla com n-1 dummies\n",
    "modelo_dummies = sm.OLS.from_formula(\"SalePrice ~ Q('1.5Unf') + Q('1Story') + Q('2.5Fin') + Q('2.5Unf') + Q('2Story') + SFoyer + SLvl\", df_dummies_auxiliar).fit()\n",
    "\n",
    "# Verificação dos parâmetros do modelo.\n",
    "modelo_dummies.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8135d1a",
   "metadata": {},
   "source": [
    "## OverallQual (Numérica)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c7d3458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "\n",
      "Correlação entre OverallQual e SalePrice\n",
      "\n",
      "             OverallQual  SalePrice\n",
      "OverallQual     1.000000   0.785555\n",
      "SalePrice       0.785555   1.000000\n",
      "\n",
      "Correlação entre ln<OverallQual> e ln<SalePrice>\n",
      "\n",
      "             OverallQual  SalePrice\n",
      "OverallQual     1.000000   0.783082\n",
      "SalePrice       0.783082   1.000000\n",
      "\n",
      "Correlação entre OverallQual e SalePrice SEM OUTLIER\n",
      "\n",
      "             OverallQual  SalePrice\n",
      "OverallQual     1.000000   0.784402\n",
      "SalePrice       0.784402   1.000000\n",
      "\n",
      "Correlação entre ln<OverallQual> e ln<SalePrice> SEM OUTLIER\n",
      "\n",
      "             OverallQual  SalePrice\n",
      "OverallQual     1.000000   0.780921\n",
      "SalePrice       0.780921   1.000000\n",
      "\n",
      "Quantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "\n",
      "Quantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nome_feature = 'OverallQual'\n",
    "\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# # Substituição de valores não válidos pela mediana da variável em ambos os data frames.\n",
    "# dados_treino[nome_feature].fillna(dados_treino[nome_feature].median(), inplace = True)\n",
    "# df_sem_outlier[nome_feature].fillna(df_sem_outlier[nome_feature].median(), inplace = True)\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target}\\n\")\n",
    "print(dados_treino[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}>\\n\")\n",
    "\n",
    "df_ln[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores maiores que mediana + 3 vezes o desvio padrão.\n",
    "med = df_sem_outlier[nome_feature].median()\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] >= (df_sem_outlier[nome_feature].median() + 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores MENOR que mediana - 3 vezes o desvio padrão.\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] <= (df_sem_outlier[nome_feature].median() - 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target} SEM OUTLIER\\n\")\n",
    "print(df_sem_outlier[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}> SEM OUTLIER\\n\")\n",
    "\n",
    "df_ln_sem_outlier[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln_sem_outlier[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln_sem_outlier[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ARMAZENAMENTO DAS FEATURES CASO SEJAM UTILIZADAS NO MODELO DE REGRESSÃO LINEAR.\n",
    "\n",
    "# Armazenamento da feature não transformada.\n",
    "features_numericas[nome_feature] = dados_treino[nome_feature]\n",
    "\n",
    "# Armezenamento da feature transformada com ln.\n",
    "features_ln_numericas[nome_feature] = df_ln[nome_feature]\n",
    "\n",
    "# Armazenamento da feature não transformada.\n",
    "features_numericas_sem_outlier[nome_feature] = df_sem_outlier[nome_feature]\n",
    "\n",
    "# Armezenamento da feature transformada com ln.\n",
    "features_ln_numericas_sem_outlier[nome_feature] = df_ln_sem_outlier[nome_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36239648",
   "metadata": {},
   "source": [
    "## OverallCond (Numérica)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02a2f030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "\n",
      "Correlação entre OverallCond e SalePrice\n",
      "\n",
      "             OverallCond  SalePrice\n",
      "OverallCond     1.000000  -0.074391\n",
      "SalePrice      -0.074391   1.000000\n",
      "\n",
      "Correlação entre ln<OverallCond> e ln<SalePrice>\n",
      "\n",
      "             OverallCond  SalePrice\n",
      "OverallCond     1.000000   0.008687\n",
      "SalePrice       0.008687   1.000000\n",
      "\n",
      "Correlação entre OverallCond e SalePrice SEM OUTLIER\n",
      "\n",
      "             OverallCond  SalePrice\n",
      "OverallCond     1.000000  -0.115216\n",
      "SalePrice      -0.115216   1.000000\n",
      "\n",
      "Correlação entre ln<OverallCond> e ln<SalePrice> SEM OUTLIER\n",
      "\n",
      "             OverallCond  SalePrice\n",
      "OverallCond     1.000000  -0.031341\n",
      "SalePrice      -0.031341   1.000000\n",
      "\n",
      "Quantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "\n",
      "Quantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nome_feature = 'OverallCond'\n",
    "\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# # Substituição de valores não válidos pela mediana da variável em ambos os data frames.\n",
    "# dados_treino[nome_feature].fillna(dados_treino[nome_feature].median(), inplace = True)\n",
    "# df_sem_outlier[nome_feature].fillna(df_sem_outlier[nome_feature].median(), inplace = True)\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target}\\n\")\n",
    "print(dados_treino[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}>\\n\")\n",
    "\n",
    "df_ln[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores maiores que mediana + 3 vezes o desvio padrão.\n",
    "med = df_sem_outlier[nome_feature].median()\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] >= (df_sem_outlier[nome_feature].median() + 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores MENOR que mediana - 3 vezes o desvio padrão.\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] <= (df_sem_outlier[nome_feature].median() - 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target} SEM OUTLIER\\n\")\n",
    "print(df_sem_outlier[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}> SEM OUTLIER\\n\")\n",
    "\n",
    "df_ln_sem_outlier[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln_sem_outlier[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln_sem_outlier[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# # ARMAZENAMENTO DAS FEATURES CASO SEJAM UTILIZADAS NO MODELO DE REGRESSÃO LINEAR.\n",
    "\n",
    "# # Armazenamento da feature não transformada.\n",
    "# features_numericas[nome_feature] = dados_treino[nome_feature]\n",
    "\n",
    "# # Armezenamento da feature transformada com ln.\n",
    "# features_ln_numericas[nome_feature] = df_ln[nome_feature]\n",
    "\n",
    "# # Armazenamento da feature não transformada.\n",
    "# features_numericas_sem_outlier[nome_feature] = df_sem_outlier[nome_feature]\n",
    "\n",
    "# # Armezenamento da feature transformada com ln.\n",
    "# features_ln_numericas_sem_outlier[nome_feature] = df_ln_sem_outlier[nome_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b388b7e1",
   "metadata": {},
   "source": [
    "## YearBuilt (Numérica)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c73d20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "\n",
      "Correlação entre YearBuilt e SalePrice\n",
      "\n",
      "           YearBuilt  SalePrice\n",
      "YearBuilt   1.000000   0.516501\n",
      "SalePrice   0.516501   1.000000\n",
      "\n",
      "Correlação entre ln<YearBuilt> e ln<SalePrice>\n",
      "\n",
      "           YearBuilt  SalePrice\n",
      "YearBuilt   1.000000   0.574521\n",
      "SalePrice   0.574521   1.000000\n",
      "\n",
      "Correlação entre YearBuilt e SalePrice SEM OUTLIER\n",
      "\n",
      "           YearBuilt  SalePrice\n",
      "YearBuilt   1.000000   0.515775\n",
      "SalePrice   0.515775   1.000000\n",
      "\n",
      "Correlação entre ln<YearBuilt> e ln<SalePrice> SEM OUTLIER\n",
      "\n",
      "           YearBuilt  SalePrice\n",
      "YearBuilt   1.000000   0.573265\n",
      "SalePrice   0.573265   1.000000\n",
      "\n",
      "Quantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "\n",
      "Quantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nome_feature = 'YearBuilt'\n",
    "\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# # Substituição de valores não válidos pela mediana da variável em ambos os data frames.\n",
    "# dados_treino[nome_feature].fillna(dados_treino[nome_feature].median(), inplace = True)\n",
    "# df_sem_outlier[nome_feature].fillna(df_sem_outlier[nome_feature].median(), inplace = True)\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target}\\n\")\n",
    "print(dados_treino[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}>\\n\")\n",
    "\n",
    "df_ln[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores maiores que mediana + 3 vezes o desvio padrão.\n",
    "med = df_sem_outlier[nome_feature].median()\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] >= (df_sem_outlier[nome_feature].median() + 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores MENOR que mediana - 3 vezes o desvio padrão.\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] <= (df_sem_outlier[nome_feature].median() - 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target} SEM OUTLIER\\n\")\n",
    "print(df_sem_outlier[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}> SEM OUTLIER\\n\")\n",
    "\n",
    "df_ln_sem_outlier[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln_sem_outlier[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln_sem_outlier[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# ARMAZENAMENTO DAS FEATURES CASO SEJAM UTILIZADAS NO MODELO DE REGRESSÃO LINEAR.\n",
    "\n",
    "# Armazenamento da feature não transformada.\n",
    "features_numericas[nome_feature] = dados_treino[nome_feature]\n",
    "\n",
    "# Armezenamento da feature transformada com ln.\n",
    "features_ln_numericas[nome_feature] = df_ln[nome_feature]\n",
    "\n",
    "# Armazenamento da feature não transformada.\n",
    "features_numericas_sem_outlier[nome_feature] = df_sem_outlier[nome_feature]\n",
    "\n",
    "# Armezenamento da feature transformada com ln.\n",
    "features_ln_numericas_sem_outlier[nome_feature] = df_ln_sem_outlier[nome_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c406485",
   "metadata": {},
   "source": [
    "## YearRemodAdd (Numérica)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e77c7aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "\n",
      "Correlação entre YearRemodAdd e SalePrice\n",
      "\n",
      "              YearRemodAdd  SalePrice\n",
      "YearRemodAdd      1.000000   0.508593\n",
      "SalePrice         0.508593   1.000000\n",
      "\n",
      "Correlação entre ln<YearRemodAdd> e ln<SalePrice>\n",
      "\n",
      "              YearRemodAdd  SalePrice\n",
      "YearRemodAdd      1.000000   0.562127\n",
      "SalePrice         0.562127   1.000000\n",
      "\n",
      "Correlação entre YearRemodAdd e SalePrice SEM OUTLIER\n",
      "\n",
      "              YearRemodAdd  SalePrice\n",
      "YearRemodAdd      1.000000   0.508593\n",
      "SalePrice         0.508593   1.000000\n",
      "\n",
      "Correlação entre ln<YearRemodAdd> e ln<SalePrice> SEM OUTLIER\n",
      "\n",
      "              YearRemodAdd  SalePrice\n",
      "YearRemodAdd      1.000000   0.562127\n",
      "SalePrice         0.562127   1.000000\n",
      "\n",
      "Quantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "\n",
      "Quantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nome_feature = 'YearRemodAdd'\n",
    "\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# # Substituição de valores não válidos pela mediana da variável em ambos os data frames.\n",
    "# dados_treino[nome_feature].fillna(dados_treino[nome_feature].median(), inplace = True)\n",
    "# df_sem_outlier[nome_feature].fillna(df_sem_outlier[nome_feature].median(), inplace = True)\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target}\\n\")\n",
    "print(dados_treino[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}>\\n\")\n",
    "\n",
    "df_ln[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores maiores que mediana + 3 vezes o desvio padrão.\n",
    "med = df_sem_outlier[nome_feature].median()\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] >= (df_sem_outlier[nome_feature].median() + 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores MENOR que mediana - 3 vezes o desvio padrão.\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] <= (df_sem_outlier[nome_feature].median() - 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target} SEM OUTLIER\\n\")\n",
    "print(df_sem_outlier[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}> SEM OUTLIER\\n\")\n",
    "\n",
    "df_ln_sem_outlier[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln_sem_outlier[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln_sem_outlier[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# # ARMAZENAMENTO DAS FEATURES CASO SEJAM UTILIZADAS NO MODELO DE REGRESSÃO LINEAR.\n",
    "\n",
    "# # Armazenamento da feature não transformada.\n",
    "# features_numericas[nome_feature] = dados_treino[nome_feature]\n",
    "\n",
    "# # Armezenamento da feature transformada com ln.\n",
    "# features_ln_numericas[nome_feature] = df_ln[nome_feature]\n",
    "\n",
    "# # Armazenamento da feature não transformada.\n",
    "# features_numericas_sem_outlier[nome_feature] = df_sem_outlier[nome_feature]\n",
    "\n",
    "# # Armezenamento da feature transformada com ln.\n",
    "# features_ln_numericas_sem_outlier[nome_feature] = df_ln_sem_outlier[nome_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695b45f5",
   "metadata": {},
   "source": [
    "## RoofStyle (Categórica)\n",
    "\n",
    "Tipo do telhado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8930467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "Verficação da disposição da variável em agurpamento:\n",
      "\n",
      "RoofStyle\n",
      "Flat        11\n",
      "Gable      906\n",
      "Gambrel      9\n",
      "Hip        235\n",
      "Mansard      5\n",
      "Shed         2\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>SalePrice</td>    <th>  R-squared:         </th> <td>   0.059</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.055</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   14.65</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 05 Dec 2023</td> <th>  Prob (F-statistic):</th> <td>6.00e-14</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>07:17:26</td>     <th>  Log-Likelihood:    </th> <td> -14767.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.955e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1162</td>      <th>  BIC:               </th> <td>2.958e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td> 1.951e+05</td> <td> 2.26e+04</td> <td>    8.618</td> <td> 0.000</td> <td> 1.51e+05</td> <td>  2.4e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Gable</th>     <td> -2.32e+04</td> <td> 2.28e+04</td> <td>   -1.018</td> <td> 0.309</td> <td>-6.79e+04</td> <td> 2.15e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Gambrel</th>   <td>-4.058e+04</td> <td> 3.38e+04</td> <td>   -1.202</td> <td> 0.230</td> <td>-1.07e+05</td> <td> 2.56e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Hip</th>       <td> 2.313e+04</td> <td> 2.32e+04</td> <td>    0.998</td> <td> 0.318</td> <td>-2.23e+04</td> <td> 6.86e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Mansard</th>   <td>-2.114e+04</td> <td> 4.05e+04</td> <td>   -0.522</td> <td> 0.602</td> <td>-1.01e+05</td> <td> 5.83e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Shed</th>      <td> 2.987e+04</td> <td> 5.77e+04</td> <td>    0.517</td> <td> 0.605</td> <td>-8.34e+04</td> <td> 1.43e+05</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>357.331</td> <th>  Durbin-Watson:     </th> <td>   2.040</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1296.784</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.453</td>  <th>  Prob(JB):          </th> <td>2.55e-282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 7.267</td>  <th>  Cond. No.          </th> <td>    38.8</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              SalePrice   R-squared:                       0.059\n",
       "Model:                            OLS   Adj. R-squared:                  0.055\n",
       "Method:                 Least Squares   F-statistic:                     14.65\n",
       "Date:                Tue, 05 Dec 2023   Prob (F-statistic):           6.00e-14\n",
       "Time:                        07:17:26   Log-Likelihood:                -14767.\n",
       "No. Observations:                1168   AIC:                         2.955e+04\n",
       "Df Residuals:                    1162   BIC:                         2.958e+04\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept   1.951e+05   2.26e+04      8.618      0.000    1.51e+05     2.4e+05\n",
       "Gable       -2.32e+04   2.28e+04     -1.018      0.309   -6.79e+04    2.15e+04\n",
       "Gambrel    -4.058e+04   3.38e+04     -1.202      0.230   -1.07e+05    2.56e+04\n",
       "Hip         2.313e+04   2.32e+04      0.998      0.318   -2.23e+04    6.86e+04\n",
       "Mansard    -2.114e+04   4.05e+04     -0.522      0.602   -1.01e+05    5.83e+04\n",
       "Shed        2.987e+04   5.77e+04      0.517      0.605   -8.34e+04    1.43e+05\n",
       "==============================================================================\n",
       "Omnibus:                      357.331   Durbin-Watson:                   2.040\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1296.784\n",
       "Skew:                           1.453   Prob(JB):                    2.55e-282\n",
       "Kurtosis:                       7.267   Cond. No.                         38.8\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nome_feature = 'RoofStyle'\n",
    "\n",
    "# Verificação de valores nulos na variável\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Estatística univariádas pela variável\n",
    "print('Verficação da disposição da variável em agurpamento:\\n')\n",
    "agrupado = dados_treino.groupby([nome_feature]).size()\n",
    "print(agrupado)\n",
    "\n",
    "# Conversão da variável categórica em dicotômica com a exclusão da primeira variável dicotômica.\n",
    "df_dummies_auxiliar = pd.get_dummies(dados_treino[nome_feature], columns=[nome_feature], drop_first=True)\n",
    "\n",
    "# Inclusão da variável dependente ao data frame de variáveis dicotômicas.\n",
    "df_dummies_auxiliar[nome_target] = dados_treino[nome_target].copy()\n",
    "\n",
    "# Verificação do data frame.\n",
    "df_dummies_auxiliar.head(6)\n",
    "\n",
    "# Estimação do modelo de regressão linear múltipla com n-1 dummies\n",
    "modelo_dummies = sm.OLS.from_formula(\"SalePrice ~ Gable + Gambrel + Hip + Mansard + Shed\", df_dummies_auxiliar).fit()\n",
    "\n",
    "# Verificação dos parâmetros do modelo.\n",
    "modelo_dummies.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259cc1f5",
   "metadata": {},
   "source": [
    "## RoofMatl (Categórica)\n",
    "\n",
    "Material do Telhado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e683fcbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "Verficação da disposição da variável em agurpamento:\n",
      "\n",
      "RoofMatl\n",
      "ClyTile       1\n",
      "CompShg    1149\n",
      "Metal         1\n",
      "Roll          1\n",
      "Tar&Grv       9\n",
      "WdShake       3\n",
      "WdShngl       4\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>SalePrice</td>    <th>  R-squared:         </th> <td>   0.014</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.008</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   2.654</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 05 Dec 2023</td> <th>  Prob (F-statistic):</th>  <td>0.0146</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>07:17:26</td>     <th>  Log-Likelihood:    </th> <td> -14795.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.960e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1161</td>      <th>  BIC:               </th> <td>2.964e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>    <td>   1.6e+05</td> <td> 7.69e+04</td> <td>    2.080</td> <td> 0.038</td> <td> 9048.694</td> <td> 3.11e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CompShg</th>      <td> 2.079e+04</td> <td>  7.7e+04</td> <td>    0.270</td> <td> 0.787</td> <td> -1.3e+05</td> <td> 1.72e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Metal</th>        <td>     2e+04</td> <td> 1.09e+05</td> <td>    0.184</td> <td> 0.854</td> <td>-1.93e+05</td> <td> 2.33e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Roll</th>         <td>  -2.3e+04</td> <td> 1.09e+05</td> <td>   -0.211</td> <td> 0.833</td> <td>-2.36e+05</td> <td>  1.9e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q('Tar&Grv')</th> <td> 3.239e+04</td> <td> 8.11e+04</td> <td>    0.399</td> <td> 0.690</td> <td>-1.27e+05</td> <td> 1.92e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>WdShake</th>      <td>   6.6e+04</td> <td> 8.88e+04</td> <td>    0.743</td> <td> 0.458</td> <td>-1.08e+05</td> <td>  2.4e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>WdShngl</th>      <td> 1.666e+05</td> <td>  8.6e+04</td> <td>    1.937</td> <td> 0.053</td> <td>-2143.691</td> <td> 3.35e+05</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>443.220</td> <th>  Durbin-Watson:     </th> <td>   2.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2075.538</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.732</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.537</td>  <th>  Cond. No.          </th> <td>    131.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              SalePrice   R-squared:                       0.014\n",
       "Model:                            OLS   Adj. R-squared:                  0.008\n",
       "Method:                 Least Squares   F-statistic:                     2.654\n",
       "Date:                Tue, 05 Dec 2023   Prob (F-statistic):             0.0146\n",
       "Time:                        07:17:26   Log-Likelihood:                -14795.\n",
       "No. Observations:                1168   AIC:                         2.960e+04\n",
       "Df Residuals:                    1161   BIC:                         2.964e+04\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "Intercept       1.6e+05   7.69e+04      2.080      0.038    9048.694    3.11e+05\n",
       "CompShg       2.079e+04    7.7e+04      0.270      0.787    -1.3e+05    1.72e+05\n",
       "Metal             2e+04   1.09e+05      0.184      0.854   -1.93e+05    2.33e+05\n",
       "Roll           -2.3e+04   1.09e+05     -0.211      0.833   -2.36e+05     1.9e+05\n",
       "Q('Tar&Grv')  3.239e+04   8.11e+04      0.399      0.690   -1.27e+05    1.92e+05\n",
       "WdShake         6.6e+04   8.88e+04      0.743      0.458   -1.08e+05     2.4e+05\n",
       "WdShngl       1.666e+05    8.6e+04      1.937      0.053   -2143.691    3.35e+05\n",
       "==============================================================================\n",
       "Omnibus:                      443.220   Durbin-Watson:                   2.047\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2075.538\n",
       "Skew:                           1.732   Prob(JB):                         0.00\n",
       "Kurtosis:                       8.537   Cond. No.                         131.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nome_feature = 'RoofMatl'\n",
    "\n",
    "# Verificação de valores nulos na variável\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Estatística univariádas pela variável\n",
    "print('Verficação da disposição da variável em agurpamento:\\n')\n",
    "agrupado = dados_treino.groupby([nome_feature]).size()\n",
    "print(agrupado)\n",
    "\n",
    "# Conversão da variável categórica em dicotômica com a exclusão da primeira variável dicotômica.\n",
    "df_dummies_auxiliar = pd.get_dummies(dados_treino[nome_feature], columns=[nome_feature], drop_first=True)\n",
    "\n",
    "# Inclusão da variável dependente ao data frame de variáveis dicotômicas.\n",
    "df_dummies_auxiliar[nome_target] = dados_treino[nome_target].copy()\n",
    "\n",
    "# Verificação do data frame.\n",
    "df_dummies_auxiliar.head(6)\n",
    "\n",
    "# Estimação do modelo de regressão linear múltipla com n-1 dummies\n",
    "modelo_dummies = sm.OLS.from_formula(\"SalePrice ~ CompShg + Metal + Roll + Q('Tar&Grv') + WdShake + WdShngl\", df_dummies_auxiliar).fit()\n",
    "\n",
    "# Verificação dos parâmetros do modelo.\n",
    "modelo_dummies.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff05230",
   "metadata": {},
   "source": [
    "## Exterior1st (Categórica)\n",
    "\n",
    "**Cobertura externa da casa.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa60e7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "Verficação da disposição da variável em agurpamento:\n",
      "\n",
      "Exterior1st\n",
      "AsbShng     16\n",
      "AsphShn      1\n",
      "BrkComm      2\n",
      "BrkFace     40\n",
      "CBlock       1\n",
      "CemntBd     45\n",
      "HdBoard    176\n",
      "ImStucc      1\n",
      "MetalSd    173\n",
      "Plywood     81\n",
      "Stone        1\n",
      "Stucco      21\n",
      "VinylSd    420\n",
      "Wd Sdng    171\n",
      "WdShing     19\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>SalePrice</td>    <th>  R-squared:         </th> <td>   0.165</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.155</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   16.24</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 05 Dec 2023</td> <th>  Prob (F-statistic):</th> <td>9.56e-37</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>07:17:26</td>     <th>  Log-Likelihood:    </th> <td> -14698.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.943e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1153</td>      <th>  BIC:               </th> <td>2.950e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    14</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>    <td>  1.12e+05</td> <td> 1.78e+04</td> <td>    6.308</td> <td> 0.000</td> <td> 7.72e+04</td> <td> 1.47e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AsphShn</th>      <td>-1.202e+04</td> <td> 7.32e+04</td> <td>   -0.164</td> <td> 0.870</td> <td>-1.56e+05</td> <td> 1.32e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BrkComm</th>      <td>-4.102e+04</td> <td> 5.33e+04</td> <td>   -0.770</td> <td> 0.441</td> <td>-1.46e+05</td> <td> 6.35e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BrkFace</th>      <td>  9.46e+04</td> <td>  2.1e+04</td> <td>    4.502</td> <td> 0.000</td> <td> 5.34e+04</td> <td> 1.36e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CBlock</th>       <td>-7025.0000</td> <td> 7.32e+04</td> <td>   -0.096</td> <td> 0.924</td> <td>-1.51e+05</td> <td> 1.37e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CemntBd</th>      <td> 1.265e+05</td> <td> 2.07e+04</td> <td>    6.117</td> <td> 0.000</td> <td> 8.59e+04</td> <td> 1.67e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HdBoard</th>      <td> 4.883e+04</td> <td> 1.85e+04</td> <td>    2.632</td> <td> 0.009</td> <td> 1.24e+04</td> <td> 8.52e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ImStucc</th>      <td>   1.5e+05</td> <td> 7.32e+04</td> <td>    2.048</td> <td> 0.041</td> <td> 6301.073</td> <td> 2.94e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MetalSd</th>      <td> 3.742e+04</td> <td> 1.86e+04</td> <td>    2.016</td> <td> 0.044</td> <td>  998.060</td> <td> 7.38e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Plywood</th>      <td> 6.544e+04</td> <td> 1.94e+04</td> <td>    3.367</td> <td> 0.001</td> <td> 2.73e+04</td> <td> 1.04e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Stone</th>        <td>  1.18e+05</td> <td> 7.32e+04</td> <td>    1.611</td> <td> 0.107</td> <td>-2.57e+04</td> <td> 2.62e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Stucco</th>       <td> 6.344e+04</td> <td> 2.36e+04</td> <td>    2.691</td> <td> 0.007</td> <td> 1.72e+04</td> <td>  1.1e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>VinylSd</th>      <td>  1.01e+05</td> <td> 1.81e+04</td> <td>    5.580</td> <td> 0.000</td> <td> 6.55e+04</td> <td> 1.36e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q('Wd Sdng')</th> <td> 3.875e+04</td> <td> 1.86e+04</td> <td>    2.086</td> <td> 0.037</td> <td> 2305.862</td> <td> 7.52e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>WdShing</th>      <td> 3.691e+04</td> <td> 2.41e+04</td> <td>    1.531</td> <td> 0.126</td> <td>-1.04e+04</td> <td> 8.42e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>508.013</td> <th>  Durbin-Watson:     </th> <td>   2.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3873.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.833</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>11.133</td>  <th>  Cond. No.          </th> <td>    46.0</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              SalePrice   R-squared:                       0.165\n",
       "Model:                            OLS   Adj. R-squared:                  0.155\n",
       "Method:                 Least Squares   F-statistic:                     16.24\n",
       "Date:                Tue, 05 Dec 2023   Prob (F-statistic):           9.56e-37\n",
       "Time:                        07:17:26   Log-Likelihood:                -14698.\n",
       "No. Observations:                1168   AIC:                         2.943e+04\n",
       "Df Residuals:                    1153   BIC:                         2.950e+04\n",
       "Df Model:                          14                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "Intercept      1.12e+05   1.78e+04      6.308      0.000    7.72e+04    1.47e+05\n",
       "AsphShn      -1.202e+04   7.32e+04     -0.164      0.870   -1.56e+05    1.32e+05\n",
       "BrkComm      -4.102e+04   5.33e+04     -0.770      0.441   -1.46e+05    6.35e+04\n",
       "BrkFace        9.46e+04    2.1e+04      4.502      0.000    5.34e+04    1.36e+05\n",
       "CBlock       -7025.0000   7.32e+04     -0.096      0.924   -1.51e+05    1.37e+05\n",
       "CemntBd       1.265e+05   2.07e+04      6.117      0.000    8.59e+04    1.67e+05\n",
       "HdBoard       4.883e+04   1.85e+04      2.632      0.009    1.24e+04    8.52e+04\n",
       "ImStucc         1.5e+05   7.32e+04      2.048      0.041    6301.073    2.94e+05\n",
       "MetalSd       3.742e+04   1.86e+04      2.016      0.044     998.060    7.38e+04\n",
       "Plywood       6.544e+04   1.94e+04      3.367      0.001    2.73e+04    1.04e+05\n",
       "Stone          1.18e+05   7.32e+04      1.611      0.107   -2.57e+04    2.62e+05\n",
       "Stucco        6.344e+04   2.36e+04      2.691      0.007    1.72e+04     1.1e+05\n",
       "VinylSd        1.01e+05   1.81e+04      5.580      0.000    6.55e+04    1.36e+05\n",
       "Q('Wd Sdng')  3.875e+04   1.86e+04      2.086      0.037    2305.862    7.52e+04\n",
       "WdShing       3.691e+04   2.41e+04      1.531      0.126   -1.04e+04    8.42e+04\n",
       "==============================================================================\n",
       "Omnibus:                      508.013   Durbin-Watson:                   2.016\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3873.044\n",
       "Skew:                           1.833   Prob(JB):                         0.00\n",
       "Kurtosis:                      11.133   Cond. No.                         46.0\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nome_feature = 'Exterior1st'\n",
    "\n",
    "# Verificação de valores nulos na variável\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Estatística univariádas pela variável\n",
    "print('Verficação da disposição da variável em agurpamento:\\n')\n",
    "agrupado = dados_treino.groupby([nome_feature]).size()\n",
    "print(agrupado)\n",
    "\n",
    "# Conversão da variável categórica em dicotômica com a exclusão da primeira variável dicotômica.\n",
    "df_dummies_auxiliar = pd.get_dummies(dados_treino[nome_feature], columns=[nome_feature], drop_first=True)\n",
    "\n",
    "# Inclusão da variável dependente ao data frame de variáveis dicotômicas.\n",
    "df_dummies_auxiliar[nome_target] = dados_treino[nome_target].copy()\n",
    "\n",
    "# Verificação do data frame.\n",
    "df_dummies_auxiliar.head(6)\n",
    "\n",
    "# Estimação do modelo de regressão linear múltipla com n-1 dummies\n",
    "modelo_dummies = sm.OLS.from_formula(\"SalePrice ~ AsphShn + BrkComm + BrkFace + CBlock + CemntBd + HdBoard + ImStucc + MetalSd + Plywood + Stone + Stucco + VinylSd + Q('Wd Sdng') + WdShing\", df_dummies_auxiliar).fit()\n",
    "\n",
    "# Verificação dos parâmetros do modelo.\n",
    "modelo_dummies.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be67b77f",
   "metadata": {},
   "source": [
    "## Exterior2nd (Categórica)\n",
    "\n",
    "**Cobertura externa da casa, para aquelas possuem mais de um tipo de cobertura.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a99e81de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "Verficação da disposição da variável em agurpamento:\n",
      "\n",
      "Exterior2nd\n",
      "AsbShng     17\n",
      "AsphShn      3\n",
      "Brk Cmn      6\n",
      "BrkFace     15\n",
      "CBlock       1\n",
      "CmentBd     44\n",
      "HdBoard    163\n",
      "ImStucc      6\n",
      "MetalSd    165\n",
      "Other        1\n",
      "Plywood    112\n",
      "Stone        3\n",
      "Stucco      23\n",
      "VinylSd    410\n",
      "Wd Sdng    165\n",
      "Wd Shng     34\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>SalePrice</td>    <th>  R-squared:         </th> <td>   0.169</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.158</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   15.63</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 05 Dec 2023</td> <th>  Prob (F-statistic):</th> <td>2.26e-37</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>07:17:26</td>     <th>  Log-Likelihood:    </th> <td> -14694.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.942e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1152</td>      <th>  BIC:               </th> <td>2.950e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    15</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>    <td> 1.208e+05</td> <td> 1.72e+04</td> <td>    7.024</td> <td> 0.000</td> <td>  8.7e+04</td> <td> 1.54e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AsphShn</th>      <td> 1.724e+04</td> <td> 4.44e+04</td> <td>    0.388</td> <td> 0.698</td> <td>-6.99e+04</td> <td> 1.04e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q('Brk Cmn')</th> <td> 2741.1765</td> <td> 3.37e+04</td> <td>    0.081</td> <td> 0.935</td> <td>-6.33e+04</td> <td> 6.88e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BrkFace</th>      <td> 1.081e+05</td> <td> 2.51e+04</td> <td>    4.305</td> <td> 0.000</td> <td> 5.88e+04</td> <td> 1.57e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CBlock</th>       <td>-1.576e+04</td> <td> 7.29e+04</td> <td>   -0.216</td> <td> 0.829</td> <td>-1.59e+05</td> <td> 1.27e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CmentBd</th>      <td> 1.157e+05</td> <td> 2.02e+04</td> <td>    5.717</td> <td> 0.000</td> <td>  7.6e+04</td> <td> 1.55e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HdBoard</th>      <td> 4.482e+04</td> <td> 1.81e+04</td> <td>    2.481</td> <td> 0.013</td> <td> 9372.478</td> <td> 8.03e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ImStucc</th>      <td> 1.674e+05</td> <td> 3.37e+04</td> <td>    4.974</td> <td> 0.000</td> <td> 1.01e+05</td> <td> 2.33e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MetalSd</th>      <td> 2.942e+04</td> <td> 1.81e+04</td> <td>    1.629</td> <td> 0.104</td> <td>-6006.865</td> <td> 6.48e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Other</th>        <td> 1.982e+05</td> <td> 7.29e+04</td> <td>    2.718</td> <td> 0.007</td> <td> 5.51e+04</td> <td> 3.41e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Plywood</th>      <td> 4.728e+04</td> <td> 1.85e+04</td> <td>    2.563</td> <td> 0.011</td> <td> 1.11e+04</td> <td> 8.35e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Stone</th>        <td> 4.491e+04</td> <td> 4.44e+04</td> <td>    1.012</td> <td> 0.312</td> <td>-4.22e+04</td> <td> 1.32e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Stucco</th>       <td> 4.259e+04</td> <td> 2.27e+04</td> <td>    1.879</td> <td> 0.061</td> <td>-1892.037</td> <td> 8.71e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>VinylSd</th>      <td>  9.29e+04</td> <td> 1.75e+04</td> <td>    5.295</td> <td> 0.000</td> <td> 5.85e+04</td> <td> 1.27e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q('Wd Sdng')</th> <td> 2.966e+04</td> <td> 1.81e+04</td> <td>    1.643</td> <td> 0.101</td> <td>-5766.702</td> <td> 6.51e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q('Wd Shng')</th> <td> 3.993e+04</td> <td> 2.11e+04</td> <td>    1.896</td> <td> 0.058</td> <td>-1380.123</td> <td> 8.12e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>420.228</td> <th>  Durbin-Watson:     </th> <td>   2.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2146.331</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.595</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.824</td>  <th>  Cond. No.          </th> <td>    43.6</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              SalePrice   R-squared:                       0.169\n",
       "Model:                            OLS   Adj. R-squared:                  0.158\n",
       "Method:                 Least Squares   F-statistic:                     15.63\n",
       "Date:                Tue, 05 Dec 2023   Prob (F-statistic):           2.26e-37\n",
       "Time:                        07:17:26   Log-Likelihood:                -14694.\n",
       "No. Observations:                1168   AIC:                         2.942e+04\n",
       "Df Residuals:                    1152   BIC:                         2.950e+04\n",
       "Df Model:                          15                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "Intercept     1.208e+05   1.72e+04      7.024      0.000     8.7e+04    1.54e+05\n",
       "AsphShn       1.724e+04   4.44e+04      0.388      0.698   -6.99e+04    1.04e+05\n",
       "Q('Brk Cmn')  2741.1765   3.37e+04      0.081      0.935   -6.33e+04    6.88e+04\n",
       "BrkFace       1.081e+05   2.51e+04      4.305      0.000    5.88e+04    1.57e+05\n",
       "CBlock       -1.576e+04   7.29e+04     -0.216      0.829   -1.59e+05    1.27e+05\n",
       "CmentBd       1.157e+05   2.02e+04      5.717      0.000     7.6e+04    1.55e+05\n",
       "HdBoard       4.482e+04   1.81e+04      2.481      0.013    9372.478    8.03e+04\n",
       "ImStucc       1.674e+05   3.37e+04      4.974      0.000    1.01e+05    2.33e+05\n",
       "MetalSd       2.942e+04   1.81e+04      1.629      0.104   -6006.865    6.48e+04\n",
       "Other         1.982e+05   7.29e+04      2.718      0.007    5.51e+04    3.41e+05\n",
       "Plywood       4.728e+04   1.85e+04      2.563      0.011    1.11e+04    8.35e+04\n",
       "Stone         4.491e+04   4.44e+04      1.012      0.312   -4.22e+04    1.32e+05\n",
       "Stucco        4.259e+04   2.27e+04      1.879      0.061   -1892.037    8.71e+04\n",
       "VinylSd        9.29e+04   1.75e+04      5.295      0.000    5.85e+04    1.27e+05\n",
       "Q('Wd Sdng')  2.966e+04   1.81e+04      1.643      0.101   -5766.702    6.51e+04\n",
       "Q('Wd Shng')  3.993e+04   2.11e+04      1.896      0.058   -1380.123    8.12e+04\n",
       "==============================================================================\n",
       "Omnibus:                      420.228   Durbin-Watson:                   2.001\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2146.331\n",
       "Skew:                           1.595   Prob(JB):                         0.00\n",
       "Kurtosis:                       8.824   Cond. No.                         43.6\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nome_feature = 'Exterior2nd'\n",
    "\n",
    "# Verificação de valores nulos na variável\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Estatística univariádas pela variável\n",
    "print('Verficação da disposição da variável em agurpamento:\\n')\n",
    "agrupado = dados_treino.groupby([nome_feature]).size()\n",
    "print(agrupado)\n",
    "\n",
    "# Conversão da variável categórica em dicotômica com a exclusão da primeira variável dicotômica.\n",
    "df_dummies_auxiliar = pd.get_dummies(dados_treino[nome_feature], columns=[nome_feature], drop_first=True)\n",
    "\n",
    "# Inclusão da variável dependente ao data frame de variáveis dicotômicas.\n",
    "df_dummies_auxiliar[nome_target] = dados_treino[nome_target].copy()\n",
    "\n",
    "# Verificação do data frame.\n",
    "df_dummies_auxiliar.head(6)\n",
    "\n",
    "# Estimação do modelo de regressão linear múltipla com n-1 dummies\n",
    "modelo_dummies = sm.OLS.from_formula(\"SalePrice ~ AsphShn + Q('Brk Cmn') + BrkFace + CBlock + CmentBd + HdBoard + ImStucc + MetalSd + Other + Plywood + Stone + Stucco + VinylSd + Q('Wd Sdng') + Q('Wd Shng')\", df_dummies_auxiliar).fit()\n",
    "\n",
    "# Verificação dos parâmetros do modelo.\n",
    "modelo_dummies.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8f8018",
   "metadata": {},
   "source": [
    "## MasVnrType (Categórica)\n",
    "\n",
    "**Tipo de folheado da alvenaria.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a1d8911e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 6\n",
      "\n",
      "Verficação da disposição da variável em agurpamento:\n",
      "\n",
      "MasVnrType\n",
      "BrkCmn      13\n",
      "BrkFace    366\n",
      "None       677\n",
      "Stone      106\n",
      "dtype: int64\n",
      "\n",
      "Verifcamos que após o agrupamento o valor da moda dessa variável é \"None\", ou seja, sem folheado na alvenaria. Portanto iremos substituir os valores não válidos pela moda para aliminarmos esses valores dos dados.\n",
      "\n",
      "      BrkFace  None  Stone  SalePrice\n",
      "254         0     1      0     145000\n",
      "1066        0     1      0     178000\n",
      "638         0     1      0      85000\n",
      "799         1     0      0     175000\n",
      "380         0     1      0     127000\n",
      "303         0     1      0     149900\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>SalePrice</td>    <th>  R-squared:         </th> <td>   0.170</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.168</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   79.69</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 05 Dec 2023</td> <th>  Prob (F-statistic):</th> <td>6.86e-47</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>07:55:32</td>     <th>  Log-Likelihood:    </th> <td> -14694.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.940e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1164</td>      <th>  BIC:               </th> <td>2.942e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   1.5e+05</td> <td> 1.95e+04</td> <td>    7.676</td> <td> 0.000</td> <td> 1.12e+05</td> <td> 1.88e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BrkFace</th>   <td> 5.178e+04</td> <td> 1.99e+04</td> <td>    2.604</td> <td> 0.009</td> <td> 1.28e+04</td> <td> 9.08e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q('None')</th> <td> 8751.7005</td> <td> 1.97e+04</td> <td>    0.444</td> <td> 0.657</td> <td>   -3e+04</td> <td> 4.75e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Stone</th>     <td>  1.11e+05</td> <td> 2.07e+04</td> <td>    5.361</td> <td> 0.000</td> <td> 7.04e+04</td> <td> 1.52e+05</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>473.899</td> <th>  Durbin-Watson:     </th> <td>   2.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2897.486</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.764</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 9.862</td>  <th>  Cond. No.          </th> <td>    23.2</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              SalePrice   R-squared:                       0.170\n",
       "Model:                            OLS   Adj. R-squared:                  0.168\n",
       "Method:                 Least Squares   F-statistic:                     79.69\n",
       "Date:                Tue, 05 Dec 2023   Prob (F-statistic):           6.86e-47\n",
       "Time:                        07:55:32   Log-Likelihood:                -14694.\n",
       "No. Observations:                1168   AIC:                         2.940e+04\n",
       "Df Residuals:                    1164   BIC:                         2.942e+04\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     1.5e+05   1.95e+04      7.676      0.000    1.12e+05    1.88e+05\n",
       "BrkFace     5.178e+04   1.99e+04      2.604      0.009    1.28e+04    9.08e+04\n",
       "Q('None')   8751.7005   1.97e+04      0.444      0.657      -3e+04    4.75e+04\n",
       "Stone        1.11e+05   2.07e+04      5.361      0.000    7.04e+04    1.52e+05\n",
       "==============================================================================\n",
       "Omnibus:                      473.899   Durbin-Watson:                   2.019\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2897.486\n",
       "Skew:                           1.764   Prob(JB):                         0.00\n",
       "Kurtosis:                       9.862   Cond. No.                         23.2\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nome_feature = 'MasVnrType'\n",
    "\n",
    "# Verificação de valores nulos na variável\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Estatística univariádas pela variável\n",
    "print('Verficação da disposição da variável em agurpamento:\\n')\n",
    "agrupado = dados_treino.groupby([nome_feature]).size()\n",
    "print(agrupado)\n",
    "\n",
    "print(f'\\nVerifcamos que após o agrupamento o valor da moda dessa variável é \"None\", ou seja, sem folheado na alvenaria. Portanto iremos substituir os valores não válidos pela moda para aliminarmos esses valores dos dados.\\n')\n",
    "\n",
    "# Cópia dos valores que serão manipulados para que os valores originais são sejam alterados.\n",
    "df_dummies_auxiliar_1 = dados_treino[nome_feature].copy()\n",
    "\n",
    "# Eliminação dos valores não válidas pelo valor da moda.\n",
    "df_dummies_auxiliar_1.fillna('None', inplace = True)\n",
    "\n",
    "# Conversão da variável categórica em dicotômica com a exclusão da primeira variável dicotômica.\n",
    "df_dummies_auxiliar = pd.get_dummies(df_dummies_auxiliar_1, columns=[nome_feature], drop_first=True)\n",
    "\n",
    "# Inclusão da variável dependente ao data frame de variáveis dicotômicas.\n",
    "df_dummies_auxiliar[nome_target] = dados_treino[nome_target].copy()\n",
    "\n",
    "# Verificação do data frame.\n",
    "print(df_dummies_auxiliar.head(6))\n",
    "\n",
    "# Estimação do modelo de regressão linear múltipla com n-1 dummies\n",
    "modelo_dummies = sm.OLS.from_formula(\"SalePrice ~ BrkFace + Q('None') + Stone\", df_dummies_auxiliar).fit()\n",
    "\n",
    "# Verificação dos parâmetros do modelo.\n",
    "modelo_dummies.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589f9f8b",
   "metadata": {},
   "source": [
    "## MasVnrArea (Numérica)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e75dbb61",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 6\n",
      "\n",
      "\n",
      "Correlação entre MasVnrArea e SalePrice\n",
      "\n",
      "            MasVnrArea  SalePrice\n",
      "MasVnrArea    1.000000   0.457608\n",
      "SalePrice     0.457608   1.000000\n",
      "\n",
      "Correlação entre ln<MasVnrArea> e ln<SalePrice>\n",
      "\n",
      "            MasVnrArea  SalePrice\n",
      "MasVnrArea    1.000000   0.307111\n",
      "SalePrice     0.307111   1.000000\n",
      "\n",
      "Correlação entre MasVnrArea e SalePrice SEM OUTLIER\n",
      "\n",
      "            MasVnrArea  SalePrice\n",
      "MasVnrArea     1.00000    0.28302\n",
      "SalePrice      0.28302    1.00000\n",
      "\n",
      "Correlação entre ln<MasVnrArea> e ln<SalePrice> SEM OUTLIER\n",
      "\n",
      "            MasVnrArea  SalePrice\n",
      "MasVnrArea    1.000000   0.211818\n",
      "SalePrice     0.211818   1.000000\n",
      "\n",
      "Quantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: 680\n",
      "\n",
      "Quantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "\n",
      "Quantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nome_feature = 'MasVnrArea'\n",
    "\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Substituição de valores não válidos pela mediana da variável em ambos os data frames.\n",
    "dados_treino[nome_feature].fillna(dados_treino[nome_feature].median(), inplace = True)\n",
    "df_sem_outlier[nome_feature].fillna(df_sem_outlier[nome_feature].median(), inplace = True)\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target}\\n\")\n",
    "print(dados_treino[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}>\\n\")\n",
    "\n",
    "df_ln[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores maiores que mediana + 3 vezes o desvio padrão.\n",
    "med = df_sem_outlier[nome_feature].median()\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] >= (df_sem_outlier[nome_feature].median() + 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores MENOR que mediana - 3 vezes o desvio padrão.\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] <= (df_sem_outlier[nome_feature].median() - 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target} SEM OUTLIER\\n\")\n",
    "print(df_sem_outlier[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}> SEM OUTLIER\\n\")\n",
    "\n",
    "df_ln_sem_outlier[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln_sem_outlier[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln_sem_outlier[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# # ARMAZENAMENTO DAS FEATURES CASO SEJAM UTILIZADAS NO MODELO DE REGRESSÃO LINEAR.\n",
    "\n",
    "# # Armazenamento da feature não transformada.\n",
    "# features_numericas[nome_feature] = dados_treino[nome_feature]\n",
    "\n",
    "# # Armezenamento da feature transformada com ln.\n",
    "# features_ln_numericas[nome_feature] = df_ln[nome_feature]\n",
    "\n",
    "# # Armazenamento da feature não transformada.\n",
    "# features_numericas_sem_outlier[nome_feature] = df_sem_outlier[nome_feature]\n",
    "\n",
    "# # Armezenamento da feature transformada com ln.\n",
    "# features_ln_numericas_sem_outlier[nome_feature] = df_ln_sem_outlier[nome_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7df56b",
   "metadata": {},
   "source": [
    "## ExterQual (Categórica)\n",
    "\n",
    "**Avaliação do acabamento externo do imóvel.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "31910576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "Verficação da disposição da variável em agurpamento:\n",
      "\n",
      "ExterQual\n",
      "Ex     42\n",
      "Fa     11\n",
      "Gd    388\n",
      "TA    727\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>SalePrice</td>    <th>  R-squared:         </th> <td>   0.451</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.449</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   318.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 05 Dec 2023</td> <th>  Prob (F-statistic):</th> <td>5.70e-151</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>07:17:26</td>     <th>  Log-Likelihood:    </th> <td> -14453.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.891e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1164</td>      <th>  BIC:               </th> <td>2.893e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td> 3.522e+05</td> <td> 8846.030</td> <td>   39.814</td> <td> 0.000</td> <td> 3.35e+05</td> <td>  3.7e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fa</th>        <td>-2.581e+05</td> <td> 1.94e+04</td> <td>  -13.294</td> <td> 0.000</td> <td>-2.96e+05</td> <td> -2.2e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Gd</th>        <td>-1.214e+05</td> <td> 9312.510</td> <td>  -13.032</td> <td> 0.000</td> <td> -1.4e+05</td> <td>-1.03e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TA</th>        <td>-2.057e+05</td> <td> 9097.967</td> <td>  -22.605</td> <td> 0.000</td> <td>-2.24e+05</td> <td>-1.88e+05</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>468.582</td> <th>  Durbin-Watson:     </th> <td>   2.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>4338.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.593</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>11.888</td>  <th>  Cond. No.          </th> <td>    15.8</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              SalePrice   R-squared:                       0.451\n",
       "Model:                            OLS   Adj. R-squared:                  0.449\n",
       "Method:                 Least Squares   F-statistic:                     318.6\n",
       "Date:                Tue, 05 Dec 2023   Prob (F-statistic):          5.70e-151\n",
       "Time:                        07:17:26   Log-Likelihood:                -14453.\n",
       "No. Observations:                1168   AIC:                         2.891e+04\n",
       "Df Residuals:                    1164   BIC:                         2.893e+04\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept   3.522e+05   8846.030     39.814      0.000    3.35e+05     3.7e+05\n",
       "Fa         -2.581e+05   1.94e+04    -13.294      0.000   -2.96e+05    -2.2e+05\n",
       "Gd         -1.214e+05   9312.510    -13.032      0.000    -1.4e+05   -1.03e+05\n",
       "TA         -2.057e+05   9097.967    -22.605      0.000   -2.24e+05   -1.88e+05\n",
       "==============================================================================\n",
       "Omnibus:                      468.582   Durbin-Watson:                   2.050\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4338.067\n",
       "Skew:                           1.593   Prob(JB):                         0.00\n",
       "Kurtosis:                      11.888   Cond. No.                         15.8\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nome_feature = 'ExterQual'\n",
    "\n",
    "# Verificação de valores nulos na variável\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Estatística univariádas pela variável\n",
    "print('Verficação da disposição da variável em agurpamento:\\n')\n",
    "agrupado = dados_treino.groupby([nome_feature]).size()\n",
    "print(agrupado)\n",
    "\n",
    "# Conversão da variável categórica em dicotômica com a exclusão da primeira variável dicotômica.\n",
    "df_dummies_auxiliar = pd.get_dummies(dados_treino[nome_feature], columns=[nome_feature], drop_first=True)\n",
    "\n",
    "# Inclusão da variável dependente ao data frame de variáveis dicotômicas.\n",
    "df_dummies_auxiliar[nome_target] = dados_treino[nome_target].copy()\n",
    "\n",
    "# Verificação do data frame.\n",
    "df_dummies_auxiliar.head(6)\n",
    "\n",
    "# Estimação do modelo de regressão linear múltipla com n-1 dummies\n",
    "modelo_dummies = sm.OLS.from_formula(\"SalePrice ~ Fa + Gd + TA\", df_dummies_auxiliar).fit()\n",
    "\n",
    "# Verificação dos parâmetros do modelo.\n",
    "modelo_dummies.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7737183",
   "metadata": {},
   "source": [
    "## ExterCond (Categórica)\n",
    "\n",
    "Avaliação do estadu atual do acabamento externo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2d139f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "Verficação da disposição da variável em agurpamento:\n",
      "\n",
      "ExterCond\n",
      "Ex       3\n",
      "Fa      24\n",
      "Gd     122\n",
      "Po       1\n",
      "TA    1018\n",
      "dtype: int64\n",
      "      Fa  Gd  Po  TA  SalePrice\n",
      "254    0   1   0   0     145000\n",
      "1066   0   0   0   1     178000\n",
      "638    0   0   0   1      85000\n",
      "799    0   0   0   1     175000\n",
      "380    0   0   0   1     127000\n",
      "303    0   0   0   1     149900\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>SalePrice</td>    <th>  R-squared:         </th> <td>   0.025</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.022</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   7.466</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 05 Dec 2023</td> <th>  Prob (F-statistic):</th> <td>6.15e-06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>08:00:47</td>     <th>  Log-Likelihood:    </th> <td> -14788.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.959e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1163</td>      <th>  BIC:               </th> <td>2.961e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td> 2.013e+05</td> <td> 4.41e+04</td> <td>    4.563</td> <td> 0.000</td> <td> 1.15e+05</td> <td> 2.88e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fa</th>        <td>-9.285e+04</td> <td> 4.68e+04</td> <td>   -1.984</td> <td> 0.047</td> <td>-1.85e+05</td> <td>-1028.780</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Gd</th>        <td>-3.354e+04</td> <td> 4.47e+04</td> <td>   -0.751</td> <td> 0.453</td> <td>-1.21e+05</td> <td> 5.41e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Po</th>        <td>-1.248e+05</td> <td> 8.82e+04</td> <td>   -1.415</td> <td> 0.157</td> <td>-2.98e+05</td> <td> 4.83e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TA</th>        <td>-1.649e+04</td> <td> 4.42e+04</td> <td>   -0.373</td> <td> 0.709</td> <td>-1.03e+05</td> <td> 7.02e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>456.258</td> <th>  Durbin-Watson:     </th> <td>   2.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2216.510</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.776</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.739</td>  <th>  Cond. No.          </th> <td>    65.2</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              SalePrice   R-squared:                       0.025\n",
       "Model:                            OLS   Adj. R-squared:                  0.022\n",
       "Method:                 Least Squares   F-statistic:                     7.466\n",
       "Date:                Tue, 05 Dec 2023   Prob (F-statistic):           6.15e-06\n",
       "Time:                        08:00:47   Log-Likelihood:                -14788.\n",
       "No. Observations:                1168   AIC:                         2.959e+04\n",
       "Df Residuals:                    1163   BIC:                         2.961e+04\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept   2.013e+05   4.41e+04      4.563      0.000    1.15e+05    2.88e+05\n",
       "Fa         -9.285e+04   4.68e+04     -1.984      0.047   -1.85e+05   -1028.780\n",
       "Gd         -3.354e+04   4.47e+04     -0.751      0.453   -1.21e+05    5.41e+04\n",
       "Po         -1.248e+05   8.82e+04     -1.415      0.157   -2.98e+05    4.83e+04\n",
       "TA         -1.649e+04   4.42e+04     -0.373      0.709   -1.03e+05    7.02e+04\n",
       "==============================================================================\n",
       "Omnibus:                      456.258   Durbin-Watson:                   2.050\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2216.510\n",
       "Skew:                           1.776   Prob(JB):                         0.00\n",
       "Kurtosis:                       8.739   Cond. No.                         65.2\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nome_feature = 'ExterCond'\n",
    "\n",
    "# Verificação de valores nulos na variável\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Estatística univariádas pela variável\n",
    "print('Verficação da disposição da variável em agurpamento:\\n')\n",
    "agrupado = dados_treino.groupby([nome_feature]).size()\n",
    "print(agrupado)\n",
    "\n",
    "# Conversão da variável categórica em dicotômica com a exclusão da primeira variável dicotômica.\n",
    "df_dummies_auxiliar = pd.get_dummies(dados_treino[nome_feature], columns=[nome_feature], drop_first=True)\n",
    "\n",
    "# Inclusão da variável dependente ao data frame de variáveis dicotômicas.\n",
    "df_dummies_auxiliar[nome_target] = dados_treino[nome_target].copy()\n",
    "\n",
    "# Verificação do data frame.\n",
    "print(df_dummies_auxiliar.head(6))\n",
    "\n",
    "# Estimação do modelo de regressão linear múltipla com n-1 dummies\n",
    "modelo_dummies = sm.OLS.from_formula(\"SalePrice ~ Fa + Gd + Po + TA\", df_dummies_auxiliar).fit()\n",
    "\n",
    "# Verificação dos parâmetros do modelo.\n",
    "modelo_dummies.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c477b2",
   "metadata": {},
   "source": [
    "## Foundation (Categórica)\n",
    "\n",
    "Tipo de fundação do imóvel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "bf14b0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "Verficação da disposição da variável em agurpamento:\n",
      "\n",
      "Foundation\n",
      "BrkTil    116\n",
      "CBlock    504\n",
      "PConc     520\n",
      "Slab       20\n",
      "Stone       5\n",
      "Wood        3\n",
      "dtype: int64\n",
      "\n",
      "      CBlock  PConc  Slab  Stone  Wood  SalePrice\n",
      "254        1      0     0      0     0     145000\n",
      "1066       0      1     0      0     0     178000\n",
      "638        1      0     0      0     0      85000\n",
      "799        0      0     0      0     0     175000\n",
      "380        0      0     0      0     0     127000\n",
      "303        0      1     0      0     0     149900\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>SalePrice</td>    <th>  R-squared:         </th> <td>   0.249</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.246</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   77.15</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 05 Dec 2023</td> <th>  Prob (F-statistic):</th> <td>6.12e-70</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>08:04:36</td>     <th>  Log-Likelihood:    </th> <td> -14635.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.928e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1162</td>      <th>  BIC:               </th> <td>2.931e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td> 1.371e+05</td> <td> 6229.130</td> <td>   22.009</td> <td> 0.000</td> <td> 1.25e+05</td> <td> 1.49e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CBlock</th>    <td> 1.389e+04</td> <td> 6908.885</td> <td>    2.011</td> <td> 0.045</td> <td>  335.748</td> <td> 2.74e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PConc</th>     <td> 8.662e+04</td> <td> 6888.969</td> <td>   12.574</td> <td> 0.000</td> <td> 7.31e+04</td> <td>    1e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Slab</th>      <td>-3.027e+04</td> <td> 1.62e+04</td> <td>   -1.863</td> <td> 0.063</td> <td>-6.21e+04</td> <td> 1601.995</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Stone</th>     <td>  4.15e+04</td> <td> 3.06e+04</td> <td>    1.354</td> <td> 0.176</td> <td>-1.86e+04</td> <td> 1.02e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Wood</th>      <td> 4.857e+04</td> <td> 3.92e+04</td> <td>    1.238</td> <td> 0.216</td> <td>-2.84e+04</td> <td> 1.26e+05</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>484.220</td> <th>  Durbin-Watson:     </th> <td>   2.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3031.966</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.801</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>10.023</td>  <th>  Cond. No.          </th> <td>    23.7</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              SalePrice   R-squared:                       0.249\n",
       "Model:                            OLS   Adj. R-squared:                  0.246\n",
       "Method:                 Least Squares   F-statistic:                     77.15\n",
       "Date:                Tue, 05 Dec 2023   Prob (F-statistic):           6.12e-70\n",
       "Time:                        08:04:36   Log-Likelihood:                -14635.\n",
       "No. Observations:                1168   AIC:                         2.928e+04\n",
       "Df Residuals:                    1162   BIC:                         2.931e+04\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept   1.371e+05   6229.130     22.009      0.000    1.25e+05    1.49e+05\n",
       "CBlock      1.389e+04   6908.885      2.011      0.045     335.748    2.74e+04\n",
       "PConc       8.662e+04   6888.969     12.574      0.000    7.31e+04       1e+05\n",
       "Slab       -3.027e+04   1.62e+04     -1.863      0.063   -6.21e+04    1601.995\n",
       "Stone        4.15e+04   3.06e+04      1.354      0.176   -1.86e+04    1.02e+05\n",
       "Wood        4.857e+04   3.92e+04      1.238      0.216   -2.84e+04    1.26e+05\n",
       "==============================================================================\n",
       "Omnibus:                      484.220   Durbin-Watson:                   2.050\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3031.966\n",
       "Skew:                           1.801   Prob(JB):                         0.00\n",
       "Kurtosis:                      10.023   Cond. No.                         23.7\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nome_feature = 'Foundation'\n",
    "\n",
    "# Verificação de valores nulos na variável\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Estatística univariádas pela variável\n",
    "print('Verficação da disposição da variável em agurpamento:\\n')\n",
    "agrupado = dados_treino.groupby([nome_feature]).size()\n",
    "print(agrupado)\n",
    "print()\n",
    "\n",
    "# Conversão da variável categórica em dicotômica com a exclusão da primeira variável dicotômica.\n",
    "df_dummies_auxiliar = pd.get_dummies(dados_treino[nome_feature], columns=[nome_feature], drop_first=True)\n",
    "\n",
    "# Inclusão da variável dependente ao data frame de variáveis dicotômicas.\n",
    "df_dummies_auxiliar[nome_target] = dados_treino[nome_target].copy()\n",
    "\n",
    "# Verificação do data frame.\n",
    "print(df_dummies_auxiliar.head(6))\n",
    "\n",
    "# Estimação do modelo de regressão linear múltipla com n-1 dummies\n",
    "modelo_dummies = sm.OLS.from_formula(\"SalePrice ~ CBlock + PConc + Slab + Stone + Wood\", df_dummies_auxiliar).fit()\n",
    "\n",
    "# Verificação dos parâmetros do modelo.\n",
    "modelo_dummies.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3def389",
   "metadata": {},
   "source": [
    "## BsmtQual (Categórica)\n",
    "\n",
    "Altura do porão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "1e60ace4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 28\n",
      "\n",
      "Verficação da disposição da variável em agurpamento:\n",
      "\n",
      "BsmtQual\n",
      "Ex     97\n",
      "Fa     29\n",
      "Gd    493\n",
      "TA    521\n",
      "dtype: int64\n",
      "\n",
      "Verifcamos que após o agrupamento o valor da moda dessa variável é \"TA\".\n",
      "\n",
      "      Fa  Gd  TA  SalePrice\n",
      "254    0   0   1     145000\n",
      "1066   0   1   0     178000\n",
      "638    1   0   0      85000\n",
      "799    0   1   0     175000\n",
      "380    0   0   1     127000\n",
      "303    0   0   1     149900\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>SalePrice</td>    <th>  R-squared:         </th> <td>   0.455</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.454</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   324.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 05 Dec 2023</td> <th>  Prob (F-statistic):</th> <td>6.28e-153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:43:51</td>     <th>  Log-Likelihood:    </th> <td> -14448.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.890e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1164</td>      <th>  BIC:               </th> <td>2.892e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td> 3.213e+05</td> <td> 5798.336</td> <td>   55.410</td> <td> 0.000</td> <td>  3.1e+05</td> <td> 3.33e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fa</th>        <td>-2.023e+05</td> <td> 1.21e+04</td> <td>  -16.737</td> <td> 0.000</td> <td>-2.26e+05</td> <td>-1.79e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Gd</th>        <td> -1.18e+05</td> <td> 6343.164</td> <td>  -18.599</td> <td> 0.000</td> <td> -1.3e+05</td> <td>-1.06e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TA</th>        <td>-1.809e+05</td> <td> 6289.751</td> <td>  -28.759</td> <td> 0.000</td> <td>-1.93e+05</td> <td>-1.69e+05</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>379.239</td> <th>  Durbin-Watson:     </th> <td>   1.997</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2387.778</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.349</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 9.464</td>  <th>  Cond. No.          </th> <td>    9.74</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              SalePrice   R-squared:                       0.455\n",
       "Model:                            OLS   Adj. R-squared:                  0.454\n",
       "Method:                 Least Squares   F-statistic:                     324.1\n",
       "Date:                Tue, 05 Dec 2023   Prob (F-statistic):          6.28e-153\n",
       "Time:                        11:43:51   Log-Likelihood:                -14448.\n",
       "No. Observations:                1168   AIC:                         2.890e+04\n",
       "Df Residuals:                    1164   BIC:                         2.892e+04\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept   3.213e+05   5798.336     55.410      0.000     3.1e+05    3.33e+05\n",
       "Fa         -2.023e+05   1.21e+04    -16.737      0.000   -2.26e+05   -1.79e+05\n",
       "Gd          -1.18e+05   6343.164    -18.599      0.000    -1.3e+05   -1.06e+05\n",
       "TA         -1.809e+05   6289.751    -28.759      0.000   -1.93e+05   -1.69e+05\n",
       "==============================================================================\n",
       "Omnibus:                      379.239   Durbin-Watson:                   1.997\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2387.778\n",
       "Skew:                           1.349   Prob(JB):                         0.00\n",
       "Kurtosis:                       9.464   Cond. No.                         9.74\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nome_feature = 'BsmtQual'\n",
    "\n",
    "# Verificação de valores nulos na variável\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Estatística univariádas pela variável\n",
    "print('Verficação da disposição da variável em agurpamento:\\n')\n",
    "agrupado = dados_treino.groupby([nome_feature]).size()\n",
    "print(agrupado)\n",
    "\n",
    "print(f'\\nVerifcamos que após o agrupamento o valor da moda dessa variável é \"TA\".\\n')\n",
    "\n",
    "# Cópia dos valores que serão manipulados para que os valores originais são sejam alterados.\n",
    "df_dummies_auxiliar_1 = dados_treino[nome_feature].copy()\n",
    "\n",
    "# Eliminação dos valores não válidas pelo valor da moda.\n",
    "df_dummies_auxiliar_1.fillna('TA', inplace = True)\n",
    "\n",
    "# Conversão da variável categórica em dicotômica com a exclusão da primeira variável dicotômica.\n",
    "df_dummies_auxiliar = pd.get_dummies(df_dummies_auxiliar_1, columns=[nome_feature], drop_first=True)\n",
    "\n",
    "# Inclusão da variável dependente ao data frame de variáveis dicotômicas.\n",
    "df_dummies_auxiliar[nome_target] = dados_treino[nome_target].copy()\n",
    "\n",
    "# Verificação do data frame.\n",
    "print(df_dummies_auxiliar.head(6))\n",
    "\n",
    "# Estimação do modelo de regressão linear múltipla com n-1 dummies\n",
    "modelo_dummies = sm.OLS.from_formula(\"SalePrice ~ Fa + Gd + TA\", df_dummies_auxiliar).fit()\n",
    "\n",
    "# Verificação dos parâmetros do modelo.\n",
    "modelo_dummies.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11b7d20",
   "metadata": {},
   "source": [
    "## BsmtCond (Categórica)\n",
    "\n",
    "Condição geral do porão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "5f971bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 28\n",
      "\n",
      "Verficação da disposição da variável em agurpamento:\n",
      "\n",
      "BsmtCond\n",
      "Fa      39\n",
      "Gd      55\n",
      "Po       1\n",
      "TA    1045\n",
      "dtype: int64\n",
      "\n",
      "Verifcamos que após o agrupamento o valor da moda dessa variável é \"TA\".\n",
      "\n",
      "      Gd  Po  TA  SalePrice\n",
      "254    0   0   1     145000\n",
      "1066   0   0   1     178000\n",
      "638    0   0   1      85000\n",
      "799    0   0   1     175000\n",
      "380    0   0   1     127000\n",
      "303    0   0   1     149900\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>SalePrice</td>    <th>  R-squared:         </th> <td>   0.029</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.026</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   11.48</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 05 Dec 2023</td> <th>  Prob (F-statistic):</th> <td>2.03e-07</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:44:00</td>     <th>  Log-Likelihood:    </th> <td> -14786.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.958e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1164</td>      <th>  BIC:               </th> <td>2.960e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td> 1.219e+05</td> <td> 1.22e+04</td> <td>    9.987</td> <td> 0.000</td> <td>  9.8e+04</td> <td> 1.46e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Gd</th>        <td> 8.871e+04</td> <td>  1.6e+04</td> <td>    5.558</td> <td> 0.000</td> <td> 5.74e+04</td> <td>  1.2e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Po</th>        <td>-6.093e+04</td> <td> 7.72e+04</td> <td>   -0.789</td> <td> 0.430</td> <td>-2.12e+05</td> <td> 9.06e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TA</th>        <td> 6.029e+04</td> <td> 1.24e+04</td> <td>    4.851</td> <td> 0.000</td> <td> 3.59e+04</td> <td> 8.47e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>459.730</td> <th>  Durbin-Watson:     </th> <td>   2.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2243.525</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.790</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.770</td>  <th>  Cond. No.          </th> <td>    47.5</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              SalePrice   R-squared:                       0.029\n",
       "Model:                            OLS   Adj. R-squared:                  0.026\n",
       "Method:                 Least Squares   F-statistic:                     11.48\n",
       "Date:                Tue, 05 Dec 2023   Prob (F-statistic):           2.03e-07\n",
       "Time:                        11:44:00   Log-Likelihood:                -14786.\n",
       "No. Observations:                1168   AIC:                         2.958e+04\n",
       "Df Residuals:                    1164   BIC:                         2.960e+04\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept   1.219e+05   1.22e+04      9.987      0.000     9.8e+04    1.46e+05\n",
       "Gd          8.871e+04    1.6e+04      5.558      0.000    5.74e+04     1.2e+05\n",
       "Po         -6.093e+04   7.72e+04     -0.789      0.430   -2.12e+05    9.06e+04\n",
       "TA          6.029e+04   1.24e+04      4.851      0.000    3.59e+04    8.47e+04\n",
       "==============================================================================\n",
       "Omnibus:                      459.730   Durbin-Watson:                   2.018\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2243.525\n",
       "Skew:                           1.790   Prob(JB):                         0.00\n",
       "Kurtosis:                       8.770   Cond. No.                         47.5\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nome_feature = 'BsmtCond'\n",
    "\n",
    "# Verificação de valores nulos na variável\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Estatística univariádas pela variável\n",
    "print('Verficação da disposição da variável em agurpamento:\\n')\n",
    "agrupado = dados_treino.groupby([nome_feature]).size()\n",
    "print(agrupado)\n",
    "\n",
    "print(f'\\nVerifcamos que após o agrupamento o valor da moda dessa variável é \"TA\".\\n')\n",
    "\n",
    "# Cópia dos valores que serão manipulados para que os valores originais são sejam alterados.\n",
    "df_dummies_auxiliar_1 = dados_treino[nome_feature].copy()\n",
    "\n",
    "# Eliminação dos valores não válidas pelo valor da moda.\n",
    "df_dummies_auxiliar_1.fillna('TA', inplace = True)\n",
    "\n",
    "# Conversão da variável categórica em dicotômica com a exclusão da primeira variável dicotômica.\n",
    "df_dummies_auxiliar = pd.get_dummies(df_dummies_auxiliar_1, columns=[nome_feature], drop_first=True)\n",
    "\n",
    "# Inclusão da variável dependente ao data frame de variáveis dicotômicas.\n",
    "df_dummies_auxiliar[nome_target] = dados_treino[nome_target].copy()\n",
    "\n",
    "# Verificação do data frame.\n",
    "print(df_dummies_auxiliar.head(6))\n",
    "\n",
    "# Estimação do modelo de regressão linear múltipla com n-1 dummies\n",
    "modelo_dummies = sm.OLS.from_formula(\"SalePrice ~ Gd + Po + TA\", df_dummies_auxiliar).fit()\n",
    "\n",
    "# Verificação dos parâmetros do modelo.\n",
    "modelo_dummies.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4e54c5",
   "metadata": {},
   "source": [
    "## BsmtExposure (Categórica)\n",
    "\n",
    "Condições das paredes do térreo ou do jardim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "492628fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 28\n",
      "\n",
      "Verficação da disposição da variável em agurpamento:\n",
      "\n",
      "BsmtExposure\n",
      "Av    175\n",
      "Gd    103\n",
      "Mn     93\n",
      "No    769\n",
      "dtype: int64\n",
      "\n",
      "Verifcamos que após o agrupamento o valor da moda dessa variável é \"No\".\n",
      "\n",
      "      Gd  Mn  No  SalePrice\n",
      "254    0   0   1     145000\n",
      "1066   0   0   1     178000\n",
      "638    0   0   1      85000\n",
      "799    0   0   1     175000\n",
      "380    0   0   1     127000\n",
      "303    0   0   1     149900\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>SalePrice</td>    <th>  R-squared:         </th> <td>   0.124</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.122</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   55.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 05 Dec 2023</td> <th>  Prob (F-statistic):</th> <td>3.02e-33</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:44:36</td>     <th>  Log-Likelihood:    </th> <td> -14725.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.946e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1164</td>      <th>  BIC:               </th> <td>2.948e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td> 2.128e+05</td> <td> 5473.067</td> <td>   38.886</td> <td> 0.000</td> <td> 2.02e+05</td> <td> 2.24e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Gd</th>        <td>  3.37e+04</td> <td> 8991.550</td> <td>    3.748</td> <td> 0.000</td> <td> 1.61e+04</td> <td> 5.13e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Mn</th>        <td>-1.582e+04</td> <td> 9290.877</td> <td>   -1.703</td> <td> 0.089</td> <td>-3.41e+04</td> <td> 2407.462</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No</th>        <td>-4.851e+04</td> <td> 6044.143</td> <td>   -8.025</td> <td> 0.000</td> <td>-6.04e+04</td> <td>-3.66e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>380.622</td> <th>  Durbin-Watson:     </th> <td>   2.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1556.939</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.508</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 7.786</td>  <th>  Cond. No.          </th> <td>    7.27</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              SalePrice   R-squared:                       0.124\n",
       "Model:                            OLS   Adj. R-squared:                  0.122\n",
       "Method:                 Least Squares   F-statistic:                     55.00\n",
       "Date:                Tue, 05 Dec 2023   Prob (F-statistic):           3.02e-33\n",
       "Time:                        11:44:36   Log-Likelihood:                -14725.\n",
       "No. Observations:                1168   AIC:                         2.946e+04\n",
       "Df Residuals:                    1164   BIC:                         2.948e+04\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept   2.128e+05   5473.067     38.886      0.000    2.02e+05    2.24e+05\n",
       "Gd           3.37e+04   8991.550      3.748      0.000    1.61e+04    5.13e+04\n",
       "Mn         -1.582e+04   9290.877     -1.703      0.089   -3.41e+04    2407.462\n",
       "No         -4.851e+04   6044.143     -8.025      0.000   -6.04e+04   -3.66e+04\n",
       "==============================================================================\n",
       "Omnibus:                      380.622   Durbin-Watson:                   2.033\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1556.939\n",
       "Skew:                           1.508   Prob(JB):                         0.00\n",
       "Kurtosis:                       7.786   Cond. No.                         7.27\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nome_feature = 'BsmtExposure'\n",
    "\n",
    "# Verificação de valores nulos na variável\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Estatística univariádas pela variável\n",
    "print('Verficação da disposição da variável em agurpamento:\\n')\n",
    "agrupado = dados_treino.groupby([nome_feature]).size()\n",
    "print(agrupado)\n",
    "\n",
    "print(f'\\nVerifcamos que após o agrupamento o valor da moda dessa variável é \"No\".\\n')\n",
    "\n",
    "# Cópia dos valores que serão manipulados para que os valores originais são sejam alterados.\n",
    "df_dummies_auxiliar_1 = dados_treino[nome_feature].copy()\n",
    "\n",
    "# Eliminação dos valores não válidas pelo valor da moda.\n",
    "df_dummies_auxiliar_1.fillna('No', inplace = True)\n",
    "\n",
    "# Conversão da variável categórica em dicotômica com a exclusão da primeira variável dicotômica.\n",
    "df_dummies_auxiliar = pd.get_dummies(df_dummies_auxiliar_1, columns=[nome_feature], drop_first=True)\n",
    "\n",
    "# Inclusão da variável dependente ao data frame de variáveis dicotômicas.\n",
    "df_dummies_auxiliar[nome_target] = dados_treino[nome_target].copy()\n",
    "\n",
    "# Verificação do data frame.\n",
    "print(df_dummies_auxiliar.head(6))\n",
    "\n",
    "# Estimação do modelo de regressão linear múltipla com n-1 dummies\n",
    "modelo_dummies = sm.OLS.from_formula(\"SalePrice ~ Gd + Mn + No\", df_dummies_auxiliar).fit()\n",
    "\n",
    "# Verificação dos parâmetros do modelo.\n",
    "modelo_dummies.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52809a8f",
   "metadata": {},
   "source": [
    "## BsmtFinType1 (Categórica)\n",
    "\n",
    "Classificação da área finalizada do porão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "76c57853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 28\n",
      "\n",
      "Verficação da disposição da variável em agurpamento:\n",
      "\n",
      "BsmtFinType1\n",
      "ALQ    178\n",
      "BLQ    123\n",
      "GLQ    328\n",
      "LwQ     62\n",
      "Rec    104\n",
      "Unf    345\n",
      "dtype: int64\n",
      "\n",
      "Verifcamos que após o agrupamento o valor da moda dessa variável é \"Unf\".\n",
      "\n",
      "      BLQ  GLQ  LwQ  Rec  Unf  SalePrice\n",
      "254     0    0    0    1    0     145000\n",
      "1066    0    0    0    0    1     178000\n",
      "638     0    0    0    0    1      85000\n",
      "799     0    0    0    0    0     175000\n",
      "380     0    0    1    0    0     127000\n",
      "303     0    0    0    0    0     149900\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>SalePrice</td>    <th>  R-squared:         </th> <td>   0.190</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.187</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   54.57</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 05 Dec 2023</td> <th>  Prob (F-statistic):</th> <td>5.37e-51</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:48:37</td>     <th>  Log-Likelihood:    </th> <td> -14679.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.937e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1162</td>      <th>  BIC:               </th> <td>2.940e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td> 1.609e+05</td> <td> 5222.749</td> <td>   30.817</td> <td> 0.000</td> <td> 1.51e+05</td> <td> 1.71e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BLQ</th>       <td>-9070.2213</td> <td> 8170.147</td> <td>   -1.110</td> <td> 0.267</td> <td>-2.51e+04</td> <td> 6959.669</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>GLQ</th>       <td> 7.318e+04</td> <td> 6486.904</td> <td>   11.282</td> <td> 0.000</td> <td> 6.05e+04</td> <td> 8.59e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LwQ</th>       <td>-1.078e+04</td> <td> 1.03e+04</td> <td>   -1.049</td> <td> 0.295</td> <td>-3.09e+04</td> <td> 9385.610</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Rec</th>       <td>-1.264e+04</td> <td> 8600.170</td> <td>   -1.470</td> <td> 0.142</td> <td>-2.95e+04</td> <td> 4232.963</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Unf</th>       <td> 8127.7457</td> <td> 6347.761</td> <td>    1.280</td> <td> 0.201</td> <td>-4326.609</td> <td> 2.06e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>440.874</td> <th>  Durbin-Watson:     </th> <td>   2.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2358.867</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.668</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 9.110</td>  <th>  Cond. No.          </th> <td>    7.66</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              SalePrice   R-squared:                       0.190\n",
       "Model:                            OLS   Adj. R-squared:                  0.187\n",
       "Method:                 Least Squares   F-statistic:                     54.57\n",
       "Date:                Tue, 05 Dec 2023   Prob (F-statistic):           5.37e-51\n",
       "Time:                        11:48:37   Log-Likelihood:                -14679.\n",
       "No. Observations:                1168   AIC:                         2.937e+04\n",
       "Df Residuals:                    1162   BIC:                         2.940e+04\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept   1.609e+05   5222.749     30.817      0.000    1.51e+05    1.71e+05\n",
       "BLQ        -9070.2213   8170.147     -1.110      0.267   -2.51e+04    6959.669\n",
       "GLQ         7.318e+04   6486.904     11.282      0.000    6.05e+04    8.59e+04\n",
       "LwQ        -1.078e+04   1.03e+04     -1.049      0.295   -3.09e+04    9385.610\n",
       "Rec        -1.264e+04   8600.170     -1.470      0.142   -2.95e+04    4232.963\n",
       "Unf         8127.7457   6347.761      1.280      0.201   -4326.609    2.06e+04\n",
       "==============================================================================\n",
       "Omnibus:                      440.874   Durbin-Watson:                   2.073\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2358.867\n",
       "Skew:                           1.668   Prob(JB):                         0.00\n",
       "Kurtosis:                       9.110   Cond. No.                         7.66\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nome_feature = 'BsmtFinType1'\n",
    "\n",
    "# Verificação de valores nulos na variável\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Estatística univariádas pela variável\n",
    "print('Verficação da disposição da variável em agurpamento:\\n')\n",
    "agrupado = dados_treino.groupby([nome_feature]).size()\n",
    "print(agrupado)\n",
    "\n",
    "print(f'\\nVerifcamos que após o agrupamento o valor da moda dessa variável é \"Unf\".\\n')\n",
    "\n",
    "# Cópia dos valores que serão manipulados para que os valores originais são sejam alterados.\n",
    "df_dummies_auxiliar_1 = dados_treino[nome_feature].copy()\n",
    "\n",
    "# Eliminação dos valores não válidas pelo valor da moda.\n",
    "df_dummies_auxiliar_1.fillna('Unf', inplace = True)\n",
    "\n",
    "# Conversão da variável categórica em dicotômica com a exclusão da primeira variável dicotômica.\n",
    "df_dummies_auxiliar = pd.get_dummies(df_dummies_auxiliar_1, columns=[nome_feature], drop_first=True)\n",
    "\n",
    "# Inclusão da variável dependente ao data frame de variáveis dicotômicas.\n",
    "df_dummies_auxiliar[nome_target] = dados_treino[nome_target].copy()\n",
    "\n",
    "# Verificação do data frame.\n",
    "print(df_dummies_auxiliar.head(6))\n",
    "\n",
    "# Estimação do modelo de regressão linear múltipla com n-1 dummies\n",
    "modelo_dummies = sm.OLS.from_formula(\"SalePrice ~ BLQ + GLQ + LwQ + Rec + Unf\", df_dummies_auxiliar).fit()\n",
    "\n",
    "# Verificação dos parâmetros do modelo.\n",
    "modelo_dummies.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4b06eb",
   "metadata": {},
   "source": [
    "## BsmtFinSF1 (Numérica)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a8da89bf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "\n",
      "Correlação entre BsmtFinSF1 e SalePrice\n",
      "\n",
      "            BsmtFinSF1  SalePrice\n",
      "BsmtFinSF1     1.00000    0.35946\n",
      "SalePrice      0.35946    1.00000\n",
      "\n",
      "Correlação entre ln<BsmtFinSF1> e ln<SalePrice>\n",
      "\n",
      "            BsmtFinSF1  SalePrice\n",
      "BsmtFinSF1    1.000000   0.181611\n",
      "SalePrice     0.181611   1.000000\n",
      "\n",
      "Correlação entre BsmtFinSF1 e SalePrice SEM OUTLIER\n",
      "\n",
      "            BsmtFinSF1  SalePrice\n",
      "BsmtFinSF1    1.000000   0.335119\n",
      "SalePrice     0.335119   1.000000\n",
      "\n",
      "Correlação entre ln<BsmtFinSF1> e ln<SalePrice> SEM OUTLIER\n",
      "\n",
      "            BsmtFinSF1  SalePrice\n",
      "BsmtFinSF1    1.000000   0.175794\n",
      "SalePrice     0.175794   1.000000\n",
      "\n",
      "Quantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "\n",
      "Quantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\John\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "nome_feature = 'BsmtFinSF1'\n",
    "\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# # Substituição de valores não válidos pela mediana da variável em ambos os data frames.\n",
    "# dados_treino[nome_feature].fillna(dados_treino[nome_feature].median(), inplace = True)\n",
    "# df_sem_outlier[nome_feature].fillna(df_sem_outlier[nome_feature].median(), inplace = True)\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target}\\n\")\n",
    "print(dados_treino[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}>\\n\")\n",
    "\n",
    "# df_ln[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln[nome_feature] = np.where(dados_treino[nome_feature] == 0, 1, np.log(dados_treino[nome_feature]))\n",
    "df_ln[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores maiores que mediana + 3 vezes o desvio padrão.\n",
    "med = df_sem_outlier[nome_feature].median()\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] >= (df_sem_outlier[nome_feature].median() + 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores MENOR que mediana - 3 vezes o desvio padrão.\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] <= (df_sem_outlier[nome_feature].median() - 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target} SEM OUTLIER\\n\")\n",
    "print(df_sem_outlier[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}> SEM OUTLIER\\n\")\n",
    "\n",
    "# df_ln_sem_outlier[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln_sem_outlier[nome_feature] = np.where(dados_treino[nome_feature] == 0, 1, np.log(dados_treino[nome_feature]))\n",
    "df_ln_sem_outlier[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln_sem_outlier[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# ARMAZENAMENTO DAS FEATURES CASO SEJAM UTILIZADAS NO MODELO DE REGRESSÃO LINEAR.\n",
    "\n",
    "# Armazenamento da feature não transformada.\n",
    "features_numericas[nome_feature] = dados_treino[nome_feature]\n",
    "\n",
    "# Armezenamento da feature transformada com ln.\n",
    "features_ln_numericas[nome_feature] = df_ln[nome_feature]\n",
    "\n",
    "# Armazenamento da feature não transformada.\n",
    "features_numericas_sem_outlier[nome_feature] = df_sem_outlier[nome_feature]\n",
    "\n",
    "# Armezenamento da feature transformada com ln.\n",
    "features_ln_numericas_sem_outlier[nome_feature] = df_ln_sem_outlier[nome_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b53c803",
   "metadata": {},
   "source": [
    "## BsmtFinType2 (Categórica)\n",
    "\n",
    "Classificação da área finalizada do porão (se houver múltiplos tipos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "fc2c38f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 28\n",
      "\n",
      "Verficação da disposição da variável em agurpamento:\n",
      "\n",
      "BsmtFinType2\n",
      "ALQ      17\n",
      "BLQ      22\n",
      "GLQ      10\n",
      "LwQ      36\n",
      "Rec      46\n",
      "Unf    1009\n",
      "dtype: int64\n",
      "\n",
      "Após o agrupamento é possivel afirmar que a moda dessa variável é \"Unf\".\n",
      "\n",
      "      BLQ  GLQ  LwQ  Rec  Unf  SalePrice\n",
      "254     0    0    0    0    1     145000\n",
      "1066    0    0    0    0    1     178000\n",
      "638     0    0    0    0    1      85000\n",
      "799     0    0    0    0    1     175000\n",
      "380     0    0    0    0    1     127000\n",
      "303     0    0    0    0    1     149900\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>SalePrice</td>    <th>  R-squared:         </th> <td>   0.007</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.003</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1.638</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 05 Dec 2023</td> <th>  Prob (F-statistic):</th>  <td> 0.147</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:55:51</td>     <th>  Log-Likelihood:    </th> <td> -14799.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.961e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1162</td>      <th>  BIC:               </th> <td>2.964e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td> 2.094e+05</td> <td> 1.87e+04</td> <td>   11.189</td> <td> 0.000</td> <td> 1.73e+05</td> <td> 2.46e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BLQ</th>       <td>-5.137e+04</td> <td> 2.49e+04</td> <td>   -2.062</td> <td> 0.039</td> <td>   -1e+05</td> <td>-2482.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>GLQ</th>       <td>-1.127e+04</td> <td> 3.07e+04</td> <td>   -0.366</td> <td> 0.714</td> <td>-7.16e+04</td> <td> 4.91e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LwQ</th>       <td>-4.521e+04</td> <td> 2.27e+04</td> <td>   -1.991</td> <td> 0.047</td> <td>-8.98e+04</td> <td> -656.854</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Rec</th>       <td>-4.169e+04</td> <td> 2.19e+04</td> <td>   -1.903</td> <td> 0.057</td> <td>-8.47e+04</td> <td> 1281.436</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Unf</th>       <td>-2.687e+04</td> <td> 1.89e+04</td> <td>   -1.424</td> <td> 0.155</td> <td>-6.39e+04</td> <td> 1.01e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>436.282</td> <th>  Durbin-Watson:     </th> <td>   2.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1973.905</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.714</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.367</td>  <th>  Cond. No.          </th> <td>    28.9</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              SalePrice   R-squared:                       0.007\n",
       "Model:                            OLS   Adj. R-squared:                  0.003\n",
       "Method:                 Least Squares   F-statistic:                     1.638\n",
       "Date:                Tue, 05 Dec 2023   Prob (F-statistic):              0.147\n",
       "Time:                        11:55:51   Log-Likelihood:                -14799.\n",
       "No. Observations:                1168   AIC:                         2.961e+04\n",
       "Df Residuals:                    1162   BIC:                         2.964e+04\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept   2.094e+05   1.87e+04     11.189      0.000    1.73e+05    2.46e+05\n",
       "BLQ        -5.137e+04   2.49e+04     -2.062      0.039      -1e+05   -2482.160\n",
       "GLQ        -1.127e+04   3.07e+04     -0.366      0.714   -7.16e+04    4.91e+04\n",
       "LwQ        -4.521e+04   2.27e+04     -1.991      0.047   -8.98e+04    -656.854\n",
       "Rec        -4.169e+04   2.19e+04     -1.903      0.057   -8.47e+04    1281.436\n",
       "Unf        -2.687e+04   1.89e+04     -1.424      0.155   -6.39e+04    1.01e+04\n",
       "==============================================================================\n",
       "Omnibus:                      436.282   Durbin-Watson:                   2.033\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1973.905\n",
       "Skew:                           1.714   Prob(JB):                         0.00\n",
       "Kurtosis:                       8.367   Cond. No.                         28.9\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nome_feature = 'BsmtFinType2'\n",
    "\n",
    "# Verificação de valores nulos na variável\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Estatística univariádas pela variável\n",
    "print('Verficação da disposição da variável em agurpamento:\\n')\n",
    "agrupado = dados_treino.groupby([nome_feature]).size()\n",
    "print(agrupado)\n",
    "\n",
    "print(f'\\nApós o agrupamento é possivel afirmar que a moda dessa variável é \"Unf\".\\n')\n",
    "\n",
    "# Cópia dos valores que serão manipulados para que os valores originais são sejam alterados.\n",
    "df_dummies_auxiliar_1 = dados_treino[nome_feature].copy()\n",
    "\n",
    "# Eliminação dos valores não válidas pelo valor da moda.\n",
    "df_dummies_auxiliar_1.fillna('Unf', inplace = True)\n",
    "\n",
    "# Conversão da variável categórica em dicotômica com a exclusão da primeira variável dicotômica.\n",
    "df_dummies_auxiliar = pd.get_dummies(df_dummies_auxiliar_1, columns=[nome_feature], drop_first=True)\n",
    "\n",
    "# Inclusão da variável dependente ao data frame de variáveis dicotômicas.\n",
    "df_dummies_auxiliar[nome_target] = dados_treino[nome_target].copy()\n",
    "\n",
    "# Verificação do data frame.\n",
    "print(df_dummies_auxiliar.head(6))\n",
    "\n",
    "# Estimação do modelo de regressão linear múltipla com n-1 dummies\n",
    "modelo_dummies = sm.OLS.from_formula(\"SalePrice ~ BLQ + GLQ + LwQ + Rec + Unf\", df_dummies_auxiliar).fit()\n",
    "\n",
    "# Verificação dos parâmetros do modelo.\n",
    "modelo_dummies.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43591683",
   "metadata": {},
   "source": [
    "## BsmtFinSF2 (Numérica)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "826fcd2c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "\n",
      "Correlação entre BsmtFinSF2 e SalePrice\n",
      "\n",
      "            BsmtFinSF2  SalePrice\n",
      "BsmtFinSF2    1.000000  -0.005731\n",
      "SalePrice    -0.005731   1.000000\n",
      "\n",
      "Correlação entre ln<BsmtFinSF2> e ln<SalePrice>\n",
      "\n",
      "            BsmtFinSF2  SalePrice\n",
      "BsmtFinSF2    1.000000  -0.016641\n",
      "SalePrice    -0.016641   1.000000\n",
      "\n",
      "Correlação entre BsmtFinSF2 e SalePrice SEM OUTLIER\n",
      "\n",
      "            BsmtFinSF2  SalePrice\n",
      "BsmtFinSF2    1.000000  -0.076548\n",
      "SalePrice    -0.076548   1.000000\n",
      "\n",
      "Correlação entre ln<BsmtFinSF2> e ln<SalePrice> SEM OUTLIER\n",
      "\n",
      "            BsmtFinSF2  SalePrice\n",
      "BsmtFinSF2    1.000000  -0.055942\n",
      "SalePrice    -0.055942   1.000000\n",
      "\n",
      "Quantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "\n",
      "Quantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\John\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "nome_feature = 'BsmtFinSF2'\n",
    "\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# # Substituição de valores não válidos pela mediana da variável em ambos os data frames.\n",
    "# dados_treino[nome_feature].fillna(dados_treino[nome_feature].median(), inplace = True)\n",
    "# df_sem_outlier[nome_feature].fillna(df_sem_outlier[nome_feature].median(), inplace = True)\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target}\\n\")\n",
    "print(dados_treino[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}>\\n\")\n",
    "\n",
    "# df_ln[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln[nome_feature] = np.where(dados_treino[nome_feature] == 0, 1, np.log(dados_treino[nome_feature]))\n",
    "df_ln[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores maiores que mediana + 3 vezes o desvio padrão.\n",
    "med = df_sem_outlier[nome_feature].median()\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] >= (df_sem_outlier[nome_feature].median() + 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores MENOR que mediana - 3 vezes o desvio padrão.\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] <= (df_sem_outlier[nome_feature].median() - 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target} SEM OUTLIER\\n\")\n",
    "print(df_sem_outlier[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}> SEM OUTLIER\\n\")\n",
    "\n",
    "# df_ln_sem_outlier[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln_sem_outlier[nome_feature] = np.where(dados_treino[nome_feature] == 0, 1, np.log(dados_treino[nome_feature]))\n",
    "df_ln_sem_outlier[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln_sem_outlier[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# # ARMAZENAMENTO DAS FEATURES CASO SEJAM UTILIZADAS NO MODELO DE REGRESSÃO LINEAR.\n",
    "\n",
    "# # Armazenamento da feature não transformada.\n",
    "# features_numericas[nome_feature] = dados_treino[nome_feature]\n",
    "\n",
    "# # Armezenamento da feature transformada com ln.\n",
    "# features_ln_numericas[nome_feature] = df_ln[nome_feature]\n",
    "\n",
    "# # Armazenamento da feature não transformada.\n",
    "# features_numericas_sem_outlier[nome_feature] = df_sem_outlier[nome_feature]\n",
    "\n",
    "# # Armezenamento da feature transformada com ln.\n",
    "# features_ln_numericas_sem_outlier[nome_feature] = df_ln_sem_outlier[nome_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c961baa3",
   "metadata": {},
   "source": [
    "## BsmtUnfSF (Numérica)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c66db79d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "\n",
      "Correlação entre BsmtUnfSF e SalePrice\n",
      "\n",
      "           BsmtUnfSF  SalePrice\n",
      "BsmtUnfSF   1.000000   0.222487\n",
      "SalePrice   0.222487   1.000000\n",
      "\n",
      "Correlação entre ln<BsmtUnfSF> e ln<SalePrice>\n",
      "\n",
      "           BsmtUnfSF  SalePrice\n",
      "BsmtUnfSF   1.000000   0.094597\n",
      "SalePrice   0.094597   1.000000\n",
      "\n",
      "Correlação entre BsmtUnfSF e SalePrice SEM OUTLIER\n",
      "\n",
      "           BsmtUnfSF  SalePrice\n",
      "BsmtUnfSF   1.000000   0.162155\n",
      "SalePrice   0.162155   1.000000\n",
      "\n",
      "Correlação entre ln<BsmtUnfSF> e ln<SalePrice> SEM OUTLIER\n",
      "\n",
      "           BsmtUnfSF  SalePrice\n",
      "BsmtUnfSF   1.000000   0.067187\n",
      "SalePrice   0.067187   1.000000\n",
      "\n",
      "Quantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: 92\n",
      "\n",
      "Quantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "\n",
      "Quantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nome_feature = 'BsmtUnfSF'\n",
    "\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# # Substituição de valores não válidos pela mediana da variável em ambos os data frames.\n",
    "# dados_treino[nome_feature].fillna(dados_treino[nome_feature].median(), inplace = True)\n",
    "# df_sem_outlier[nome_feature].fillna(df_sem_outlier[nome_feature].median(), inplace = True)\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target}\\n\")\n",
    "print(dados_treino[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}>\\n\")\n",
    "\n",
    "df_ln[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores maiores que mediana + 3 vezes o desvio padrão.\n",
    "med = df_sem_outlier[nome_feature].median()\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] >= (df_sem_outlier[nome_feature].median() + 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores MENOR que mediana - 3 vezes o desvio padrão.\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] <= (df_sem_outlier[nome_feature].median() - 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target} SEM OUTLIER\\n\")\n",
    "print(df_sem_outlier[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}> SEM OUTLIER\\n\")\n",
    "\n",
    "df_ln_sem_outlier[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln_sem_outlier[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln_sem_outlier[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# # ARMAZENAMENTO DAS FEATURES CASO SEJAM UTILIZADAS NO MODELO DE REGRESSÃO LINEAR.\n",
    "\n",
    "# # Armazenamento da feature não transformada.\n",
    "# features_numericas[nome_feature] = dados_treino[nome_feature]\n",
    "\n",
    "# # Armezenamento da feature transformada com ln.\n",
    "# features_ln_numericas[nome_feature] = df_ln[nome_feature]\n",
    "\n",
    "# # Armazenamento da feature não transformada.\n",
    "# features_numericas_sem_outlier[nome_feature] = df_sem_outlier[nome_feature]\n",
    "\n",
    "# # Armezenamento da feature transformada com ln.\n",
    "# features_ln_numericas_sem_outlier[nome_feature] = df_ln_sem_outlier[nome_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4348b68",
   "metadata": {},
   "source": [
    "## TotalBsmtSF (Numérica)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d143d0ad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "\n",
      "Correlação entre TotalBsmtSF e SalePrice\n",
      "\n",
      "             TotalBsmtSF  SalePrice\n",
      "TotalBsmtSF     1.000000   0.597766\n",
      "SalePrice       0.597766   1.000000\n",
      "\n",
      "Correlação entre ln<TotalBsmtSF> e ln<SalePrice>\n",
      "\n",
      "             TotalBsmtSF  SalePrice\n",
      "TotalBsmtSF     1.000000   0.591487\n",
      "SalePrice       0.591487   1.000000\n",
      "\n",
      "Correlação entre TotalBsmtSF e SalePrice SEM OUTLIER\n",
      "\n",
      "             TotalBsmtSF  SalePrice\n",
      "TotalBsmtSF     1.000000   0.588824\n",
      "SalePrice       0.588824   1.000000\n",
      "\n",
      "Correlação entre ln<TotalBsmtSF> e ln<SalePrice> SEM OUTLIER\n",
      "\n",
      "             TotalBsmtSF  SalePrice\n",
      "TotalBsmtSF     1.000000   0.574535\n",
      "SalePrice       0.574535   1.000000\n",
      "\n",
      "Quantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: 28\n",
      "\n",
      "Quantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "\n",
      "Quantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nome_feature = 'TotalBsmtSF'\n",
    "\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# # Substituição de valores não válidos pela mediana da variável em ambos os data frames.\n",
    "# dados_treino[nome_feature].fillna(dados_treino[nome_feature].median(), inplace = True)\n",
    "# df_sem_outlier[nome_feature].fillna(df_sem_outlier[nome_feature].median(), inplace = True)\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target}\\n\")\n",
    "print(dados_treino[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}>\\n\")\n",
    "\n",
    "df_ln[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores maiores que mediana + 3 vezes o desvio padrão.\n",
    "med = df_sem_outlier[nome_feature].median()\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] >= (df_sem_outlier[nome_feature].median() + 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores MENOR que mediana - 3 vezes o desvio padrão.\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] <= (df_sem_outlier[nome_feature].median() - 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target} SEM OUTLIER\\n\")\n",
    "print(df_sem_outlier[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}> SEM OUTLIER\\n\")\n",
    "\n",
    "df_ln_sem_outlier[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln_sem_outlier[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln_sem_outlier[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# # ARMAZENAMENTO DAS FEATURES CASO SEJAM UTILIZADAS NO MODELO DE REGRESSÃO LINEAR.\n",
    "\n",
    "# # Armazenamento da feature não transformada.\n",
    "# features_numericas[nome_feature] = dados_treino[nome_feature]\n",
    "\n",
    "# # Armezenamento da feature transformada com ln.\n",
    "# features_ln_numericas[nome_feature] = df_ln[nome_feature]\n",
    "\n",
    "# # Armazenamento da feature não transformada.\n",
    "# features_numericas_sem_outlier[nome_feature] = df_sem_outlier[nome_feature]\n",
    "\n",
    "# # Armezenamento da feature transformada com ln.\n",
    "# features_ln_numericas_sem_outlier[nome_feature] = df_ln_sem_outlier[nome_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7297fed4",
   "metadata": {},
   "source": [
    "## Heating (Categórica)\n",
    "\n",
    "Tipo de sistema de aquecimento do imóvel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "1e0037bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "Verficação da disposição da variável em agurpamento:\n",
      "\n",
      "Heating\n",
      "Floor       1\n",
      "GasA     1140\n",
      "GasW       15\n",
      "Grav        6\n",
      "OthW        2\n",
      "Wall        4\n",
      "dtype: int64\n",
      "\n",
      "Primeiros valores do Data Frame criado.\n",
      "\n",
      "      GasA  GasW  Grav  OthW  Wall  SalePrice\n",
      "254      1     0     0     0     0     145000\n",
      "1066     1     0     0     0     0     178000\n",
      "638      1     0     0     0     0      85000\n",
      "799      1     0     0     0     0     175000\n",
      "380      1     0     0     0     0     127000\n",
      "303      1     0     0     0     0     149900\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>SalePrice</td>    <th>  R-squared:         </th> <td>   0.017</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.013</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   4.021</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 05 Dec 2023</td> <th>  Prob (F-statistic):</th>  <td>0.00127</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:53:28</td>     <th>  Log-Likelihood:    </th> <td> -14793.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.960e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1162</td>      <th>  BIC:               </th> <td>2.963e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>  7.25e+04</td> <td> 7.68e+04</td> <td>    0.944</td> <td> 0.345</td> <td>-7.81e+04</td> <td> 2.23e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>GasA</th>      <td> 1.102e+05</td> <td> 7.68e+04</td> <td>    1.434</td> <td> 0.152</td> <td>-4.05e+04</td> <td> 2.61e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>GasW</th>      <td> 9.636e+04</td> <td> 7.93e+04</td> <td>    1.215</td> <td> 0.224</td> <td>-5.92e+04</td> <td> 2.52e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Grav</th>      <td> 5316.6667</td> <td> 8.29e+04</td> <td>    0.064</td> <td> 0.949</td> <td>-1.57e+05</td> <td> 1.68e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OthW</th>      <td> 5.325e+04</td> <td>  9.4e+04</td> <td>    0.566</td> <td> 0.571</td> <td>-1.31e+05</td> <td> 2.38e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Wall</th>      <td>  1.96e+04</td> <td> 8.58e+04</td> <td>    0.228</td> <td> 0.819</td> <td>-1.49e+05</td> <td> 1.88e+05</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>452.582</td> <th>  Durbin-Watson:     </th> <td>   2.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2137.591</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.771</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.602</td>  <th>  Cond. No.          </th> <td>    119.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              SalePrice   R-squared:                       0.017\n",
       "Model:                            OLS   Adj. R-squared:                  0.013\n",
       "Method:                 Least Squares   F-statistic:                     4.021\n",
       "Date:                Tue, 05 Dec 2023   Prob (F-statistic):            0.00127\n",
       "Time:                        14:53:28   Log-Likelihood:                -14793.\n",
       "No. Observations:                1168   AIC:                         2.960e+04\n",
       "Df Residuals:                    1162   BIC:                         2.963e+04\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept    7.25e+04   7.68e+04      0.944      0.345   -7.81e+04    2.23e+05\n",
       "GasA        1.102e+05   7.68e+04      1.434      0.152   -4.05e+04    2.61e+05\n",
       "GasW        9.636e+04   7.93e+04      1.215      0.224   -5.92e+04    2.52e+05\n",
       "Grav        5316.6667   8.29e+04      0.064      0.949   -1.57e+05    1.68e+05\n",
       "OthW        5.325e+04    9.4e+04      0.566      0.571   -1.31e+05    2.38e+05\n",
       "Wall         1.96e+04   8.58e+04      0.228      0.819   -1.49e+05    1.88e+05\n",
       "==============================================================================\n",
       "Omnibus:                      452.582   Durbin-Watson:                   2.040\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2137.591\n",
       "Skew:                           1.771   Prob(JB):                         0.00\n",
       "Kurtosis:                       8.602   Cond. No.                         119.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nome_feature = 'Heating'\n",
    "\n",
    "# Verificação de valores nulos na variável\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Estatística univariádas pela variável\n",
    "print('Verficação da disposição da variável em agurpamento:\\n')\n",
    "agrupado = dados_treino.groupby([nome_feature]).size()\n",
    "print(agrupado)\n",
    "\n",
    "# print(f'\\nVerifcamos que após o agrupamento o valor da moda dessa variável é \"No\".\\n')\n",
    "\n",
    "# Cópia dos valores que serão manipulados para que os valores originais são sejam alterados.\n",
    "df_dummies_auxiliar_1 = dados_treino[nome_feature].copy()\n",
    "\n",
    "# # Eliminação dos valores não válidas pelo valor da moda.\n",
    "# df_dummies_auxiliar_1.fillna('No', inplace = True)\n",
    "\n",
    "print(f'\\nPrimeiros valores do Data Frame criado.\\n')\n",
    "\n",
    "# Conversão da variável categórica em dicotômica com a exclusão da primeira variável dicotômica.\n",
    "df_dummies_auxiliar = pd.get_dummies(df_dummies_auxiliar_1, columns=[nome_feature], drop_first=True)\n",
    "\n",
    "# Inclusão da variável dependente ao data frame de variáveis dicotômicas.\n",
    "df_dummies_auxiliar[nome_target] = dados_treino[nome_target].copy()\n",
    "\n",
    "# Verificação do data frame.\n",
    "print(df_dummies_auxiliar.head(6))\n",
    "\n",
    "# Estimação do modelo de regressão linear múltipla com n-1 dummies\n",
    "modelo_dummies = sm.OLS.from_formula(\"SalePrice ~ GasA + GasW + Grav + OthW + Wall\", df_dummies_auxiliar).fit()\n",
    "\n",
    "# Verificação dos parâmetros do modelo.\n",
    "modelo_dummies.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c930b4f0",
   "metadata": {},
   "source": [
    "## HeatingQC (Categórica)\n",
    "\n",
    "Qualidade do sistema de aquecimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "40da20e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "Verficação da disposição da variável em agurpamento:\n",
      "\n",
      "HeatingQC\n",
      "Ex    583\n",
      "Fa     42\n",
      "Gd    195\n",
      "Po      1\n",
      "TA    347\n",
      "dtype: int64\n",
      "\n",
      "Primeiros valores do Data Frame criado.\n",
      "\n",
      "      Fa  Gd  Po  TA  SalePrice\n",
      "254    0   0   0   1     145000\n",
      "1066   0   1   0   0     178000\n",
      "638    0   1   0   0      85000\n",
      "799    0   0   0   0     175000\n",
      "380    0   0   0   1     127000\n",
      "303    0   0   0   1     149900\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>SalePrice</td>    <th>  R-squared:         </th> <td>   0.211</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.208</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   77.81</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 05 Dec 2023</td> <th>  Prob (F-statistic):</th> <td>1.60e-58</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:57:48</td>     <th>  Log-Likelihood:    </th> <td> -14664.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.934e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1163</td>      <th>  BIC:               </th> <td>2.936e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td> 2.165e+05</td> <td> 2847.021</td> <td>   76.062</td> <td> 0.000</td> <td> 2.11e+05</td> <td> 2.22e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fa</th>        <td>-8.878e+04</td> <td>  1.1e+04</td> <td>   -8.084</td> <td> 0.000</td> <td> -1.1e+05</td> <td>-6.72e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Gd</th>        <td>-6.116e+04</td> <td> 5686.738</td> <td>  -10.754</td> <td> 0.000</td> <td>-7.23e+04</td> <td>   -5e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Po</th>        <td>-1.295e+05</td> <td> 6.88e+04</td> <td>   -1.883</td> <td> 0.060</td> <td>-2.65e+05</td> <td> 5439.403</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TA</th>        <td>-7.268e+04</td> <td> 4660.875</td> <td>  -15.595</td> <td> 0.000</td> <td>-8.18e+04</td> <td>-6.35e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>456.479</td> <th>  Durbin-Watson:     </th> <td>   2.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2519.316</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.726</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 9.313</td>  <th>  Cond. No.          </th> <td>    36.4</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              SalePrice   R-squared:                       0.211\n",
       "Model:                            OLS   Adj. R-squared:                  0.208\n",
       "Method:                 Least Squares   F-statistic:                     77.81\n",
       "Date:                Tue, 05 Dec 2023   Prob (F-statistic):           1.60e-58\n",
       "Time:                        14:57:48   Log-Likelihood:                -14664.\n",
       "No. Observations:                1168   AIC:                         2.934e+04\n",
       "Df Residuals:                    1163   BIC:                         2.936e+04\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept   2.165e+05   2847.021     76.062      0.000    2.11e+05    2.22e+05\n",
       "Fa         -8.878e+04    1.1e+04     -8.084      0.000    -1.1e+05   -6.72e+04\n",
       "Gd         -6.116e+04   5686.738    -10.754      0.000   -7.23e+04      -5e+04\n",
       "Po         -1.295e+05   6.88e+04     -1.883      0.060   -2.65e+05    5439.403\n",
       "TA         -7.268e+04   4660.875    -15.595      0.000   -8.18e+04   -6.35e+04\n",
       "==============================================================================\n",
       "Omnibus:                      456.479   Durbin-Watson:                   2.020\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2519.316\n",
       "Skew:                           1.726   Prob(JB):                         0.00\n",
       "Kurtosis:                       9.313   Cond. No.                         36.4\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nome_feature = 'HeatingQC'\n",
    "\n",
    "# Verificação de valores nulos na variável\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Agrupamento para facilitar a visualização da variável.\n",
    "print('Verficação da disposição da variável em agurpamento:\\n')\n",
    "agrupado = dados_treino.groupby([nome_feature]).size()\n",
    "print(agrupado)\n",
    "\n",
    "# Cópia dos valores que serão manipulados para que os valores originais são sejam alterados.\n",
    "df_dummies_auxiliar_1 = dados_treino[nome_feature].copy()\n",
    "\n",
    "print(f'\\nPrimeiros valores do Data Frame criado.\\n')\n",
    "\n",
    "# Conversão da variável categórica em dicotômica com a exclusão da primeira variável dicotômica.\n",
    "df_dummies_auxiliar = pd.get_dummies(df_dummies_auxiliar_1, columns=[nome_feature], drop_first=True)\n",
    "\n",
    "# Inclusão da variável dependente ao data frame de variáveis dicotômicas.\n",
    "df_dummies_auxiliar[nome_target] = dados_treino[nome_target].copy()\n",
    "\n",
    "# Verificação do data frame.\n",
    "print(df_dummies_auxiliar.head(6))\n",
    "\n",
    "# Estimação do modelo de regressão linear múltipla com n-1 dummies\n",
    "modelo_dummies = sm.OLS.from_formula(\"SalePrice ~ Fa + Gd + Po + TA\", df_dummies_auxiliar).fit()\n",
    "\n",
    "# Verificação dos parâmetros do modelo.\n",
    "modelo_dummies.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b51fa84",
   "metadata": {},
   "source": [
    "## CentralAir (Categórica)\n",
    "\n",
    "Existência de central de ar no imóvel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "055bc7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "Verficação da disposição da variável em agurpamento:\n",
      "\n",
      "CentralAir\n",
      "N      83\n",
      "Y    1085\n",
      "dtype: int64\n",
      "\n",
      "Essa variável já é uma variável dicotômica, mas não em valores numéricos, então será convertida para valores binários, 0 e 1.\n",
      "\n",
      "\n",
      "Primeiros valores do Data Frame criado.\n",
      "\n",
      "      Y  SalePrice\n",
      "254   1     145000\n",
      "1066  1     178000\n",
      "638   1      85000\n",
      "799   1     175000\n",
      "380   1     127000\n",
      "303   1     149900\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>SalePrice</td>    <th>  R-squared:         </th> <td>   0.072</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.071</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   89.83</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 05 Dec 2023</td> <th>  Prob (F-statistic):</th> <td>1.40e-20</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:02:04</td>     <th>  Log-Likelihood:    </th> <td> -14759.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.952e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1166</td>      <th>  BIC:               </th> <td>2.953e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td> 1.068e+05</td> <td> 8175.355</td> <td>   13.059</td> <td> 0.000</td> <td> 9.07e+04</td> <td> 1.23e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Y</th>         <td> 8.039e+04</td> <td> 8482.292</td> <td>    9.478</td> <td> 0.000</td> <td> 6.37e+04</td> <td>  9.7e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>477.592</td> <th>  Durbin-Watson:     </th> <td>   2.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2456.866</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.849</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 9.066</td>  <th>  Cond. No.          </th> <td>    7.37</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              SalePrice   R-squared:                       0.072\n",
       "Model:                            OLS   Adj. R-squared:                  0.071\n",
       "Method:                 Least Squares   F-statistic:                     89.83\n",
       "Date:                Tue, 05 Dec 2023   Prob (F-statistic):           1.40e-20\n",
       "Time:                        15:02:04   Log-Likelihood:                -14759.\n",
       "No. Observations:                1168   AIC:                         2.952e+04\n",
       "Df Residuals:                    1166   BIC:                         2.953e+04\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept   1.068e+05   8175.355     13.059      0.000    9.07e+04    1.23e+05\n",
       "Y           8.039e+04   8482.292      9.478      0.000    6.37e+04     9.7e+04\n",
       "==============================================================================\n",
       "Omnibus:                      477.592   Durbin-Watson:                   2.042\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2456.866\n",
       "Skew:                           1.849   Prob(JB):                         0.00\n",
       "Kurtosis:                       9.066   Cond. No.                         7.37\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nome_feature = 'CentralAir'\n",
    "\n",
    "# Verificação de valores nulos na variável\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Estatística univariádas pela variável\n",
    "print('Verficação da disposição da variável em agurpamento:\\n')\n",
    "agrupado = dados_treino.groupby([nome_feature]).size()\n",
    "print(agrupado)\n",
    "\n",
    "print(f'\\nEssa variável já é uma variável dicotômica, mas não em valores numéricos, então será convertida para valores binários, 0 e 1.\\n')\n",
    "\n",
    "# Cópia dos valores que serão manipulados para que os valores originais são sejam alterados.\n",
    "df_dummies_auxiliar_1 = dados_treino[nome_feature].copy()\n",
    "\n",
    "print(f'\\nPrimeiros valores do Data Frame criado.\\n')\n",
    "\n",
    "# Conversão da variável categórica em dicotômica com a exclusão da primeira variável dicotômica.\n",
    "df_dummies_auxiliar = pd.get_dummies(df_dummies_auxiliar_1, columns=[nome_feature], drop_first=True)\n",
    "\n",
    "# Inclusão da variável dependente ao data frame de variáveis dicotômicas.\n",
    "df_dummies_auxiliar[nome_target] = dados_treino[nome_target].copy()\n",
    "\n",
    "# Verificação do data frame.\n",
    "print(df_dummies_auxiliar.head(6))\n",
    "\n",
    "# Estimação do modelo de regressão linear múltipla com n-1 dummies\n",
    "modelo_dummies = sm.OLS.from_formula(\"SalePrice ~ Y\", df_dummies_auxiliar).fit()\n",
    "\n",
    "# Verificação dos parâmetros do modelo.\n",
    "modelo_dummies.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66777dc",
   "metadata": {},
   "source": [
    "## Electrical (Categórica)\n",
    "\n",
    "Sistema elétrico no imóvel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "f22e2289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 1\n",
      "\n",
      "Verficação da disposição da variável em agurpamento:\n",
      "\n",
      "Electrical\n",
      "FuseA      69\n",
      "FuseF      24\n",
      "FuseP       3\n",
      "SBrkr    1071\n",
      "dtype: int64\n",
      "\n",
      "Após o agrupamento é possivel afirmar que a moda dessa variável é \"SBrkr\".\n",
      "\n",
      "      FuseF  FuseP  SBrkr  SalePrice\n",
      "254       0      0      1     145000\n",
      "1066      0      0      1     178000\n",
      "638       0      0      0      85000\n",
      "799       0      0      1     175000\n",
      "380       0      0      1     127000\n",
      "303       0      0      1     149900\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>SalePrice</td>    <th>  R-squared:         </th> <td>   0.057</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.055</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   23.59</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 05 Dec 2023</td> <th>  Prob (F-statistic):</th> <td>8.01e-15</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:06:02</td>     <th>  Log-Likelihood:    </th> <td> -14768.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.954e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1164</td>      <th>  BIC:               </th> <td>2.956e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>  1.25e+05</td> <td> 9042.618</td> <td>   13.823</td> <td> 0.000</td> <td> 1.07e+05</td> <td> 1.43e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FuseF</th>     <td>-1.596e+04</td> <td> 1.78e+04</td> <td>   -0.897</td> <td> 0.370</td> <td>-5.09e+04</td> <td>  1.9e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FuseP</th>     <td>-2.766e+04</td> <td> 4.43e+04</td> <td>   -0.624</td> <td> 0.533</td> <td>-1.15e+05</td> <td> 5.93e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SBrkr</th>     <td> 6.194e+04</td> <td> 9329.098</td> <td>    6.639</td> <td> 0.000</td> <td> 4.36e+04</td> <td> 8.02e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>459.044</td> <th>  Durbin-Watson:     </th> <td>   2.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2280.702</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.779</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.848</td>  <th>  Cond. No.          </th> <td>    27.7</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              SalePrice   R-squared:                       0.057\n",
       "Model:                            OLS   Adj. R-squared:                  0.055\n",
       "Method:                 Least Squares   F-statistic:                     23.59\n",
       "Date:                Tue, 05 Dec 2023   Prob (F-statistic):           8.01e-15\n",
       "Time:                        15:06:02   Log-Likelihood:                -14768.\n",
       "No. Observations:                1168   AIC:                         2.954e+04\n",
       "Df Residuals:                    1164   BIC:                         2.956e+04\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept    1.25e+05   9042.618     13.823      0.000    1.07e+05    1.43e+05\n",
       "FuseF      -1.596e+04   1.78e+04     -0.897      0.370   -5.09e+04     1.9e+04\n",
       "FuseP      -2.766e+04   4.43e+04     -0.624      0.533   -1.15e+05    5.93e+04\n",
       "SBrkr       6.194e+04   9329.098      6.639      0.000    4.36e+04    8.02e+04\n",
       "==============================================================================\n",
       "Omnibus:                      459.044   Durbin-Watson:                   2.047\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2280.702\n",
       "Skew:                           1.779   Prob(JB):                         0.00\n",
       "Kurtosis:                       8.848   Cond. No.                         27.7\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nome_feature = 'Electrical'\n",
    "\n",
    "# Verificação de valores nulos na variável\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Estatística univariádas pela variável\n",
    "print('Verficação da disposição da variável em agurpamento:\\n')\n",
    "agrupado = dados_treino.groupby([nome_feature]).size()\n",
    "print(agrupado)\n",
    "\n",
    "print(f'\\nApós o agrupamento é possivel afirmar que a moda dessa variável é \"SBrkr\".\\n')\n",
    "\n",
    "# Cópia dos valores que serão manipulados para que os valores originais são sejam alterados.\n",
    "df_dummies_auxiliar_1 = dados_treino[nome_feature].copy()\n",
    "\n",
    "# Eliminação dos valores não válidas pelo valor da moda.\n",
    "df_dummies_auxiliar_1.fillna('SBrkr', inplace = True)\n",
    "\n",
    "# Conversão da variável categórica em dicotômica com a exclusão da primeira variável dicotômica.\n",
    "df_dummies_auxiliar = pd.get_dummies(df_dummies_auxiliar_1, columns=[nome_feature], drop_first=True)\n",
    "\n",
    "# Inclusão da variável dependente ao data frame de variáveis dicotômicas.\n",
    "df_dummies_auxiliar[nome_target] = dados_treino[nome_target].copy()\n",
    "\n",
    "# Verificação do data frame.\n",
    "print(df_dummies_auxiliar.head(6))\n",
    "\n",
    "# Estimação do modelo de regressão linear múltipla com n-1 dummies\n",
    "modelo_dummies = sm.OLS.from_formula(\"SalePrice ~ FuseF + FuseP + SBrkr\", df_dummies_auxiliar).fit()\n",
    "\n",
    "# Verificação dos parâmetros do modelo.\n",
    "modelo_dummies.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6489b582",
   "metadata": {},
   "source": [
    "## 1stFlrSF (Numérica)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d28c3c2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "\n",
      "Correlação entre 1stFlrSF e SalePrice\n",
      "\n",
      "           1stFlrSF  SalePrice\n",
      "1stFlrSF   1.000000   0.587883\n",
      "SalePrice  0.587883   1.000000\n",
      "\n",
      "Correlação entre ln<1stFlrSF> e ln<SalePrice>\n",
      "\n",
      "           1stFlrSF  SalePrice\n",
      "1stFlrSF     1.0000     0.5952\n",
      "SalePrice    0.5952     1.0000\n",
      "\n",
      "Correlação entre 1stFlrSF e SalePrice SEM OUTLIER\n",
      "\n",
      "           1stFlrSF  SalePrice\n",
      "1stFlrSF   1.000000   0.565735\n",
      "SalePrice  0.565735   1.000000\n",
      "\n",
      "Correlação entre ln<1stFlrSF> e ln<SalePrice> SEM OUTLIER\n",
      "\n",
      "           1stFlrSF  SalePrice\n",
      "1stFlrSF   1.000000   0.578566\n",
      "SalePrice  0.578566   1.000000\n",
      "\n",
      "Quantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "\n",
      "Quantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nome_feature = '1stFlrSF'\n",
    "\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# # Substituição de valores não válidos pela mediana da variável em ambos os data frames.\n",
    "# dados_treino[nome_feature].fillna(dados_treino[nome_feature].median(), inplace = True)\n",
    "# df_sem_outlier[nome_feature].fillna(df_sem_outlier[nome_feature].median(), inplace = True)\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target}\\n\")\n",
    "print(dados_treino[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}>\\n\")\n",
    "\n",
    "df_ln[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores maiores que mediana + 3 vezes o desvio padrão.\n",
    "med = df_sem_outlier[nome_feature].median()\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] >= (df_sem_outlier[nome_feature].median() + 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores MENOR que mediana - 3 vezes o desvio padrão.\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] <= (df_sem_outlier[nome_feature].median() - 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target} SEM OUTLIER\\n\")\n",
    "print(df_sem_outlier[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}> SEM OUTLIER\\n\")\n",
    "\n",
    "df_ln_sem_outlier[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln_sem_outlier[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln_sem_outlier[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# ARMAZENAMENTO DAS FEATURES CASO SEJAM UTILIZADAS NO MODELO DE REGRESSÃO LINEAR.\n",
    "\n",
    "# Armazenamento da feature não transformada.\n",
    "features_numericas[nome_feature] = dados_treino[nome_feature]\n",
    "\n",
    "# Armezenamento da feature transformada com ln.\n",
    "features_ln_numericas[nome_feature] = df_ln[nome_feature]\n",
    "\n",
    "# Armazenamento da feature não transformada.\n",
    "features_numericas_sem_outlier[nome_feature] = df_sem_outlier[nome_feature]\n",
    "\n",
    "# Armezenamento da feature transformada com ln.\n",
    "features_ln_numericas_sem_outlier[nome_feature] = df_ln_sem_outlier[nome_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cb7e54",
   "metadata": {},
   "source": [
    "## 2ndFlrSF (Numérica)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f4e2d4b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "\n",
      "Correlação entre 2ndFlrSF e SalePrice\n",
      "\n",
      "           2ndFlrSF  SalePrice\n",
      "2ndFlrSF    1.00000    0.31403\n",
      "SalePrice   0.31403    1.00000\n",
      "\n",
      "Correlação entre ln<2ndFlrSF> e ln<SalePrice>\n",
      "\n",
      "           2ndFlrSF  SalePrice\n",
      "2ndFlrSF   1.000000   0.176861\n",
      "SalePrice  0.176861   1.000000\n",
      "\n",
      "Correlação entre 2ndFlrSF e SalePrice SEM OUTLIER\n",
      "\n",
      "           2ndFlrSF  SalePrice\n",
      "2ndFlrSF   1.000000   0.159783\n",
      "SalePrice  0.159783   1.000000\n",
      "\n",
      "Correlação entre ln<2ndFlrSF> e ln<SalePrice> SEM OUTLIER\n",
      "\n",
      "           2ndFlrSF  SalePrice\n",
      "2ndFlrSF   1.000000   0.092806\n",
      "SalePrice  0.092806   1.000000\n",
      "\n",
      "Quantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "\n",
      "Quantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\John\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "nome_feature = '2ndFlrSF'\n",
    "\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# # Substituição de valores não válidos pela mediana da variável em ambos os data frames.\n",
    "# dados_treino[nome_feature].fillna(dados_treino[nome_feature].median(), inplace = True)\n",
    "# df_sem_outlier[nome_feature].fillna(df_sem_outlier[nome_feature].median(), inplace = True)\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target}\\n\")\n",
    "print(dados_treino[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}>\\n\")\n",
    "\n",
    "# df_ln[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln[nome_feature] = np.where(dados_treino[nome_feature] == 0, 1, np.log(dados_treino[nome_feature]))\n",
    "df_ln[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores maiores que mediana + 3 vezes o desvio padrão.\n",
    "med = df_sem_outlier[nome_feature].median()\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] >= (df_sem_outlier[nome_feature].median() + 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores MENOR que mediana - 3 vezes o desvio padrão.\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] <= (df_sem_outlier[nome_feature].median() - 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target} SEM OUTLIER\\n\")\n",
    "print(df_sem_outlier[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}> SEM OUTLIER\\n\")\n",
    "\n",
    "# df_ln_sem_outlier[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln_sem_outlier[nome_feature] = np.where(dados_treino[nome_feature] == 0, 1, np.log(dados_treino[nome_feature]))\n",
    "df_ln_sem_outlier[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln_sem_outlier[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# ARMAZENAMENTO DAS FEATURES CASO SEJAM UTILIZADAS NO MODELO DE REGRESSÃO LINEAR.\n",
    "\n",
    "# Armazenamento da feature não transformada.\n",
    "features_numericas[nome_feature] = dados_treino[nome_feature]\n",
    "\n",
    "# Armezenamento da feature transformada com ln.\n",
    "features_ln_numericas[nome_feature] = df_ln[nome_feature]\n",
    "\n",
    "# Armazenamento da feature não transformada.\n",
    "features_numericas_sem_outlier[nome_feature] = df_sem_outlier[nome_feature]\n",
    "\n",
    "# Armezenamento da feature transformada com ln.\n",
    "features_ln_numericas_sem_outlier[nome_feature] = df_ln_sem_outlier[nome_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb4a500",
   "metadata": {},
   "source": [
    "## LowQualFinSF (Numérica)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1069bf9b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "\n",
      "Correlação entre LowQualFinSF e SalePrice\n",
      "\n",
      "              LowQualFinSF  SalePrice\n",
      "LowQualFinSF      1.000000  -0.011189\n",
      "SalePrice        -0.011189   1.000000\n",
      "\n",
      "Correlação entre ln<LowQualFinSF> e ln<SalePrice>\n",
      "\n",
      "              LowQualFinSF  SalePrice\n",
      "LowQualFinSF         1.000      0.139\n",
      "SalePrice            0.139      1.000\n",
      "\n",
      "Correlação entre LowQualFinSF e SalePrice SEM OUTLIER\n",
      "\n",
      "              LowQualFinSF  SalePrice\n",
      "LowQualFinSF       1.00000   -0.03101\n",
      "SalePrice         -0.03101    1.00000\n",
      "\n",
      "Correlação entre ln<LowQualFinSF> e ln<SalePrice> SEM OUTLIER\n",
      "\n",
      "              LowQualFinSF  SalePrice\n",
      "LowQualFinSF      1.000000  -0.985088\n",
      "SalePrice        -0.985088   1.000000\n",
      "\n",
      "Quantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: 1147\n",
      "\n",
      "Quantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "\n",
      "Quantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nome_feature = 'LowQualFinSF'\n",
    "\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# # Substituição de valores não válidos pela mediana da variável em ambos os data frames.\n",
    "# dados_treino[nome_feature].fillna(dados_treino[nome_feature].median(), inplace = True)\n",
    "# df_sem_outlier[nome_feature].fillna(df_sem_outlier[nome_feature].median(), inplace = True)\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target}\\n\")\n",
    "print(dados_treino[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}>\\n\")\n",
    "\n",
    "df_ln[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores maiores que mediana + 3 vezes o desvio padrão.\n",
    "med = df_sem_outlier[nome_feature].median()\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] >= (df_sem_outlier[nome_feature].median() + 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores MENOR que mediana - 3 vezes o desvio padrão.\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] <= (df_sem_outlier[nome_feature].median() - 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target} SEM OUTLIER\\n\")\n",
    "print(df_sem_outlier[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}> SEM OUTLIER\\n\")\n",
    "\n",
    "df_ln_sem_outlier[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln_sem_outlier[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln_sem_outlier[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# # ARMAZENAMENTO DAS FEATURES CASO SEJAM UTILIZADAS NO MODELO DE REGRESSÃO LINEAR.\n",
    "\n",
    "# # Armazenamento da feature não transformada.\n",
    "# features_numericas[nome_feature] = dados_treino[nome_feature]\n",
    "\n",
    "# # Armezenamento da feature transformada com ln.\n",
    "# features_ln_numericas[nome_feature] = df_ln[nome_feature]\n",
    "\n",
    "# # Armazenamento da feature não transformada.\n",
    "# features_numericas_sem_outlier[nome_feature] = df_sem_outlier[nome_feature]\n",
    "\n",
    "# # Armezenamento da feature transformada com ln.\n",
    "# features_ln_numericas_sem_outlier[nome_feature] = df_ln_sem_outlier[nome_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15add04",
   "metadata": {},
   "source": [
    "## GrLivArea (Numérica)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8e433651",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "\n",
      "Correlação entre GrLivArea e SalePrice\n",
      "\n",
      "           GrLivArea  SalePrice\n",
      "GrLivArea   1.000000   0.695652\n",
      "SalePrice   0.695652   1.000000\n",
      "\n",
      "Correlação entre ln<GrLivArea> e ln<SalePrice>\n",
      "\n",
      "           GrLivArea  SalePrice\n",
      "GrLivArea   1.000000   0.723571\n",
      "SalePrice   0.723571   1.000000\n",
      "\n",
      "Correlação entre GrLivArea e SalePrice SEM OUTLIER\n",
      "\n",
      "           GrLivArea  SalePrice\n",
      "GrLivArea   1.000000   0.641881\n",
      "SalePrice   0.641881   1.000000\n",
      "\n",
      "Correlação entre ln<GrLivArea> e ln<SalePrice> SEM OUTLIER\n",
      "\n",
      "           GrLivArea  SalePrice\n",
      "GrLivArea   1.000000   0.696854\n",
      "SalePrice   0.696854   1.000000\n",
      "\n",
      "Quantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "\n",
      "Quantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nome_feature = 'GrLivArea'\n",
    "\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# # Substituição de valores não válidos pela mediana da variável em ambos os data frames.\n",
    "# dados_treino[nome_feature].fillna(dados_treino[nome_feature].median(), inplace = True)\n",
    "# df_sem_outlier[nome_feature].fillna(df_sem_outlier[nome_feature].median(), inplace = True)\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target}\\n\")\n",
    "print(dados_treino[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}>\\n\")\n",
    "\n",
    "df_ln[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores maiores que mediana + 3 vezes o desvio padrão.\n",
    "med = df_sem_outlier[nome_feature].median()\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] >= (df_sem_outlier[nome_feature].median() + 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores MENOR que mediana - 3 vezes o desvio padrão.\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] <= (df_sem_outlier[nome_feature].median() - 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target} SEM OUTLIER\\n\")\n",
    "print(df_sem_outlier[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}> SEM OUTLIER\\n\")\n",
    "\n",
    "df_ln_sem_outlier[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln_sem_outlier[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln_sem_outlier[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# ARMAZENAMENTO DAS FEATURES CASO SEJAM UTILIZADAS NO MODELO DE REGRESSÃO LINEAR.\n",
    "\n",
    "# Armazenamento da feature não transformada.\n",
    "features_numericas[nome_feature] = dados_treino[nome_feature]\n",
    "\n",
    "# Armezenamento da feature transformada com ln.\n",
    "features_ln_numericas[nome_feature] = df_ln[nome_feature]\n",
    "\n",
    "# Armazenamento da feature não transformada.\n",
    "features_numericas_sem_outlier[nome_feature] = df_sem_outlier[nome_feature]\n",
    "\n",
    "# Armezenamento da feature transformada com ln.\n",
    "features_ln_numericas_sem_outlier[nome_feature] = df_ln_sem_outlier[nome_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c610b830",
   "metadata": {},
   "source": [
    "## BsmtFullBath (Numérica)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "33450213",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "\n",
      "Correlação entre BsmtFullBath e SalePrice\n",
      "\n",
      "              BsmtFullBath  SalePrice\n",
      "BsmtFullBath      1.000000   0.226346\n",
      "SalePrice         0.226346   1.000000\n",
      "\n",
      "Correlação entre ln<BsmtFullBath> e ln<SalePrice>\n",
      "\n",
      "              BsmtFullBath  SalePrice\n",
      "BsmtFullBath      1.000000  -0.220187\n",
      "SalePrice        -0.220187   1.000000\n",
      "\n",
      "Correlação entre BsmtFullBath e SalePrice SEM OUTLIER\n",
      "\n",
      "              BsmtFullBath  SalePrice\n",
      "BsmtFullBath      1.000000   0.211912\n",
      "SalePrice         0.211912   1.000000\n",
      "\n",
      "Correlação entre ln<BsmtFullBath> e ln<SalePrice> SEM OUTLIER\n",
      "\n",
      "              BsmtFullBath  SalePrice\n",
      "BsmtFullBath      1.000000  -0.215058\n",
      "SalePrice        -0.215058   1.000000\n",
      "\n",
      "Quantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "\n",
      "Quantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\John\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "nome_feature = 'BsmtFullBath'\n",
    "\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# # Substituição de valores não válidos pela mediana da variável em ambos os data frames.\n",
    "# dados_treino[nome_feature].fillna(dados_treino[nome_feature].median(), inplace = True)\n",
    "# df_sem_outlier[nome_feature].fillna(df_sem_outlier[nome_feature].median(), inplace = True)\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target}\\n\")\n",
    "print(dados_treino[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}>\\n\")\n",
    "\n",
    "# df_ln[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln[nome_feature] = np.where(dados_treino[nome_feature] == 0, 1, np.log(dados_treino[nome_feature]))\n",
    "df_ln[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores maiores que mediana + 3 vezes o desvio padrão.\n",
    "med = df_sem_outlier[nome_feature].median()\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] >= (df_sem_outlier[nome_feature].median() + 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores MENOR que mediana - 3 vezes o desvio padrão.\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] <= (df_sem_outlier[nome_feature].median() - 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target} SEM OUTLIER\\n\")\n",
    "print(df_sem_outlier[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}> SEM OUTLIER\\n\")\n",
    "\n",
    "# df_ln_sem_outlier[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln_sem_outlier[nome_feature] = np.where(dados_treino[nome_feature] == 0, 1, np.log(dados_treino[nome_feature]))\n",
    "df_ln_sem_outlier[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln_sem_outlier[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# ARMAZENAMENTO DAS FEATURES CASO SEJAM UTILIZADAS NO MODELO DE REGRESSÃO LINEAR.\n",
    "\n",
    "# Armazenamento da feature não transformada.\n",
    "features_numericas[nome_feature] = dados_treino[nome_feature]\n",
    "\n",
    "# Armezenamento da feature transformada com ln.\n",
    "features_ln_numericas[nome_feature] = df_ln[nome_feature]\n",
    "\n",
    "# Armazenamento da feature não transformada.\n",
    "features_numericas_sem_outlier[nome_feature] = df_sem_outlier[nome_feature]\n",
    "\n",
    "# Armezenamento da feature transformada com ln.\n",
    "features_ln_numericas_sem_outlier[nome_feature] = df_ln_sem_outlier[nome_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767585d1",
   "metadata": {},
   "source": [
    "## BsmtHalfBath (Numérica)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d669fc9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "\n",
      "Correlação entre BsmtHalfBath e SalePrice\n",
      "\n",
      "              BsmtHalfBath  SalePrice\n",
      "BsmtHalfBath      1.000000  -0.048346\n",
      "SalePrice        -0.048346   1.000000\n",
      "\n",
      "Correlação entre ln<BsmtHalfBath> e ln<SalePrice>\n",
      "\n",
      "              BsmtHalfBath  SalePrice\n",
      "BsmtHalfBath      1.000000  -0.106844\n",
      "SalePrice        -0.106844   1.000000\n",
      "\n",
      "Correlação entre BsmtHalfBath e SalePrice SEM OUTLIER\n",
      "\n",
      "              BsmtHalfBath  SalePrice\n",
      "BsmtHalfBath           NaN        NaN\n",
      "SalePrice              NaN        1.0\n",
      "\n",
      "Correlação entre ln<BsmtHalfBath> e ln<SalePrice> SEM OUTLIER\n",
      "\n",
      "              BsmtHalfBath  SalePrice\n",
      "BsmtHalfBath           NaN        NaN\n",
      "SalePrice              NaN        1.0\n",
      "\n",
      "Quantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: 1102\n",
      "\n",
      "Quantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "\n",
      "Quantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nome_feature = 'BsmtHalfBath'\n",
    "\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Substituição de valores não válidos pela mediana da variável em ambos os data frames.\n",
    "dados_treino[nome_feature].fillna(dados_treino[nome_feature].median(), inplace = True)\n",
    "df_sem_outlier[nome_feature].fillna(df_sem_outlier[nome_feature].median(), inplace = True)\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target}\\n\")\n",
    "print(dados_treino[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}>\\n\")\n",
    "\n",
    "df_ln[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores maiores que mediana + 3 vezes o desvio padrão.\n",
    "med = df_sem_outlier[nome_feature].median()\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] >= (df_sem_outlier[nome_feature].median() + 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores MENOR que mediana - 3 vezes o desvio padrão.\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] <= (df_sem_outlier[nome_feature].median() - 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target} SEM OUTLIER\\n\")\n",
    "print(df_sem_outlier[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}> SEM OUTLIER\\n\")\n",
    "\n",
    "df_ln_sem_outlier[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln_sem_outlier[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln_sem_outlier[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# # ARMAZENAMENTO DAS FEATURES CASO SEJAM UTILIZADAS NO MODELO DE REGRESSÃO LINEAR.\n",
    "\n",
    "# # Armazenamento da feature não transformada.\n",
    "# features_numericas[nome_feature] = dados_treino[nome_feature]\n",
    "\n",
    "# # Armezenamento da feature transformada com ln.\n",
    "# features_ln_numericas[nome_feature] = df_ln[nome_feature]\n",
    "\n",
    "# # Armazenamento da feature não transformada.\n",
    "# features_numericas_sem_outlier[nome_feature] = df_sem_outlier[nome_feature]\n",
    "\n",
    "# # Armezenamento da feature transformada com ln.\n",
    "# features_ln_numericas_sem_outlier[nome_feature] = df_ln_sem_outlier[nome_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c8a903",
   "metadata": {},
   "source": [
    "## FullBath (Numérica)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "58a5beba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "\n",
      "Correlação entre FullBath e SalePrice\n",
      "\n",
      "           FullBath  SalePrice\n",
      "FullBath   1.000000   0.552546\n",
      "SalePrice  0.552546   1.000000\n",
      "\n",
      "Correlação entre ln<FullBath> e ln<SalePrice>\n",
      "\n",
      "           FullBath  SalePrice\n",
      "FullBath   1.000000   0.587653\n",
      "SalePrice  0.587653   1.000000\n",
      "\n",
      "Correlação entre FullBath e SalePrice SEM OUTLIER\n",
      "\n",
      "           FullBath  SalePrice\n",
      "FullBath   1.000000   0.565991\n",
      "SalePrice  0.565991   1.000000\n",
      "\n",
      "Correlação entre ln<FullBath> e ln<SalePrice> SEM OUTLIER\n",
      "\n",
      "           FullBath  SalePrice\n",
      "FullBath   1.000000   0.590311\n",
      "SalePrice  0.590311   1.000000\n",
      "\n",
      "Quantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "\n",
      "Quantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "nome_feature = 'FullBath'\n",
    "\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# # Substituição de valores não válidos pela mediana da variável em ambos os data frames.\n",
    "# dados_treino[nome_feature].fillna(dados_treino[nome_feature].median(), inplace = True)\n",
    "# df_sem_outlier[nome_feature].fillna(df_sem_outlier[nome_feature].median(), inplace = True)\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target}\\n\")\n",
    "print(dados_treino[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}>\\n\")\n",
    "\n",
    "# df_ln[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln[nome_feature] = np.where(dados_treino[nome_feature] == 0, 1, np.log(dados_treino[nome_feature]))\n",
    "df_ln[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores maiores que mediana + 3 vezes o desvio padrão.\n",
    "med = df_sem_outlier[nome_feature].median()\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] >= (df_sem_outlier[nome_feature].median() + 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores MENOR que mediana - 3 vezes o desvio padrão.\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] <= (df_sem_outlier[nome_feature].median() - 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target} SEM OUTLIER\\n\")\n",
    "print(df_sem_outlier[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}> SEM OUTLIER\\n\")\n",
    "\n",
    "# df_ln_sem_outlier[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln_sem_outlier[nome_feature] = np.where(dados_treino[nome_feature] == 0, 1, np.log(dados_treino[nome_feature]))\n",
    "df_ln_sem_outlier[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln_sem_outlier[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# ARMAZENAMENTO DAS FEATURES CASO SEJAM UTILIZADAS NO MODELO DE REGRESSÃO LINEAR.\n",
    "\n",
    "# Armazenamento da feature não transformada.\n",
    "features_numericas[nome_feature] = dados_treino[nome_feature]\n",
    "\n",
    "# Armezenamento da feature transformada com ln.\n",
    "features_ln_numericas[nome_feature] = df_ln[nome_feature]\n",
    "\n",
    "# Armazenamento da feature não transformada.\n",
    "features_numericas_sem_outlier[nome_feature] = df_sem_outlier[nome_feature]\n",
    "\n",
    "# Armezenamento da feature transformada com ln.\n",
    "features_ln_numericas_sem_outlier[nome_feature] = df_ln_sem_outlier[nome_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafa3fb2",
   "metadata": {},
   "source": [
    "## HalfBath (Numérica)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "45e86a13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "\n",
      "Correlação entre HalfBath e SalePrice\n",
      "\n",
      "           HalfBath  SalePrice\n",
      "HalfBath   1.000000   0.280481\n",
      "SalePrice  0.280481   1.000000\n",
      "\n",
      "Correlação entre ln<HalfBath> e ln<SalePrice>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           HalfBath  SalePrice\n",
      "HalfBath   1.000000  -0.323502\n",
      "SalePrice -0.323502   1.000000\n",
      "\n",
      "Correlação entre HalfBath e SalePrice SEM OUTLIER\n",
      "\n",
      "           HalfBath  SalePrice\n",
      "HalfBath    1.00000    0.29436\n",
      "SalePrice   0.29436    1.00000\n",
      "\n",
      "Correlação entre ln<HalfBath> e ln<SalePrice> SEM OUTLIER\n",
      "\n",
      "           HalfBath  SalePrice\n",
      "HalfBath   1.000000  -0.322743\n",
      "SalePrice -0.322743   1.000000\n",
      "\n",
      "Quantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "\n",
      "Quantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "nome_feature = 'HalfBath'\n",
    "\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# # Substituição de valores não válidos pela mediana da variável em ambos os data frames.\n",
    "# dados_treino[nome_feature].fillna(dados_treino[nome_feature].median(), inplace = True)\n",
    "# df_sem_outlier[nome_feature].fillna(df_sem_outlier[nome_feature].median(), inplace = True)\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target}\\n\")\n",
    "print(dados_treino[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}>\\n\")\n",
    "\n",
    "# df_ln[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln[nome_feature] = np.where(dados_treino[nome_feature] == 0, 1, np.log(dados_treino[nome_feature]))\n",
    "df_ln[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores maiores que mediana + 3 vezes o desvio padrão.\n",
    "med = df_sem_outlier[nome_feature].median()\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] >= (df_sem_outlier[nome_feature].median() + 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores MENOR que mediana - 3 vezes o desvio padrão.\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] <= (df_sem_outlier[nome_feature].median() - 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target} SEM OUTLIER\\n\")\n",
    "print(df_sem_outlier[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}> SEM OUTLIER\\n\")\n",
    "\n",
    "# df_ln_sem_outlier[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln_sem_outlier[nome_feature] = np.where(dados_treino[nome_feature] == 0, 1, np.log(dados_treino[nome_feature]))\n",
    "df_ln_sem_outlier[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln_sem_outlier[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# ARMAZENAMENTO DAS FEATURES CASO SEJAM UTILIZADAS NO MODELO DE REGRESSÃO LINEAR.\n",
    "\n",
    "# Armazenamento da feature não transformada.\n",
    "features_numericas[nome_feature] = dados_treino[nome_feature]\n",
    "\n",
    "# Armezenamento da feature transformada com ln.\n",
    "features_ln_numericas[nome_feature] = df_ln[nome_feature]\n",
    "\n",
    "# Armazenamento da feature não transformada.\n",
    "features_numericas_sem_outlier[nome_feature] = df_sem_outlier[nome_feature]\n",
    "\n",
    "# Armezenamento da feature transformada com ln.\n",
    "features_ln_numericas_sem_outlier[nome_feature] = df_ln_sem_outlier[nome_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4824adcb",
   "metadata": {},
   "source": [
    "## BedroomAbvGr (Numérica)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8b3c2f3c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "\n",
      "Correlação entre BedroomAbvGr e SalePrice\n",
      "\n",
      "              BedroomAbvGr  SalePrice\n",
      "BedroomAbvGr      1.000000   0.156211\n",
      "SalePrice         0.156211   1.000000\n",
      "\n",
      "Correlação entre ln<BedroomAbvGr> e ln<SalePrice>\n",
      "\n",
      "              BedroomAbvGr  SalePrice\n",
      "BedroomAbvGr      1.000000   0.202308\n",
      "SalePrice         0.202308   1.000000\n",
      "\n",
      "Correlação entre BedroomAbvGr e SalePrice SEM OUTLIER\n",
      "\n",
      "              BedroomAbvGr  SalePrice\n",
      "BedroomAbvGr      1.000000   0.194383\n",
      "SalePrice         0.194383   1.000000\n",
      "\n",
      "Correlação entre ln<BedroomAbvGr> e ln<SalePrice> SEM OUTLIER\n",
      "\n",
      "              BedroomAbvGr  SalePrice\n",
      "BedroomAbvGr      1.000000   0.212133\n",
      "SalePrice         0.212133   1.000000\n",
      "\n",
      "Quantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "\n",
      "Quantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "nome_feature = 'BedroomAbvGr'\n",
    "\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# # Substituição de valores não válidos pela mediana da variável em ambos os data frames.\n",
    "# dados_treino[nome_feature].fillna(dados_treino[nome_feature].median(), inplace = True)\n",
    "# df_sem_outlier[nome_feature].fillna(df_sem_outlier[nome_feature].median(), inplace = True)\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target}\\n\")\n",
    "print(dados_treino[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}>\\n\")\n",
    "\n",
    "# df_ln[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln[nome_feature] = np.where(dados_treino[nome_feature] == 0, 1, np.log(dados_treino[nome_feature]))\n",
    "df_ln[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores maiores que mediana + 3 vezes o desvio padrão.\n",
    "med = df_sem_outlier[nome_feature].median()\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] >= (df_sem_outlier[nome_feature].median() + 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores MENOR que mediana - 3 vezes o desvio padrão.\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] <= (df_sem_outlier[nome_feature].median() - 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target} SEM OUTLIER\\n\")\n",
    "print(df_sem_outlier[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}> SEM OUTLIER\\n\")\n",
    "\n",
    "# df_ln_sem_outlier[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln_sem_outlier[nome_feature] = np.where(dados_treino[nome_feature] == 0, 1, np.log(dados_treino[nome_feature]))\n",
    "df_ln_sem_outlier[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln_sem_outlier[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# ARMAZENAMENTO DAS FEATURES CASO SEJAM UTILIZADAS NO MODELO DE REGRESSÃO LINEAR.\n",
    "\n",
    "# Armazenamento da feature não transformada.\n",
    "features_numericas[nome_feature] = dados_treino[nome_feature]\n",
    "\n",
    "# Armezenamento da feature transformada com ln.\n",
    "features_ln_numericas[nome_feature] = df_ln[nome_feature]\n",
    "\n",
    "# Armazenamento da feature não transformada.\n",
    "features_numericas_sem_outlier[nome_feature] = df_sem_outlier[nome_feature]\n",
    "\n",
    "# Armezenamento da feature transformada com ln.\n",
    "features_ln_numericas_sem_outlier[nome_feature] = df_ln_sem_outlier[nome_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6e8773",
   "metadata": {},
   "source": [
    "## KitchenAbvGr (Numérica)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "59bef320",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "\n",
      "Correlação entre KitchenAbvGr e SalePrice\n",
      "\n",
      "              KitchenAbvGr  SalePrice\n",
      "KitchenAbvGr      1.000000  -0.142785\n",
      "SalePrice        -0.142785   1.000000\n",
      "\n",
      "Correlação entre ln<KitchenAbvGr> e ln<SalePrice>\n",
      "\n",
      "              KitchenAbvGr  SalePrice\n",
      "KitchenAbvGr      1.000000  -0.163506\n",
      "SalePrice        -0.163506   1.000000\n",
      "\n",
      "Correlação entre KitchenAbvGr e SalePrice SEM OUTLIER\n",
      "\n",
      "              KitchenAbvGr  SalePrice\n",
      "KitchenAbvGr           NaN        NaN\n",
      "SalePrice              NaN        1.0\n",
      "\n",
      "Correlação entre ln<KitchenAbvGr> e ln<SalePrice> SEM OUTLIER\n",
      "\n",
      "              KitchenAbvGr  SalePrice\n",
      "KitchenAbvGr           NaN        NaN\n",
      "SalePrice              NaN        1.0\n",
      "\n",
      "Quantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "\n",
      "Quantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "nome_feature = 'KitchenAbvGr'\n",
    "\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# # Substituição de valores não válidos pela mediana da variável em ambos os data frames.\n",
    "# dados_treino[nome_feature].fillna(dados_treino[nome_feature].median(), inplace = True)\n",
    "# df_sem_outlier[nome_feature].fillna(df_sem_outlier[nome_feature].median(), inplace = True)\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target}\\n\")\n",
    "print(dados_treino[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}>\\n\")\n",
    "\n",
    "# df_ln[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln[nome_feature] = np.where(dados_treino[nome_feature] == 0, 1, np.log(dados_treino[nome_feature]))\n",
    "df_ln[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores maiores que mediana + 3 vezes o desvio padrão.\n",
    "med = df_sem_outlier[nome_feature].median()\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] >= (df_sem_outlier[nome_feature].median() + 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores MENOR que mediana - 3 vezes o desvio padrão.\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] <= (df_sem_outlier[nome_feature].median() - 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target} SEM OUTLIER\\n\")\n",
    "print(df_sem_outlier[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}> SEM OUTLIER\\n\")\n",
    "\n",
    "# df_ln_sem_outlier[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln_sem_outlier[nome_feature] = np.where(dados_treino[nome_feature] == 0, 1, np.log(dados_treino[nome_feature]))\n",
    "df_ln_sem_outlier[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln_sem_outlier[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# # ARMAZENAMENTO DAS FEATURES CASO SEJAM UTILIZADAS NO MODELO DE REGRESSÃO LINEAR.\n",
    "\n",
    "# # Armazenamento da feature não transformada.\n",
    "# features_numericas[nome_feature] = dados_treino[nome_feature]\n",
    "\n",
    "# # Armezenamento da feature transformada com ln.\n",
    "# features_ln_numericas[nome_feature] = df_ln[nome_feature]\n",
    "\n",
    "# # Armazenamento da feature não transformada.\n",
    "# features_numericas_sem_outlier[nome_feature] = df_sem_outlier[nome_feature]\n",
    "\n",
    "# # Armezenamento da feature transformada com ln.\n",
    "# features_ln_numericas_sem_outlier[nome_feature] = df_ln_sem_outlier[nome_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3ab65e",
   "metadata": {},
   "source": [
    "## KitchenQual (Categórica)\n",
    "\n",
    "Qualidade da cozinha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "30ed31d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "Verficação da disposição da variável em agurpamento:\n",
      "\n",
      "KitchenQual\n",
      "Ex     77\n",
      "Fa     32\n",
      "Gd    470\n",
      "TA    589\n",
      "dtype: int64\n",
      "\n",
      "Primeiros valores do Data Frame.\n",
      "\n",
      "      Fa  Gd  TA  SalePrice\n",
      "254    0   0   1     145000\n",
      "1066   0   0   1     178000\n",
      "638    0   0   1      85000\n",
      "799    0   1   0     175000\n",
      "380    0   1   0     127000\n",
      "303    0   0   1     149900\n",
      "\n",
      "Dados estatísticos da regressão linear criada.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>SalePrice</td>    <th>  R-squared:         </th> <td>   0.461</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.460</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   332.4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 05 Dec 2023</td> <th>  Prob (F-statistic):</th> <td>7.22e-156</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:16:06</td>     <th>  Log-Likelihood:    </th> <td> -14441.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.889e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1164</td>      <th>  BIC:               </th> <td>2.891e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td> 3.302e+05</td> <td> 6470.182</td> <td>   51.028</td> <td> 0.000</td> <td> 3.17e+05</td> <td> 3.43e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fa</th>        <td> -2.23e+05</td> <td> 1.19e+04</td> <td>  -18.678</td> <td> 0.000</td> <td>-2.46e+05</td> <td>   -2e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Gd</th>        <td>-1.187e+05</td> <td> 6980.093</td> <td>  -17.008</td> <td> 0.000</td> <td>-1.32e+05</td> <td>-1.05e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TA</th>        <td>-1.881e+05</td> <td> 6880.119</td> <td>  -27.334</td> <td> 0.000</td> <td>-2.02e+05</td> <td>-1.75e+05</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>372.707</td> <th>  Durbin-Watson:     </th> <td>   1.982</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2364.580</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.319</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 9.452</td>  <th>  Cond. No.          </th> <td>    10.4</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              SalePrice   R-squared:                       0.461\n",
       "Model:                            OLS   Adj. R-squared:                  0.460\n",
       "Method:                 Least Squares   F-statistic:                     332.4\n",
       "Date:                Tue, 05 Dec 2023   Prob (F-statistic):          7.22e-156\n",
       "Time:                        15:16:06   Log-Likelihood:                -14441.\n",
       "No. Observations:                1168   AIC:                         2.889e+04\n",
       "Df Residuals:                    1164   BIC:                         2.891e+04\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept   3.302e+05   6470.182     51.028      0.000    3.17e+05    3.43e+05\n",
       "Fa          -2.23e+05   1.19e+04    -18.678      0.000   -2.46e+05      -2e+05\n",
       "Gd         -1.187e+05   6980.093    -17.008      0.000   -1.32e+05   -1.05e+05\n",
       "TA         -1.881e+05   6880.119    -27.334      0.000   -2.02e+05   -1.75e+05\n",
       "==============================================================================\n",
       "Omnibus:                      372.707   Durbin-Watson:                   1.982\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2364.580\n",
       "Skew:                           1.319   Prob(JB):                         0.00\n",
       "Kurtosis:                       9.452   Cond. No.                         10.4\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nome_feature = 'KitchenQual'\n",
    "\n",
    "# Verificação de valores nulos na variável\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Estatística univariádas pela variável\n",
    "print('Verficação da disposição da variável em agurpamento:\\n')\n",
    "agrupado = dados_treino.groupby([nome_feature]).size()\n",
    "print(agrupado)\n",
    "\n",
    "# print(f'\\nApós o agrupamento é possivel afirmar que a moda dessa variável é \"SBrkr\".\\n')\n",
    "\n",
    "# Cópia dos valores que serão manipulados para que os valores originais são sejam alterados.\n",
    "df_dummies_auxiliar_1 = dados_treino[nome_feature].copy()\n",
    "\n",
    "# Conversão da variável categórica em dicotômica com a exclusão da primeira variável dicotômica.\n",
    "df_dummies_auxiliar = pd.get_dummies(df_dummies_auxiliar_1, columns=[nome_feature], drop_first=True)\n",
    "\n",
    "# Inclusão da variável dependente ao data frame de variáveis dicotômicas.\n",
    "df_dummies_auxiliar[nome_target] = dados_treino[nome_target].copy()\n",
    "\n",
    "print(f'\\nPrimeiros valores do Data Frame.\\n')\n",
    "\n",
    "# Verificação do data frame.\n",
    "print(df_dummies_auxiliar.head(6))\n",
    "\n",
    "# Estimação do modelo de regressão linear múltipla com n-1 dummies\n",
    "modelo_dummies = sm.OLS.from_formula(\"SalePrice ~ Fa + Gd + TA\", df_dummies_auxiliar).fit()\n",
    "\n",
    "print(f'\\nDados estatísticos da regressão linear criada.\\n')\n",
    "\n",
    "# Verificação dos parâmetros do modelo.\n",
    "modelo_dummies.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c0f82b",
   "metadata": {},
   "source": [
    "## TotRmsAbvGrd (Numérica)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "13b46b33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "\n",
      "Correlação entre TotRmsAbvGrd e SalePrice\n",
      "\n",
      "              TotRmsAbvGrd  SalePrice\n",
      "TotRmsAbvGrd      1.000000   0.520388\n",
      "SalePrice         0.520388   1.000000\n",
      "\n",
      "Correlação entre ln<TotRmsAbvGrd> e ln<SalePrice>\n",
      "\n",
      "              TotRmsAbvGrd  SalePrice\n",
      "TotRmsAbvGrd      1.000000   0.527035\n",
      "SalePrice         0.527035   1.000000\n",
      "\n",
      "Correlação entre TotRmsAbvGrd e SalePrice SEM OUTLIER\n",
      "\n",
      "              TotRmsAbvGrd  SalePrice\n",
      "TotRmsAbvGrd      1.000000   0.470294\n",
      "SalePrice         0.470294   1.000000\n",
      "\n",
      "Correlação entre ln<TotRmsAbvGrd> e ln<SalePrice> SEM OUTLIER\n",
      "\n",
      "              TotRmsAbvGrd  SalePrice\n",
      "TotRmsAbvGrd      1.000000   0.497573\n",
      "SalePrice         0.497573   1.000000\n",
      "\n",
      "Quantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "\n",
      "Quantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nome_feature = 'TotRmsAbvGrd'\n",
    "\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# # Substituição de valores não válidos pela mediana da variável em ambos os data frames.\n",
    "# dados_treino[nome_feature].fillna(dados_treino[nome_feature].median(), inplace = True)\n",
    "# df_sem_outlier[nome_feature].fillna(df_sem_outlier[nome_feature].median(), inplace = True)\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target}\\n\")\n",
    "print(dados_treino[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}>\\n\")\n",
    "\n",
    "df_ln[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores maiores que mediana + 3 vezes o desvio padrão.\n",
    "med = df_sem_outlier[nome_feature].median()\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] >= (df_sem_outlier[nome_feature].median() + 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores MENOR que mediana - 3 vezes o desvio padrão.\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] <= (df_sem_outlier[nome_feature].median() - 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target} SEM OUTLIER\\n\")\n",
    "print(df_sem_outlier[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}> SEM OUTLIER\\n\")\n",
    "\n",
    "df_ln_sem_outlier[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln_sem_outlier[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln_sem_outlier[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# ARMAZENAMENTO DAS FEATURES CASO SEJAM UTILIZADAS NO MODELO DE REGRESSÃO LINEAR.\n",
    "\n",
    "# Armazenamento da feature não transformada.\n",
    "features_numericas[nome_feature] = dados_treino[nome_feature]\n",
    "\n",
    "# Armezenamento da feature transformada com ln.\n",
    "features_ln_numericas[nome_feature] = df_ln[nome_feature]\n",
    "\n",
    "# Armazenamento da feature não transformada.\n",
    "features_numericas_sem_outlier[nome_feature] = df_sem_outlier[nome_feature]\n",
    "\n",
    "# Armezenamento da feature transformada com ln.\n",
    "features_ln_numericas_sem_outlier[nome_feature] = df_ln_sem_outlier[nome_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6d88ab",
   "metadata": {},
   "source": [
    "## Functional (Categórica)\n",
    "\n",
    "Funcionalidade do imóvel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "9b429c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "Verficação da disposição da variável em agurpamento:\n",
      "\n",
      "Functional\n",
      "Maj1       9\n",
      "Maj2       4\n",
      "Min1      28\n",
      "Min2      29\n",
      "Mod       13\n",
      "Sev        1\n",
      "Typ     1084\n",
      "dtype: int64\n",
      "\n",
      "Primeiros valores do Data Frame.\n",
      "\n",
      "      Maj2  Min1  Min2  Mod  Sev  Typ  SalePrice\n",
      "254      0     0     0    0    0    1     145000\n",
      "1066     0     0     0    0    0    1     178000\n",
      "638      0     0     0    0    0    1      85000\n",
      "799      0     0     0    0    0    1     175000\n",
      "380      0     0     0    0    0    1     127000\n",
      "303      0     0     0    0    0    1     149900\n",
      "\n",
      "Dados estatísticos da regressão linear criada.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>SalePrice</td>    <th>  R-squared:         </th> <td>   0.018</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.013</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   3.526</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 05 Dec 2023</td> <th>  Prob (F-statistic):</th>  <td>0.00183</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:21:10</td>     <th>  Log-Likelihood:    </th> <td> -14792.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.960e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1161</td>      <th>  BIC:               </th> <td>2.963e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td> 1.557e+05</td> <td> 2.56e+04</td> <td>    6.086</td> <td> 0.000</td> <td> 1.06e+05</td> <td> 2.06e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Maj2</th>      <td>-6.524e+04</td> <td> 4.61e+04</td> <td>   -1.414</td> <td> 0.158</td> <td>-1.56e+05</td> <td> 2.53e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Min1</th>      <td>-8401.3889</td> <td> 2.94e+04</td> <td>   -0.286</td> <td> 0.775</td> <td>-6.61e+04</td> <td> 4.93e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Min2</th>      <td>-1.154e+04</td> <td> 2.93e+04</td> <td>   -0.394</td> <td> 0.694</td> <td> -6.9e+04</td> <td> 4.59e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Mod</th>       <td> 1.171e+04</td> <td> 3.33e+04</td> <td>    0.352</td> <td> 0.725</td> <td>-5.36e+04</td> <td>  7.7e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sev</th>       <td>-2.674e+04</td> <td> 8.09e+04</td> <td>   -0.330</td> <td> 0.741</td> <td>-1.86e+05</td> <td> 1.32e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Typ</th>       <td> 2.835e+04</td> <td> 2.57e+04</td> <td>    1.103</td> <td> 0.270</td> <td>-2.21e+04</td> <td> 7.88e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>446.641</td> <th>  Durbin-Watson:     </th> <td>   2.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2106.811</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.744</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.579</td>  <th>  Cond. No.          </th> <td>    52.7</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              SalePrice   R-squared:                       0.018\n",
       "Model:                            OLS   Adj. R-squared:                  0.013\n",
       "Method:                 Least Squares   F-statistic:                     3.526\n",
       "Date:                Tue, 05 Dec 2023   Prob (F-statistic):            0.00183\n",
       "Time:                        15:21:10   Log-Likelihood:                -14792.\n",
       "No. Observations:                1168   AIC:                         2.960e+04\n",
       "Df Residuals:                    1161   BIC:                         2.963e+04\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept   1.557e+05   2.56e+04      6.086      0.000    1.06e+05    2.06e+05\n",
       "Maj2       -6.524e+04   4.61e+04     -1.414      0.158   -1.56e+05    2.53e+04\n",
       "Min1       -8401.3889   2.94e+04     -0.286      0.775   -6.61e+04    4.93e+04\n",
       "Min2       -1.154e+04   2.93e+04     -0.394      0.694    -6.9e+04    4.59e+04\n",
       "Mod         1.171e+04   3.33e+04      0.352      0.725   -5.36e+04     7.7e+04\n",
       "Sev        -2.674e+04   8.09e+04     -0.330      0.741   -1.86e+05    1.32e+05\n",
       "Typ         2.835e+04   2.57e+04      1.103      0.270   -2.21e+04    7.88e+04\n",
       "==============================================================================\n",
       "Omnibus:                      446.641   Durbin-Watson:                   2.050\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2106.811\n",
       "Skew:                           1.744   Prob(JB):                         0.00\n",
       "Kurtosis:                       8.579   Cond. No.                         52.7\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nome_feature = 'Functional'\n",
    "\n",
    "# Verificação de valores nulos na variável\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Estatística univariádas pela variável\n",
    "print('Verficação da disposição da variável em agurpamento:\\n')\n",
    "agrupado = dados_treino.groupby([nome_feature]).size()\n",
    "print(agrupado)\n",
    "\n",
    "# Cópia dos valores que serão manipulados para que os valores originais são sejam alterados.\n",
    "df_dummies_auxiliar_1 = dados_treino[nome_feature].copy()\n",
    "\n",
    "# Conversão da variável categórica em dicotômica com a exclusão da primeira variável dicotômica.\n",
    "df_dummies_auxiliar = pd.get_dummies(df_dummies_auxiliar_1, columns=[nome_feature], drop_first=True)\n",
    "\n",
    "# Inclusão da variável dependente ao data frame de variáveis dicotômicas.\n",
    "df_dummies_auxiliar[nome_target] = dados_treino[nome_target].copy()\n",
    "\n",
    "print(f'\\nPrimeiros valores do Data Frame.\\n')\n",
    "\n",
    "# Verificação do data frame.\n",
    "print(df_dummies_auxiliar.head(6))\n",
    "\n",
    "# Estimação do modelo de regressão linear múltipla com n-1 dummies\n",
    "modelo_dummies = sm.OLS.from_formula(\"SalePrice ~ Maj2 + Min1 + Min2 + Mod + Sev + Typ\", df_dummies_auxiliar).fit()\n",
    "\n",
    "print(f'\\nDados estatísticos da regressão linear criada.\\n')\n",
    "\n",
    "# Verificação dos parâmetros do modelo.\n",
    "modelo_dummies.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbd3ea9",
   "metadata": {},
   "source": [
    "## Fireplaces (Numérica)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1a2d3017",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "\n",
      "Correlação entre Fireplaces e SalePrice\n",
      "\n",
      "            Fireplaces  SalePrice\n",
      "Fireplaces    1.000000   0.457549\n",
      "SalePrice     0.457549   1.000000\n",
      "\n",
      "Correlação entre ln<Fireplaces> e ln<SalePrice>\n",
      "\n",
      "            Fireplaces  SalePrice\n",
      "Fireplaces     1.00000   -0.44306\n",
      "SalePrice     -0.44306    1.00000\n",
      "\n",
      "Correlação entre Fireplaces e SalePrice SEM OUTLIER\n",
      "\n",
      "            Fireplaces  SalePrice\n",
      "Fireplaces    1.000000   0.462229\n",
      "SalePrice     0.462229   1.000000\n",
      "\n",
      "Correlação entre ln<Fireplaces> e ln<SalePrice> SEM OUTLIER\n",
      "\n",
      "            Fireplaces  SalePrice\n",
      "Fireplaces    1.000000  -0.448213\n",
      "SalePrice    -0.448213   1.000000\n",
      "\n",
      "Quantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "\n",
      "Quantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\John\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "nome_feature = 'Fireplaces'\n",
    "\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# # Substituição de valores não válidos pela mediana da variável em ambos os data frames.\n",
    "# dados_treino[nome_feature].fillna(dados_treino[nome_feature].median(), inplace = True)\n",
    "# df_sem_outlier[nome_feature].fillna(df_sem_outlier[nome_feature].median(), inplace = True)\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target}\\n\")\n",
    "print(dados_treino[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}>\\n\")\n",
    "\n",
    "# df_ln[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln[nome_feature] = np.where(dados_treino[nome_feature] == 0, 1, np.log(dados_treino[nome_feature]))\n",
    "df_ln[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores maiores que mediana + 3 vezes o desvio padrão.\n",
    "med = df_sem_outlier[nome_feature].median()\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] >= (df_sem_outlier[nome_feature].median() + 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores MENOR que mediana - 3 vezes o desvio padrão.\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] <= (df_sem_outlier[nome_feature].median() - 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target} SEM OUTLIER\\n\")\n",
    "print(df_sem_outlier[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}> SEM OUTLIER\\n\")\n",
    "\n",
    "# df_ln_sem_outlier[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln_sem_outlier[nome_feature] = np.where(dados_treino[nome_feature] == 0, 1, np.log(dados_treino[nome_feature]))\n",
    "df_ln_sem_outlier[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln_sem_outlier[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# ARMAZENAMENTO DAS FEATURES CASO SEJAM UTILIZADAS NO MODELO DE REGRESSÃO LINEAR.\n",
    "\n",
    "# Armazenamento da feature não transformada.\n",
    "features_numericas[nome_feature] = dados_treino[nome_feature]\n",
    "\n",
    "# Armezenamento da feature transformada com ln.\n",
    "features_ln_numericas[nome_feature] = df_ln[nome_feature]\n",
    "\n",
    "# Armazenamento da feature não transformada.\n",
    "features_numericas_sem_outlier[nome_feature] = df_sem_outlier[nome_feature]\n",
    "\n",
    "# Armezenamento da feature transformada com ln.\n",
    "features_ln_numericas_sem_outlier[nome_feature] = df_ln_sem_outlier[nome_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e9e28f",
   "metadata": {},
   "source": [
    "## FireplaceQu (Categórica)\n",
    "\n",
    "Qualidade da Lareira"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "7a673884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 547\n",
      "\n",
      "Como essa variável possue muitos valores não definidos, não iremos trabalhar com ela.\n"
     ]
    }
   ],
   "source": [
    "nome_feature = 'FireplaceQu'\n",
    "\n",
    "# Verificação de valores nulos na variável\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "print(f'Como essa variável possue muitos valores não definidos, não iremos trabalhar com ela.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a9243d",
   "metadata": {},
   "source": [
    "## GarageType (Categórica)\n",
    "\n",
    "Tipo de garagem do imóvel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "75884292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 64\n",
      "\n",
      "Mesmo essa variável tendo muitos valores não definidos, iremos tentar formar uma regressão linear apenas dela com a variável alvo e verificar o indice de conrrelação entres elas.\n",
      "Verficação da disposição da variável em agurpamento:\n",
      "\n",
      "GarageType\n",
      "2Types       6\n",
      "Attchd     693\n",
      "Basment     16\n",
      "BuiltIn     74\n",
      "CarPort      7\n",
      "Detchd     308\n",
      "dtype: int64\n",
      "\n",
      "Após o agrupamento é possivel afirmar que a moda dessa variável é \"Attchd\".\n",
      "\n",
      "Todos os valores não definidos serão convertidos para o valores da moda.\n",
      "\n",
      "Visualização dos primeiros valores do Data Frame criado.\n",
      "\n",
      "      Attchd  Basment  BuiltIn  CarPort  Detchd  SalePrice\n",
      "254        1        0        0        0       0     145000\n",
      "1066       1        0        0        0       0     178000\n",
      "638        1        0        0        0       0      85000\n",
      "799        0        0        0        0       1     175000\n",
      "380        0        0        0        0       1     127000\n",
      "303        1        0        0        0       0     149900\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>SalePrice</td>    <th>  R-squared:         </th> <td>   0.164</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.160</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   45.49</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 05 Dec 2023</td> <th>  Prob (F-statistic):</th> <td>5.59e-43</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:33:38</td>     <th>  Log-Likelihood:    </th> <td> -14698.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.941e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1162</td>      <th>  BIC:               </th> <td>2.944e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td> 1.513e+05</td> <td> 2.89e+04</td> <td>    5.233</td> <td> 0.000</td> <td> 9.46e+04</td> <td> 2.08e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attchd</th>    <td>  4.28e+04</td> <td>  2.9e+04</td> <td>    1.475</td> <td> 0.141</td> <td>-1.41e+04</td> <td> 9.97e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Basment</th>   <td> 1.655e+04</td> <td> 3.39e+04</td> <td>    0.488</td> <td> 0.625</td> <td>   -5e+04</td> <td> 8.31e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BuiltIn</th>   <td>  9.96e+04</td> <td> 3.01e+04</td> <td>    3.314</td> <td> 0.001</td> <td> 4.06e+04</td> <td> 1.59e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CarPort</th>   <td>-4.001e+04</td> <td> 3.94e+04</td> <td>   -1.016</td> <td> 0.310</td> <td>-1.17e+05</td> <td> 3.73e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Detchd</th>    <td> -1.47e+04</td> <td> 2.92e+04</td> <td>   -0.504</td> <td> 0.615</td> <td> -7.2e+04</td> <td> 4.26e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>458.755</td> <th>  Durbin-Watson:     </th> <td>   1.980</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2686.993</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.713</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 9.594</td>  <th>  Cond. No.          </th> <td>    43.1</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              SalePrice   R-squared:                       0.164\n",
       "Model:                            OLS   Adj. R-squared:                  0.160\n",
       "Method:                 Least Squares   F-statistic:                     45.49\n",
       "Date:                Tue, 05 Dec 2023   Prob (F-statistic):           5.59e-43\n",
       "Time:                        15:33:38   Log-Likelihood:                -14698.\n",
       "No. Observations:                1168   AIC:                         2.941e+04\n",
       "Df Residuals:                    1162   BIC:                         2.944e+04\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept   1.513e+05   2.89e+04      5.233      0.000    9.46e+04    2.08e+05\n",
       "Attchd       4.28e+04    2.9e+04      1.475      0.141   -1.41e+04    9.97e+04\n",
       "Basment     1.655e+04   3.39e+04      0.488      0.625      -5e+04    8.31e+04\n",
       "BuiltIn      9.96e+04   3.01e+04      3.314      0.001    4.06e+04    1.59e+05\n",
       "CarPort    -4.001e+04   3.94e+04     -1.016      0.310   -1.17e+05    3.73e+04\n",
       "Detchd      -1.47e+04   2.92e+04     -0.504      0.615    -7.2e+04    4.26e+04\n",
       "==============================================================================\n",
       "Omnibus:                      458.755   Durbin-Watson:                   1.980\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2686.993\n",
       "Skew:                           1.713   Prob(JB):                         0.00\n",
       "Kurtosis:                       9.594   Cond. No.                         43.1\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nome_feature = 'GarageType'\n",
    "\n",
    "# Verificação de valores nulos na variável\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "print(\"Mesmo essa variável tendo muitos valores não definidos, iremos tentar formar uma regressão linear apenas dela com a variável alvo e verificar o indice de conrrelação entres elas.\")\n",
    "\n",
    "# Agrupamento dos valores da variável\n",
    "print('Verficação da disposição da variável em agurpamento:\\n')\n",
    "agrupado = dados_treino.groupby([nome_feature]).size()\n",
    "print(agrupado)\n",
    "\n",
    "print(f'\\nApós o agrupamento é possivel afirmar que a moda dessa variável é \"Attchd\".\\n')\n",
    "print(\"Todos os valores não definidos serão convertidos para o valores da moda.\")\n",
    "\n",
    "# Cópia dos valores que serão manipulados para que os valores originais são sejam alterados.\n",
    "df_dummies_auxiliar_1 = dados_treino[nome_feature].copy()\n",
    "\n",
    "# Eliminação dos valores não válidas pelo valor da moda.\n",
    "df_dummies_auxiliar_1.fillna('Attchd', inplace = True)\n",
    "\n",
    "# Conversão da variável categórica em dicotômica com a exclusão da primeira variável dicotômica.\n",
    "df_dummies_auxiliar = pd.get_dummies(df_dummies_auxiliar_1, columns=[nome_feature], drop_first=True)\n",
    "\n",
    "# Inclusão da variável dependente ao data frame de variáveis dicotômicas.\n",
    "df_dummies_auxiliar[nome_target] = dados_treino[nome_target].copy()\n",
    "\n",
    "print(\"\\nVisualização dos primeiros valores do Data Frame criado.\\n\")\n",
    "\n",
    "# Verificação do data frame.\n",
    "print(df_dummies_auxiliar.head(6))\n",
    "\n",
    "# Estimação do modelo de regressão linear múltipla com n-1 dummies\n",
    "modelo_dummies = sm.OLS.from_formula(\"SalePrice ~ Attchd + Basment + BuiltIn + CarPort + Detchd\", df_dummies_auxiliar).fit()\n",
    "\n",
    "# Verificação dos parâmetros do modelo.\n",
    "modelo_dummies.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf084c97",
   "metadata": {},
   "source": [
    "## GarageYrBlt (Numérica)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "94150331",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 64\n",
      "\n",
      "\n",
      "Correlação entre GarageYrBlt e SalePrice\n",
      "\n",
      "             GarageYrBlt  SalePrice\n",
      "GarageYrBlt      1.00000    0.45981\n",
      "SalePrice        0.45981    1.00000\n",
      "\n",
      "Correlação entre ln<GarageYrBlt> e ln<SalePrice>\n",
      "\n",
      "             GarageYrBlt  SalePrice\n",
      "GarageYrBlt     1.000000   0.479533\n",
      "SalePrice       0.479533   1.000000\n",
      "\n",
      "Correlação entre GarageYrBlt e SalePrice SEM OUTLIER\n",
      "\n",
      "             GarageYrBlt  SalePrice\n",
      "GarageYrBlt     1.000000   0.460414\n",
      "SalePrice       0.460414   1.000000\n",
      "\n",
      "Correlação entre ln<GarageYrBlt> e ln<SalePrice> SEM OUTLIER\n",
      "\n",
      "             GarageYrBlt  SalePrice\n",
      "GarageYrBlt     1.000000   0.480596\n",
      "SalePrice       0.480596   1.000000\n",
      "\n",
      "Quantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "\n",
      "Quantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nome_feature = 'GarageYrBlt'\n",
    "\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Substituição de valores não válidos pela mediana da variável em ambos os data frames.\n",
    "dados_treino[nome_feature].fillna(dados_treino[nome_feature].median(), inplace = True)\n",
    "df_sem_outlier[nome_feature].fillna(df_sem_outlier[nome_feature].median(), inplace = True)\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target}\\n\")\n",
    "print(dados_treino[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}>\\n\")\n",
    "\n",
    "df_ln[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores maiores que mediana + 3 vezes o desvio padrão.\n",
    "med = df_sem_outlier[nome_feature].median()\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] >= (df_sem_outlier[nome_feature].median() + 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores MENOR que mediana - 3 vezes o desvio padrão.\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] <= (df_sem_outlier[nome_feature].median() - 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target} SEM OUTLIER\\n\")\n",
    "print(df_sem_outlier[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}> SEM OUTLIER\\n\")\n",
    "\n",
    "df_ln_sem_outlier[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln_sem_outlier[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln_sem_outlier[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# ARMAZENAMENTO DAS FEATURES CASO SEJAM UTILIZADAS NO MODELO DE REGRESSÃO LINEAR.\n",
    "\n",
    "# Armazenamento da feature não transformada.\n",
    "features_numericas[nome_feature] = dados_treino[nome_feature]\n",
    "\n",
    "# Armezenamento da feature transformada com ln.\n",
    "features_ln_numericas[nome_feature] = df_ln[nome_feature]\n",
    "\n",
    "# Armazenamento da feature não transformada.\n",
    "features_numericas_sem_outlier[nome_feature] = df_sem_outlier[nome_feature]\n",
    "\n",
    "# Armezenamento da feature transformada com ln.\n",
    "features_ln_numericas_sem_outlier[nome_feature] = df_ln_sem_outlier[nome_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2e1a4a",
   "metadata": {},
   "source": [
    "## GarageFinish (Categórica)\n",
    "\n",
    "Acabamento interno da garagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "cfaadacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 64\n",
      "\n",
      "Mesmo essa variável tendo valores não definidos, iremos tentar formar uma regressão linear apenas dela com a variável alvo e verificar o indice de conrrelação entres elas.\n",
      "Verficação da disposição da variável em agurpamento:\n",
      "\n",
      "GarageFinish\n",
      "Fin    285\n",
      "RFn    339\n",
      "Unf    480\n",
      "dtype: int64\n",
      "\n",
      "Após o agrupamento é possivel afirmar que a moda dessa variável é \"Unf\".\n",
      "\n",
      "Todos os valores não definidos serão convertidos para o valores da moda.\n",
      "\n",
      "Visualização dos primeiros valores do Data Frame criado.\n",
      "\n",
      "      RFn  Unf  SalePrice\n",
      "254     1    0     145000\n",
      "1066    1    0     178000\n",
      "638     0    1      85000\n",
      "799     0    1     175000\n",
      "380     0    1     127000\n",
      "303     0    1     149900\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>SalePrice</td>    <th>  R-squared:         </th> <td>   0.292</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.291</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   240.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 05 Dec 2023</td> <th>  Prob (F-statistic):</th> <td>4.92e-88</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:38:29</td>     <th>  Log-Likelihood:    </th> <td> -14601.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.921e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1165</td>      <th>  BIC:               </th> <td>2.922e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td> 2.378e+05</td> <td> 3854.624</td> <td>   61.698</td> <td> 0.000</td> <td>  2.3e+05</td> <td> 2.45e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RFn</th>       <td>-3.563e+04</td> <td> 5229.673</td> <td>   -6.812</td> <td> 0.000</td> <td>-4.59e+04</td> <td>-2.54e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Unf</th>       <td>-9.885e+04</td> <td> 4758.388</td> <td>  -20.775</td> <td> 0.000</td> <td>-1.08e+05</td> <td>-8.95e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>502.460</td> <th>  Durbin-Watson:     </th> <td>   2.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3272.508</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.868</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>10.300</td>  <th>  Cond. No.          </th> <td>    4.37</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              SalePrice   R-squared:                       0.292\n",
       "Model:                            OLS   Adj. R-squared:                  0.291\n",
       "Method:                 Least Squares   F-statistic:                     240.1\n",
       "Date:                Tue, 05 Dec 2023   Prob (F-statistic):           4.92e-88\n",
       "Time:                        15:38:29   Log-Likelihood:                -14601.\n",
       "No. Observations:                1168   AIC:                         2.921e+04\n",
       "Df Residuals:                    1165   BIC:                         2.922e+04\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept   2.378e+05   3854.624     61.698      0.000     2.3e+05    2.45e+05\n",
       "RFn        -3.563e+04   5229.673     -6.812      0.000   -4.59e+04   -2.54e+04\n",
       "Unf        -9.885e+04   4758.388    -20.775      0.000   -1.08e+05   -8.95e+04\n",
       "==============================================================================\n",
       "Omnibus:                      502.460   Durbin-Watson:                   2.003\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3272.508\n",
       "Skew:                           1.868   Prob(JB):                         0.00\n",
       "Kurtosis:                      10.300   Cond. No.                         4.37\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nome_feature = 'GarageFinish'\n",
    "\n",
    "# Verificação de valores nulos na variável\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "print(\"Mesmo essa variável tendo valores não definidos, iremos tentar formar uma regressão linear apenas dela com a variável alvo e verificar o indice de conrrelação entres elas.\")\n",
    "\n",
    "# Agrupamento dos valores da variável\n",
    "print('Verficação da disposição da variável em agurpamento:\\n')\n",
    "agrupado = dados_treino.groupby([nome_feature]).size()\n",
    "print(agrupado)\n",
    "\n",
    "print(f'\\nApós o agrupamento é possivel afirmar que a moda dessa variável é \"Unf\".\\n')\n",
    "print(\"Todos os valores não definidos serão convertidos para o valores da moda.\")\n",
    "\n",
    "# Cópia dos valores que serão manipulados para que os valores originais são sejam alterados.\n",
    "df_dummies_auxiliar_1 = dados_treino[nome_feature].copy()\n",
    "\n",
    "# Eliminação dos valores não válidas pelo valor da moda.\n",
    "df_dummies_auxiliar_1.fillna('Unf', inplace = True)\n",
    "\n",
    "# Conversão da variável categórica em dicotômica com a exclusão da primeira variável dicotômica.\n",
    "df_dummies_auxiliar = pd.get_dummies(df_dummies_auxiliar_1, columns=[nome_feature], drop_first=True)\n",
    "\n",
    "# Inclusão da variável dependente ao data frame de variáveis dicotômicas.\n",
    "df_dummies_auxiliar[nome_target] = dados_treino[nome_target].copy()\n",
    "\n",
    "print(\"\\nVisualização dos primeiros valores do Data Frame criado.\\n\")\n",
    "\n",
    "# Verificação do data frame.\n",
    "print(df_dummies_auxiliar.head(6))\n",
    "\n",
    "# Estimação do modelo de regressão linear múltipla com n-1 dummies\n",
    "modelo_dummies = sm.OLS.from_formula(\"SalePrice ~ RFn + Unf\", df_dummies_auxiliar).fit()\n",
    "\n",
    "# Verificação dos parâmetros do modelo.\n",
    "modelo_dummies.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd637a8",
   "metadata": {},
   "source": [
    "## GarageCars (Numérica)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fbb61ffb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "\n",
      "Correlação entre GarageCars e SalePrice\n",
      "\n",
      "            GarageCars  SalePrice\n",
      "GarageCars    1.000000   0.640991\n",
      "SalePrice     0.640991   1.000000\n",
      "\n",
      "Correlação entre ln<GarageCars> e ln<SalePrice>\n",
      "\n",
      "            GarageCars  SalePrice\n",
      "GarageCars    1.000000   0.464816\n",
      "SalePrice     0.464816   1.000000\n",
      "\n",
      "Correlação entre GarageCars e SalePrice SEM OUTLIER\n",
      "\n",
      "            GarageCars  SalePrice\n",
      "GarageCars    1.000000   0.640991\n",
      "SalePrice     0.640991   1.000000\n",
      "\n",
      "Correlação entre ln<GarageCars> e ln<SalePrice> SEM OUTLIER\n",
      "\n",
      "            GarageCars  SalePrice\n",
      "GarageCars    1.000000   0.464816\n",
      "SalePrice     0.464816   1.000000\n",
      "\n",
      "Quantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "\n",
      "Quantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\John\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "nome_feature = 'GarageCars'\n",
    "\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Substituição de valores não válidos pela mediana da variável em ambos os data frames.\n",
    "dados_treino[nome_feature].fillna(dados_treino[nome_feature].median(), inplace = True)\n",
    "df_sem_outlier[nome_feature].fillna(df_sem_outlier[nome_feature].median(), inplace = True)\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target}\\n\")\n",
    "print(dados_treino[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}>\\n\")\n",
    "\n",
    "# df_ln[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln[nome_feature] = np.where(dados_treino[nome_feature] == 0, 1, np.log(dados_treino[nome_feature]))\n",
    "df_ln[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores maiores que mediana + 3 vezes o desvio padrão.\n",
    "med = df_sem_outlier[nome_feature].median()\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] >= (df_sem_outlier[nome_feature].median() + 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores MENOR que mediana - 3 vezes o desvio padrão.\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] <= (df_sem_outlier[nome_feature].median() - 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target} SEM OUTLIER\\n\")\n",
    "print(df_sem_outlier[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}> SEM OUTLIER\\n\")\n",
    "\n",
    "# df_ln_sem_outlier[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln_sem_outlier[nome_feature] = np.where(dados_treino[nome_feature] == 0, 1, np.log(dados_treino[nome_feature]))\n",
    "df_ln_sem_outlier[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln_sem_outlier[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# # ARMAZENAMENTO DAS FEATURES CASO SEJAM UTILIZADAS NO MODELO DE REGRESSÃO LINEAR.\n",
    "\n",
    "# # Armazenamento da feature não transformada.\n",
    "# features_numericas[nome_feature] = dados_treino[nome_feature]\n",
    "\n",
    "# # Armezenamento da feature transformada com ln.\n",
    "# features_ln_numericas[nome_feature] = df_ln[nome_feature]\n",
    "\n",
    "# # Armazenamento da feature não transformada.\n",
    "# features_numericas_sem_outlier[nome_feature] = df_sem_outlier[nome_feature]\n",
    "\n",
    "# # Armezenamento da feature transformada com ln.\n",
    "# features_ln_numericas_sem_outlier[nome_feature] = df_ln_sem_outlier[nome_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29fe5e4",
   "metadata": {},
   "source": [
    "## GarageArea (Numérica)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7a1f24c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "\n",
      "Correlação entre GarageArea e SalePrice\n",
      "\n",
      "            GarageArea  SalePrice\n",
      "GarageArea    1.000000   0.624139\n",
      "SalePrice     0.624139   1.000000\n",
      "\n",
      "Correlação entre ln<GarageArea> e ln<SalePrice>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            GarageArea  SalePrice\n",
      "GarageArea    1.000000   0.489805\n",
      "SalePrice     0.489805   1.000000\n",
      "\n",
      "Correlação entre GarageArea e SalePrice SEM OUTLIER\n",
      "\n",
      "            GarageArea  SalePrice\n",
      "GarageArea    1.000000   0.617017\n",
      "SalePrice     0.617017   1.000000\n",
      "\n",
      "Correlação entre ln<GarageArea> e ln<SalePrice> SEM OUTLIER\n",
      "\n",
      "            GarageArea  SalePrice\n",
      "GarageArea     1.00000    0.48642\n",
      "SalePrice      0.48642    1.00000\n",
      "\n",
      "Quantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "\n",
      "Quantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "nome_feature = 'GarageArea'\n",
    "\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Substituição de valores não válidos pela mediana da variável em ambos os data frames.\n",
    "dados_treino[nome_feature].fillna(dados_treino[nome_feature].median(), inplace = True)\n",
    "df_sem_outlier[nome_feature].fillna(df_sem_outlier[nome_feature].median(), inplace = True)\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target}\\n\")\n",
    "print(dados_treino[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}>\\n\")\n",
    "\n",
    "# df_ln[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln[nome_feature] = np.where(dados_treino[nome_feature] == 0, 1, np.log(dados_treino[nome_feature]))\n",
    "df_ln[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores maiores que mediana + 3 vezes o desvio padrão.\n",
    "med = df_sem_outlier[nome_feature].median()\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] >= (df_sem_outlier[nome_feature].median() + 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores MENOR que mediana - 3 vezes o desvio padrão.\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] <= (df_sem_outlier[nome_feature].median() - 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target} SEM OUTLIER\\n\")\n",
    "print(df_sem_outlier[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}> SEM OUTLIER\\n\")\n",
    "\n",
    "# df_ln_sem_outlier[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln_sem_outlier[nome_feature] = np.where(dados_treino[nome_feature] == 0, 1, np.log(dados_treino[nome_feature]))\n",
    "df_ln_sem_outlier[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln_sem_outlier[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# ARMAZENAMENTO DAS FEATURES CASO SEJAM UTILIZADAS NO MODELO DE REGRESSÃO LINEAR.\n",
    "\n",
    "# Armazenamento da feature não transformada.\n",
    "features_numericas[nome_feature] = dados_treino[nome_feature]\n",
    "\n",
    "# Armezenamento da feature transformada com ln.\n",
    "features_ln_numericas[nome_feature] = df_ln[nome_feature]\n",
    "\n",
    "# Armazenamento da feature não transformada.\n",
    "features_numericas_sem_outlier[nome_feature] = df_sem_outlier[nome_feature]\n",
    "\n",
    "# Armezenamento da feature transformada com ln.\n",
    "features_ln_numericas_sem_outlier[nome_feature] = df_ln_sem_outlier[nome_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a04a346",
   "metadata": {},
   "source": [
    "## GarageQual (Categórica)\n",
    "\n",
    "Qualidade da Garagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "f824f01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 64\n",
      "\n",
      "Mesmo essa variável tendo valores não definidos, iremos tentar formar uma regressão linear apenas dela com a variável alvo e verificar o indice de conrrelação entres elas.\n",
      "\n",
      "Verficação da disposição da variável em agurpamento:\n",
      "\n",
      "GarageQual\n",
      "Ex       3\n",
      "Fa      36\n",
      "Gd      13\n",
      "Po       2\n",
      "TA    1050\n",
      "dtype: int64\n",
      "\n",
      "Após o agrupamento é possivel afirmar que a moda dessa variável é \"TA\".\n",
      "\n",
      "Todos os valores não definidos serão convertidos para o valores da moda.\n",
      "\n",
      "Visualização dos primeiros valores do Data Frame criado.\n",
      "\n",
      "      Fa  Gd  Po  TA  SalePrice\n",
      "254    0   0   0   1     145000\n",
      "1066   0   0   0   1     178000\n",
      "638    0   0   0   1      85000\n",
      "799    0   0   0   1     175000\n",
      "380    0   0   0   1     127000\n",
      "303    0   0   0   1     149900\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>SalePrice</td>    <th>  R-squared:         </th> <td>   0.022</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.019</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   6.527</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 05 Dec 2023</td> <th>  Prob (F-statistic):</th> <td>3.41e-05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:42:45</td>     <th>  Log-Likelihood:    </th> <td> -14790.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.959e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1163</td>      <th>  BIC:               </th> <td>2.961e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>  2.41e+05</td> <td> 4.42e+04</td> <td>    5.454</td> <td> 0.000</td> <td> 1.54e+05</td> <td> 3.28e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fa</th>        <td>-1.159e+05</td> <td>  4.6e+04</td> <td>   -2.520</td> <td> 0.012</td> <td>-2.06e+05</td> <td>-2.57e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Gd</th>        <td>-2.277e+04</td> <td>  4.9e+04</td> <td>   -0.464</td> <td> 0.642</td> <td>-1.19e+05</td> <td> 7.34e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Po</th>        <td>-1.243e+05</td> <td> 6.99e+04</td> <td>   -1.778</td> <td> 0.076</td> <td>-2.61e+05</td> <td> 1.28e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TA</th>        <td>-5.821e+04</td> <td> 4.43e+04</td> <td>   -1.315</td> <td> 0.189</td> <td>-1.45e+05</td> <td> 2.86e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>444.962</td> <th>  Durbin-Watson:     </th> <td>   2.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2099.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.736</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.575</td>  <th>  Cond. No.          </th> <td>    64.0</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              SalePrice   R-squared:                       0.022\n",
       "Model:                            OLS   Adj. R-squared:                  0.019\n",
       "Method:                 Least Squares   F-statistic:                     6.527\n",
       "Date:                Tue, 05 Dec 2023   Prob (F-statistic):           3.41e-05\n",
       "Time:                        15:42:45   Log-Likelihood:                -14790.\n",
       "No. Observations:                1168   AIC:                         2.959e+04\n",
       "Df Residuals:                    1163   BIC:                         2.961e+04\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept    2.41e+05   4.42e+04      5.454      0.000    1.54e+05    3.28e+05\n",
       "Fa         -1.159e+05    4.6e+04     -2.520      0.012   -2.06e+05   -2.57e+04\n",
       "Gd         -2.277e+04    4.9e+04     -0.464      0.642   -1.19e+05    7.34e+04\n",
       "Po         -1.243e+05   6.99e+04     -1.778      0.076   -2.61e+05    1.28e+04\n",
       "TA         -5.821e+04   4.43e+04     -1.315      0.189   -1.45e+05    2.86e+04\n",
       "==============================================================================\n",
       "Omnibus:                      444.962   Durbin-Watson:                   2.024\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2099.282\n",
       "Skew:                           1.736   Prob(JB):                         0.00\n",
       "Kurtosis:                       8.575   Cond. No.                         64.0\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nome_feature = 'GarageQual'\n",
    "\n",
    "# Verificação de valores nulos na variável\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "print(\"Mesmo essa variável tendo valores não definidos, iremos tentar formar uma regressão linear apenas dela com a variável alvo e verificar o indice de conrrelação entres elas.\")\n",
    "\n",
    "# Agrupamento dos valores da variável\n",
    "print('\\nVerficação da disposição da variável em agurpamento:\\n')\n",
    "agrupado = dados_treino.groupby([nome_feature]).size()\n",
    "print(agrupado)\n",
    "\n",
    "print(f'\\nApós o agrupamento é possivel afirmar que a moda dessa variável é \"TA\".\\n')\n",
    "print(\"Todos os valores não definidos serão convertidos para o valores da moda.\")\n",
    "\n",
    "# Cópia dos valores que serão manipulados para que os valores originais são sejam alterados.\n",
    "df_dummies_auxiliar_1 = dados_treino[nome_feature].copy()\n",
    "\n",
    "# Eliminação dos valores não válidas pelo valor da moda.\n",
    "df_dummies_auxiliar_1.fillna('TA', inplace = True)\n",
    "\n",
    "# Conversão da variável categórica em dicotômica com a exclusão da primeira variável dicotômica.\n",
    "df_dummies_auxiliar = pd.get_dummies(df_dummies_auxiliar_1, columns=[nome_feature], drop_first=True)\n",
    "\n",
    "# Inclusão da variável dependente ao data frame de variáveis dicotômicas.\n",
    "df_dummies_auxiliar[nome_target] = dados_treino[nome_target].copy()\n",
    "\n",
    "print(\"\\nVisualização dos primeiros valores do Data Frame criado.\\n\")\n",
    "\n",
    "# Verificação do data frame.\n",
    "print(df_dummies_auxiliar.head(6))\n",
    "\n",
    "# Estimação do modelo de regressão linear múltipla com n-1 dummies\n",
    "modelo_dummies = sm.OLS.from_formula(\"SalePrice ~ Fa + Gd + Po + TA\", df_dummies_auxiliar).fit()\n",
    "\n",
    "# Verificação dos parâmetros do modelo.\n",
    "modelo_dummies.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbc7227",
   "metadata": {},
   "source": [
    "## GarageCond (Categórica)\n",
    "\n",
    "Condição da garagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "5aa768a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 64\n",
      "\n",
      "Mesmo essa variável tendo 64 valores não definidos, iremos tentar formar uma regressão linear apenas dela com a variável alvo e verificar o indice de conrrelação entres elas.\n",
      "\n",
      "Verficação da disposição da variável em agurpamento:\n",
      "\n",
      "GarageCond\n",
      "Ex       2\n",
      "Fa      27\n",
      "Gd       9\n",
      "Po       5\n",
      "TA    1061\n",
      "dtype: int64\n",
      "\n",
      "Após o agrupamento é possivel afirmar que a moda dessa variável é \"TA\".\n",
      "\n",
      "Todos os valores não definidos serão convertidos para o valores da moda.\n",
      "\n",
      "Visualização dos primeiros valores do Data Frame criado.\n",
      "\n",
      "      Fa  Gd  Po  TA  SalePrice\n",
      "254    0   0   0   1     145000\n",
      "1066   0   0   0   1     178000\n",
      "638    0   0   0   1      85000\n",
      "799    0   0   0   1     175000\n",
      "380    0   0   0   1     127000\n",
      "303    0   0   0   1     149900\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>SalePrice</td>    <th>  R-squared:         </th> <td>   0.020</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.017</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   6.061</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 05 Dec 2023</td> <th>  Prob (F-statistic):</th> <td>7.93e-05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:45:23</td>     <th>  Log-Likelihood:    </th> <td> -14791.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.959e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1163</td>      <th>  BIC:               </th> <td>2.962e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>  1.24e+05</td> <td> 5.42e+04</td> <td>    2.289</td> <td> 0.022</td> <td> 1.77e+04</td> <td>  2.3e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fa</th>        <td>-6559.5926</td> <td> 5.61e+04</td> <td>   -0.117</td> <td> 0.907</td> <td>-1.17e+05</td> <td> 1.04e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Gd</th>        <td> 5.593e+04</td> <td> 5.99e+04</td> <td>    0.934</td> <td> 0.351</td> <td>-6.16e+04</td> <td> 1.73e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Po</th>        <td>-7100.0000</td> <td> 6.41e+04</td> <td>   -0.111</td> <td> 0.912</td> <td>-1.33e+05</td> <td> 1.19e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TA</th>        <td> 5.938e+04</td> <td> 5.42e+04</td> <td>    1.095</td> <td> 0.274</td> <td> -4.7e+04</td> <td> 1.66e+05</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>448.228</td> <th>  Durbin-Watson:     </th> <td>   2.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2118.512</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.750</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.592</td>  <th>  Cond. No.          </th> <td>    76.4</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              SalePrice   R-squared:                       0.020\n",
       "Model:                            OLS   Adj. R-squared:                  0.017\n",
       "Method:                 Least Squares   F-statistic:                     6.061\n",
       "Date:                Tue, 05 Dec 2023   Prob (F-statistic):           7.93e-05\n",
       "Time:                        15:45:23   Log-Likelihood:                -14791.\n",
       "No. Observations:                1168   AIC:                         2.959e+04\n",
       "Df Residuals:                    1163   BIC:                         2.962e+04\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept    1.24e+05   5.42e+04      2.289      0.022    1.77e+04     2.3e+05\n",
       "Fa         -6559.5926   5.61e+04     -0.117      0.907   -1.17e+05    1.04e+05\n",
       "Gd          5.593e+04   5.99e+04      0.934      0.351   -6.16e+04    1.73e+05\n",
       "Po         -7100.0000   6.41e+04     -0.111      0.912   -1.33e+05    1.19e+05\n",
       "TA          5.938e+04   5.42e+04      1.095      0.274    -4.7e+04    1.66e+05\n",
       "==============================================================================\n",
       "Omnibus:                      448.228   Durbin-Watson:                   2.012\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2118.512\n",
       "Skew:                           1.750   Prob(JB):                         0.00\n",
       "Kurtosis:                       8.592   Cond. No.                         76.4\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nome_feature = 'GarageCond'\n",
    "\n",
    "# Verificação de valores nulos na variável\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "print(\"Mesmo essa variável tendo 64 valores não definidos, iremos tentar formar uma regressão linear apenas dela com a variável alvo e verificar o indice de conrrelação entres elas.\")\n",
    "\n",
    "# Agrupamento dos valores da variável\n",
    "print('\\nVerficação da disposição da variável em agurpamento:\\n')\n",
    "agrupado = dados_treino.groupby([nome_feature]).size()\n",
    "print(agrupado)\n",
    "\n",
    "print(f'\\nApós o agrupamento é possivel afirmar que a moda dessa variável é \"TA\".\\n')\n",
    "print(\"Todos os valores não definidos serão convertidos para o valores da moda.\")\n",
    "\n",
    "# Cópia dos valores que serão manipulados para que os valores originais são sejam alterados.\n",
    "df_dummies_auxiliar_1 = dados_treino[nome_feature].copy()\n",
    "\n",
    "# Eliminação dos valores não válidas pelo valor da moda.\n",
    "df_dummies_auxiliar_1.fillna('TA', inplace = True)\n",
    "\n",
    "# Conversão da variável categórica em dicotômica com a exclusão da primeira variável dicotômica.\n",
    "df_dummies_auxiliar = pd.get_dummies(df_dummies_auxiliar_1, columns=[nome_feature], drop_first=True)\n",
    "\n",
    "# Inclusão da variável dependente ao data frame de variáveis dicotômicas.\n",
    "df_dummies_auxiliar[nome_target] = dados_treino[nome_target].copy()\n",
    "\n",
    "print(\"\\nVisualização dos primeiros valores do Data Frame criado.\\n\")\n",
    "\n",
    "# Verificação do data frame.\n",
    "print(df_dummies_auxiliar.head(6))\n",
    "\n",
    "# Estimação do modelo de regressão linear múltipla com n-1 dummies\n",
    "modelo_dummies = sm.OLS.from_formula(\"SalePrice ~ Fa + Gd + Po + TA\", df_dummies_auxiliar).fit()\n",
    "\n",
    "# Verificação dos parâmetros do modelo.\n",
    "modelo_dummies.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb43c53",
   "metadata": {},
   "source": [
    "## PavedDrive (Categórica)\n",
    "\n",
    "Condições da área de acesso para os veículos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "047e2d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "\n",
      "Verficação da disposição da variável em agurpamento:\n",
      "\n",
      "PavedDrive\n",
      "N      73\n",
      "P      25\n",
      "Y    1070\n",
      "dtype: int64\n",
      "\n",
      "Visualização dos primeiros valores do Data Frame criado.\n",
      "\n",
      "      P  Y  SalePrice\n",
      "254   0  1     145000\n",
      "1066  0  1     178000\n",
      "638   1  0      85000\n",
      "799   0  1     175000\n",
      "380   0  1     127000\n",
      "303   0  1     149900\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>SalePrice</td>    <th>  R-squared:         </th> <td>   0.054</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.052</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   32.93</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 05 Dec 2023</td> <th>  Prob (F-statistic):</th> <td>1.23e-14</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:48:17</td>     <th>  Log-Likelihood:    </th> <td> -14771.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.955e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1165</td>      <th>  BIC:               </th> <td>2.956e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td> 1.178e+05</td> <td> 8805.336</td> <td>   13.383</td> <td> 0.000</td> <td> 1.01e+05</td> <td> 1.35e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P</th>         <td> 2.034e+04</td> <td> 1.74e+04</td> <td>    1.166</td> <td> 0.244</td> <td>-1.39e+04</td> <td> 5.45e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Y</th>         <td> 6.895e+04</td> <td> 9100.749</td> <td>    7.576</td> <td> 0.000</td> <td> 5.11e+04</td> <td> 8.68e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>459.612</td> <th>  Durbin-Watson:     </th> <td>   2.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2254.112</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.787</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.792</td>  <th>  Cond. No.          </th> <td>    11.8</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              SalePrice   R-squared:                       0.054\n",
       "Model:                            OLS   Adj. R-squared:                  0.052\n",
       "Method:                 Least Squares   F-statistic:                     32.93\n",
       "Date:                Tue, 05 Dec 2023   Prob (F-statistic):           1.23e-14\n",
       "Time:                        15:48:17   Log-Likelihood:                -14771.\n",
       "No. Observations:                1168   AIC:                         2.955e+04\n",
       "Df Residuals:                    1165   BIC:                         2.956e+04\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept   1.178e+05   8805.336     13.383      0.000    1.01e+05    1.35e+05\n",
       "P           2.034e+04   1.74e+04      1.166      0.244   -1.39e+04    5.45e+04\n",
       "Y           6.895e+04   9100.749      7.576      0.000    5.11e+04    8.68e+04\n",
       "==============================================================================\n",
       "Omnibus:                      459.612   Durbin-Watson:                   2.036\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2254.112\n",
       "Skew:                           1.787   Prob(JB):                         0.00\n",
       "Kurtosis:                       8.792   Cond. No.                         11.8\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nome_feature = 'PavedDrive'\n",
    "\n",
    "# Verificação de valores nulos na variável\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Agrupamento dos valores da variável\n",
    "print('\\nVerficação da disposição da variável em agurpamento:\\n')\n",
    "agrupado = dados_treino.groupby([nome_feature]).size()\n",
    "print(agrupado)\n",
    "\n",
    "# Cópia dos valores que serão manipulados para que os valores originais são sejam alterados.\n",
    "df_dummies_auxiliar_1 = dados_treino[nome_feature].copy()\n",
    "\n",
    "# Conversão da variável categórica em dicotômica com a exclusão da primeira variável dicotômica.\n",
    "df_dummies_auxiliar = pd.get_dummies(df_dummies_auxiliar_1, columns=[nome_feature], drop_first=True)\n",
    "\n",
    "# Inclusão da variável dependente ao data frame de variáveis dicotômicas.\n",
    "df_dummies_auxiliar[nome_target] = dados_treino[nome_target].copy()\n",
    "\n",
    "print(\"\\nVisualização dos primeiros valores do Data Frame criado.\\n\")\n",
    "\n",
    "# Verificação do data frame.\n",
    "print(df_dummies_auxiliar.head(6))\n",
    "\n",
    "# Estimação do modelo de regressão linear múltipla com n-1 dummies\n",
    "modelo_dummies = sm.OLS.from_formula(\"SalePrice ~ P + Y\", df_dummies_auxiliar).fit()\n",
    "\n",
    "# Verificação dos parâmetros do modelo.\n",
    "modelo_dummies.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23edd421",
   "metadata": {},
   "source": [
    "## WoodDeckSF (Numérica)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6de3ab7e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "\n",
      "Correlação entre WoodDeckSF e SalePrice\n",
      "\n",
      "            WoodDeckSF  SalePrice\n",
      "WoodDeckSF    1.000000   0.329843\n",
      "SalePrice     0.329843   1.000000\n",
      "\n",
      "Correlação entre ln<WoodDeckSF> e ln<SalePrice>\n",
      "\n",
      "            WoodDeckSF  SalePrice\n",
      "WoodDeckSF    1.000000   0.365981\n",
      "SalePrice     0.365981   1.000000\n",
      "\n",
      "Correlação entre WoodDeckSF e SalePrice SEM OUTLIER\n",
      "\n",
      "            WoodDeckSF  SalePrice\n",
      "WoodDeckSF    1.000000   0.297535\n",
      "SalePrice     0.297535   1.000000\n",
      "\n",
      "Correlação entre ln<WoodDeckSF> e ln<SalePrice> SEM OUTLIER\n",
      "\n",
      "            WoodDeckSF  SalePrice\n",
      "WoodDeckSF    1.000000   0.320093\n",
      "SalePrice     0.320093   1.000000\n",
      "\n",
      "Quantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "\n",
      "Quantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\John\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "nome_feature = 'WoodDeckSF'\n",
    "\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Substituição de valores não válidos pela mediana da variável em ambos os data frames.\n",
    "dados_treino[nome_feature].fillna(dados_treino[nome_feature].median(), inplace = True)\n",
    "df_sem_outlier[nome_feature].fillna(df_sem_outlier[nome_feature].median(), inplace = True)\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target}\\n\")\n",
    "print(dados_treino[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}>\\n\")\n",
    "\n",
    "# df_ln[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln[nome_feature] = np.where(dados_treino[nome_feature] == 0, 1, np.log(dados_treino[nome_feature]))\n",
    "df_ln[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores maiores que mediana + 3 vezes o desvio padrão.\n",
    "med = df_sem_outlier[nome_feature].median()\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] >= (df_sem_outlier[nome_feature].median() + 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores MENOR que mediana - 3 vezes o desvio padrão.\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] <= (df_sem_outlier[nome_feature].median() - 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target} SEM OUTLIER\\n\")\n",
    "print(df_sem_outlier[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}> SEM OUTLIER\\n\")\n",
    "\n",
    "# df_ln_sem_outlier[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln_sem_outlier[nome_feature] = np.where(dados_treino[nome_feature] == 0, 1, np.log(dados_treino[nome_feature]))\n",
    "df_ln_sem_outlier[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln_sem_outlier[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# ARMAZENAMENTO DAS FEATURES CASO SEJAM UTILIZADAS NO MODELO DE REGRESSÃO LINEAR.\n",
    "\n",
    "# Armazenamento da feature não transformada.\n",
    "features_numericas[nome_feature] = dados_treino[nome_feature]\n",
    "\n",
    "# Armezenamento da feature transformada com ln.\n",
    "features_ln_numericas[nome_feature] = df_ln[nome_feature]\n",
    "\n",
    "# Armazenamento da feature não transformada.\n",
    "features_numericas_sem_outlier[nome_feature] = df_sem_outlier[nome_feature]\n",
    "\n",
    "# Armezenamento da feature transformada com ln.\n",
    "features_ln_numericas_sem_outlier[nome_feature] = df_ln_sem_outlier[nome_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6de8fc8",
   "metadata": {},
   "source": [
    "## OpenPorchSF (Numérica)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "70de4568",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "\n",
      "Correlação entre OpenPorchSF e SalePrice\n",
      "\n",
      "             OpenPorchSF  SalePrice\n",
      "OpenPorchSF     1.000000   0.299969\n",
      "SalePrice       0.299969   1.000000\n",
      "\n",
      "Correlação entre ln<OpenPorchSF> e ln<SalePrice>\n",
      "\n",
      "             OpenPorchSF  SalePrice\n",
      "OpenPorchSF     1.000000   0.457373\n",
      "SalePrice       0.457373   1.000000\n",
      "\n",
      "Correlação entre OpenPorchSF e SalePrice SEM OUTLIER\n",
      "\n",
      "             OpenPorchSF  SalePrice\n",
      "OpenPorchSF     1.000000   0.354971\n",
      "SalePrice       0.354971   1.000000\n",
      "\n",
      "Correlação entre ln<OpenPorchSF> e ln<SalePrice> SEM OUTLIER\n",
      "\n",
      "             OpenPorchSF  SalePrice\n",
      "OpenPorchSF     1.000000   0.466921\n",
      "SalePrice       0.466921   1.000000\n",
      "\n",
      "Quantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "\n",
      "Quantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\John\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "nome_feature = 'OpenPorchSF'\n",
    "\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Substituição de valores não válidos pela mediana da variável em ambos os data frames.\n",
    "dados_treino[nome_feature].fillna(dados_treino[nome_feature].median(), inplace = True)\n",
    "df_sem_outlier[nome_feature].fillna(df_sem_outlier[nome_feature].median(), inplace = True)\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target}\\n\")\n",
    "print(dados_treino[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}>\\n\")\n",
    "\n",
    "# df_ln[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln[nome_feature] = np.where(dados_treino[nome_feature] == 0, 1, np.log(dados_treino[nome_feature]))\n",
    "df_ln[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores maiores que mediana + 3 vezes o desvio padrão.\n",
    "med = df_sem_outlier[nome_feature].median()\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] >= (df_sem_outlier[nome_feature].median() + 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores MENOR que mediana - 3 vezes o desvio padrão.\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] <= (df_sem_outlier[nome_feature].median() - 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target} SEM OUTLIER\\n\")\n",
    "print(df_sem_outlier[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}> SEM OUTLIER\\n\")\n",
    "\n",
    "# df_ln_sem_outlier[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln_sem_outlier[nome_feature] = np.where(dados_treino[nome_feature] == 0, 1, np.log(dados_treino[nome_feature]))\n",
    "df_ln_sem_outlier[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln_sem_outlier[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# ARMAZENAMENTO DAS FEATURES CASO SEJAM UTILIZADAS NO MODELO DE REGRESSÃO LINEAR.\n",
    "\n",
    "# Armazenamento da feature não transformada.\n",
    "features_numericas[nome_feature] = dados_treino[nome_feature]\n",
    "\n",
    "# Armezenamento da feature transformada com ln.\n",
    "features_ln_numericas[nome_feature] = df_ln[nome_feature]\n",
    "\n",
    "# Armazenamento da feature não transformada.\n",
    "features_numericas_sem_outlier[nome_feature] = df_sem_outlier[nome_feature]\n",
    "\n",
    "# Armezenamento da feature transformada com ln.\n",
    "features_ln_numericas_sem_outlier[nome_feature] = df_ln_sem_outlier[nome_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36736626",
   "metadata": {},
   "source": [
    "## EnclosedPorch (Numérica)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d5b3fe12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "\n",
      "Correlação entre EnclosedPorch e SalePrice\n",
      "\n",
      "               EnclosedPorch  SalePrice\n",
      "EnclosedPorch       1.000000  -0.149532\n",
      "SalePrice          -0.149532   1.000000\n",
      "\n",
      "Correlação entre ln<EnclosedPorch> e ln<SalePrice>\n",
      "\n",
      "               EnclosedPorch  SalePrice\n",
      "EnclosedPorch        1.00000   -0.22274\n",
      "SalePrice           -0.22274    1.00000\n",
      "\n",
      "Correlação entre EnclosedPorch e SalePrice SEM OUTLIER\n",
      "\n",
      "               EnclosedPorch  SalePrice\n",
      "EnclosedPorch       1.000000  -0.169576\n",
      "SalePrice          -0.169576   1.000000\n",
      "\n",
      "Correlação entre ln<EnclosedPorch> e ln<SalePrice> SEM OUTLIER\n",
      "\n",
      "               EnclosedPorch  SalePrice\n",
      "EnclosedPorch       1.000000  -0.220302\n",
      "SalePrice          -0.220302   1.000000\n",
      "\n",
      "Quantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "\n",
      "Quantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\John\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "nome_feature = 'EnclosedPorch'\n",
    "\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Substituição de valores não válidos pela mediana da variável em ambos os data frames.\n",
    "dados_treino[nome_feature].fillna(dados_treino[nome_feature].median(), inplace = True)\n",
    "df_sem_outlier[nome_feature].fillna(df_sem_outlier[nome_feature].median(), inplace = True)\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target}\\n\")\n",
    "print(dados_treino[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}>\\n\")\n",
    "\n",
    "# df_ln[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln[nome_feature] = np.where(dados_treino[nome_feature] == 0, 1, np.log(dados_treino[nome_feature]))\n",
    "df_ln[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores maiores que mediana + 3 vezes o desvio padrão.\n",
    "med = df_sem_outlier[nome_feature].median()\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] >= (df_sem_outlier[nome_feature].median() + 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores MENOR que mediana - 3 vezes o desvio padrão.\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] <= (df_sem_outlier[nome_feature].median() - 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target} SEM OUTLIER\\n\")\n",
    "print(df_sem_outlier[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}> SEM OUTLIER\\n\")\n",
    "\n",
    "# df_ln_sem_outlier[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln_sem_outlier[nome_feature] = np.where(dados_treino[nome_feature] == 0, 1, np.log(dados_treino[nome_feature]))\n",
    "df_ln_sem_outlier[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln_sem_outlier[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# # ARMAZENAMENTO DAS FEATURES CASO SEJAM UTILIZADAS NO MODELO DE REGRESSÃO LINEAR.\n",
    "\n",
    "# # Armazenamento da feature não transformada.\n",
    "# features_numericas[nome_feature] = dados_treino[nome_feature]\n",
    "\n",
    "# # Armezenamento da feature transformada com ln.\n",
    "# features_ln_numericas[nome_feature] = df_ln[nome_feature]\n",
    "\n",
    "# # Armazenamento da feature não transformada.\n",
    "# features_numericas_sem_outlier[nome_feature] = df_sem_outlier[nome_feature]\n",
    "\n",
    "# # Armezenamento da feature transformada com ln.\n",
    "# features_ln_numericas_sem_outlier[nome_feature] = df_ln_sem_outlier[nome_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d06e999",
   "metadata": {},
   "source": [
    "## 3SsnPorch (Numérica)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "47869c5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "\n",
      "Correlação entre 3SsnPorch e SalePrice\n",
      "\n",
      "           3SsnPorch  SalePrice\n",
      "3SsnPorch   1.000000   0.051532\n",
      "SalePrice   0.051532   1.000000\n",
      "\n",
      "Correlação entre ln<3SsnPorch> e ln<SalePrice>\n",
      "\n",
      "           3SsnPorch  SalePrice\n",
      "3SsnPorch   1.000000   0.064786\n",
      "SalePrice   0.064786   1.000000\n",
      "\n",
      "Correlação entre 3SsnPorch e SalePrice SEM OUTLIER\n",
      "\n",
      "           3SsnPorch  SalePrice\n",
      "3SsnPorch        NaN        NaN\n",
      "SalePrice        NaN        1.0\n",
      "\n",
      "Correlação entre ln<3SsnPorch> e ln<SalePrice> SEM OUTLIER\n",
      "\n",
      "           3SsnPorch  SalePrice\n",
      "3SsnPorch        NaN        NaN\n",
      "SalePrice        NaN        1.0\n",
      "\n",
      "Quantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "\n",
      "Quantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\John\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "nome_feature = '3SsnPorch'\n",
    "\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Substituição de valores não válidos pela mediana da variável em ambos os data frames.\n",
    "dados_treino[nome_feature].fillna(dados_treino[nome_feature].median(), inplace = True)\n",
    "df_sem_outlier[nome_feature].fillna(df_sem_outlier[nome_feature].median(), inplace = True)\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target}\\n\")\n",
    "print(dados_treino[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}>\\n\")\n",
    "\n",
    "# df_ln[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln[nome_feature] = np.where(dados_treino[nome_feature] == 0, 1, np.log(dados_treino[nome_feature]))\n",
    "df_ln[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores maiores que mediana + 3 vezes o desvio padrão.\n",
    "med = df_sem_outlier[nome_feature].median()\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] >= (df_sem_outlier[nome_feature].median() + 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores MENOR que mediana - 3 vezes o desvio padrão.\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] <= (df_sem_outlier[nome_feature].median() - 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target} SEM OUTLIER\\n\")\n",
    "print(df_sem_outlier[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}> SEM OUTLIER\\n\")\n",
    "\n",
    "# df_ln_sem_outlier[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln_sem_outlier[nome_feature] = np.where(dados_treino[nome_feature] == 0, 1, np.log(dados_treino[nome_feature]))\n",
    "df_ln_sem_outlier[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln_sem_outlier[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# # ARMAZENAMENTO DAS FEATURES CASO SEJAM UTILIZADAS NO MODELO DE REGRESSÃO LINEAR.\n",
    "\n",
    "# # Armazenamento da feature não transformada.\n",
    "# features_numericas[nome_feature] = dados_treino[nome_feature]\n",
    "\n",
    "# # Armezenamento da feature transformada com ln.\n",
    "# features_ln_numericas[nome_feature] = df_ln[nome_feature]\n",
    "\n",
    "# # Armazenamento da feature não transformada.\n",
    "# features_numericas_sem_outlier[nome_feature] = df_sem_outlier[nome_feature]\n",
    "\n",
    "# # Armezenamento da feature transformada com ln.\n",
    "# features_ln_numericas_sem_outlier[nome_feature] = df_ln_sem_outlier[nome_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a41f29",
   "metadata": {},
   "source": [
    "## ScreenPorch (Numérica)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d00c8413",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "\n",
      "Correlação entre ScreenPorch e SalePrice\n",
      "\n",
      "             ScreenPorch  SalePrice\n",
      "ScreenPorch     1.000000   0.119172\n",
      "SalePrice       0.119172   1.000000\n",
      "\n",
      "Correlação entre ln<ScreenPorch> e ln<SalePrice>\n",
      "\n",
      "             ScreenPorch  SalePrice\n",
      "ScreenPorch     1.000000   0.108928\n",
      "SalePrice       0.108928   1.000000\n",
      "\n",
      "Correlação entre ScreenPorch e SalePrice SEM OUTLIER\n",
      "\n",
      "             ScreenPorch  SalePrice\n",
      "ScreenPorch     1.000000   0.000126\n",
      "SalePrice       0.000126   1.000000\n",
      "\n",
      "Correlação entre ln<ScreenPorch> e ln<SalePrice> SEM OUTLIER\n",
      "\n",
      "             ScreenPorch  SalePrice\n",
      "ScreenPorch     1.000000   0.005706\n",
      "SalePrice       0.005706   1.000000\n",
      "\n",
      "Quantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "\n",
      "Quantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\John\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "nome_feature = 'ScreenPorch'\n",
    "\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Substituição de valores não válidos pela mediana da variável em ambos os data frames.\n",
    "dados_treino[nome_feature].fillna(dados_treino[nome_feature].median(), inplace = True)\n",
    "df_sem_outlier[nome_feature].fillna(df_sem_outlier[nome_feature].median(), inplace = True)\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target}\\n\")\n",
    "print(dados_treino[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}>\\n\")\n",
    "\n",
    "# df_ln[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln[nome_feature] = np.where(dados_treino[nome_feature] == 0, 1, np.log(dados_treino[nome_feature]))\n",
    "df_ln[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores maiores que mediana + 3 vezes o desvio padrão.\n",
    "med = df_sem_outlier[nome_feature].median()\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] >= (df_sem_outlier[nome_feature].median() + 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores MENOR que mediana - 3 vezes o desvio padrão.\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] <= (df_sem_outlier[nome_feature].median() - 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target} SEM OUTLIER\\n\")\n",
    "print(df_sem_outlier[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}> SEM OUTLIER\\n\")\n",
    "\n",
    "# df_ln_sem_outlier[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln_sem_outlier[nome_feature] = np.where(dados_treino[nome_feature] == 0, 1, np.log(dados_treino[nome_feature]))\n",
    "df_ln_sem_outlier[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln_sem_outlier[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# # ARMAZENAMENTO DAS FEATURES CASO SEJAM UTILIZADAS NO MODELO DE REGRESSÃO LINEAR.\n",
    "\n",
    "# # Armazenamento da feature não transformada.\n",
    "# features_numericas[nome_feature] = dados_treino[nome_feature]\n",
    "\n",
    "# # Armezenamento da feature transformada com ln.\n",
    "# features_ln_numericas[nome_feature] = df_ln[nome_feature]\n",
    "\n",
    "# # Armazenamento da feature não transformada.\n",
    "# features_numericas_sem_outlier[nome_feature] = df_sem_outlier[nome_feature]\n",
    "\n",
    "# # Armezenamento da feature transformada com ln.\n",
    "# features_ln_numericas_sem_outlier[nome_feature] = df_ln_sem_outlier[nome_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d2e568",
   "metadata": {},
   "source": [
    "## PoolArea (Numérica)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "803c9254",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "\n",
      "Correlação entre PoolArea e SalePrice\n",
      "\n",
      "           PoolArea  SalePrice\n",
      "PoolArea    1.00000    0.11563\n",
      "SalePrice   0.11563    1.00000\n",
      "\n",
      "Correlação entre ln<PoolArea> e ln<SalePrice>\n",
      "\n",
      "           PoolArea  SalePrice\n",
      "PoolArea   1.000000   0.084458\n",
      "SalePrice  0.084458   1.000000\n",
      "\n",
      "Correlação entre PoolArea e SalePrice SEM OUTLIER\n",
      "\n",
      "           PoolArea  SalePrice\n",
      "PoolArea        NaN        NaN\n",
      "SalePrice       NaN        1.0\n",
      "\n",
      "Correlação entre ln<PoolArea> e ln<SalePrice> SEM OUTLIER\n",
      "\n",
      "           PoolArea  SalePrice\n",
      "PoolArea        NaN        NaN\n",
      "SalePrice       NaN        1.0\n",
      "\n",
      "Quantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "\n",
      "Quantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "nome_feature = 'PoolArea'\n",
    "\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Substituição de valores não válidos pela mediana da variável em ambos os data frames.\n",
    "dados_treino[nome_feature].fillna(dados_treino[nome_feature].median(), inplace = True)\n",
    "df_sem_outlier[nome_feature].fillna(df_sem_outlier[nome_feature].median(), inplace = True)\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target}\\n\")\n",
    "print(dados_treino[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}>\\n\")\n",
    "\n",
    "# df_ln[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln[nome_feature] = np.where(dados_treino[nome_feature] == 0, 1, np.log(dados_treino[nome_feature]))\n",
    "df_ln[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores maiores que mediana + 3 vezes o desvio padrão.\n",
    "med = df_sem_outlier[nome_feature].median()\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] >= (df_sem_outlier[nome_feature].median() + 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores MENOR que mediana - 3 vezes o desvio padrão.\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] <= (df_sem_outlier[nome_feature].median() - 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target} SEM OUTLIER\\n\")\n",
    "print(df_sem_outlier[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}> SEM OUTLIER\\n\")\n",
    "\n",
    "# df_ln_sem_outlier[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln_sem_outlier[nome_feature] = np.where(dados_treino[nome_feature] == 0, 1, np.log(dados_treino[nome_feature]))\n",
    "df_ln_sem_outlier[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln_sem_outlier[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# # ARMAZENAMENTO DAS FEATURES CASO SEJAM UTILIZADAS NO MODELO DE REGRESSÃO LINEAR.\n",
    "\n",
    "# # Armazenamento da feature não transformada.\n",
    "# features_numericas[nome_feature] = dados_treino[nome_feature]\n",
    "\n",
    "# # Armezenamento da feature transformada com ln.\n",
    "# features_ln_numericas[nome_feature] = df_ln[nome_feature]\n",
    "\n",
    "# # Armazenamento da feature não transformada.\n",
    "# features_numericas_sem_outlier[nome_feature] = df_sem_outlier[nome_feature]\n",
    "\n",
    "# # Armezenamento da feature transformada com ln.\n",
    "# features_ln_numericas_sem_outlier[nome_feature] = df_ln_sem_outlier[nome_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92729a08",
   "metadata": {},
   "source": [
    "## PoolQC (Categórica)\n",
    "\n",
    "Qualidade da piscina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "cbad675e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 1162\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nome_feature = 'PoolQC'\n",
    "\n",
    "# Verificação de valores nulos na variável\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "print(\"A maioria dos valores dessa variável são indefidas, por isso não iremos utilizá-la.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9140932c",
   "metadata": {},
   "source": [
    "## Fence (Categórica)\n",
    "\n",
    "Qualidade da cerca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "aa5dd2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 935\n",
      "\n",
      "Da mesma forma que a variável anterior, essa variável possue muitos valores indefinidos, por isso não será utilizada.\n"
     ]
    }
   ],
   "source": [
    "nome_feature = 'Fence'\n",
    "\n",
    "# Verificação de valores nulos na variável\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "print(\"Da mesma forma que a variável anterior, essa variável possue muitos valores indefinidos, por isso não será utilizada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aef0baa",
   "metadata": {},
   "source": [
    "## MiscFeature (Categórica)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04d7193",
   "metadata": {},
   "source": [
    "## MiscVal (Numérica)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "08987d1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "\n",
      "Correlação entre MiscVal e SalePrice\n",
      "\n",
      "            MiscVal  SalePrice\n",
      "MiscVal    1.000000  -0.020179\n",
      "SalePrice -0.020179   1.000000\n",
      "\n",
      "Correlação entre ln<MiscVal> e ln<SalePrice>\n",
      "\n",
      "            MiscVal  SalePrice\n",
      "MiscVal    1.000000  -0.048269\n",
      "SalePrice -0.048269   1.000000\n",
      "\n",
      "Correlação entre MiscVal e SalePrice SEM OUTLIER\n",
      "\n",
      "            MiscVal  SalePrice\n",
      "MiscVal    1.000000  -0.052314\n",
      "SalePrice -0.052314   1.000000\n",
      "\n",
      "Correlação entre ln<MiscVal> e ln<SalePrice> SEM OUTLIER\n",
      "\n",
      "            MiscVal  SalePrice\n",
      "MiscVal    1.000000  -0.054359\n",
      "SalePrice -0.054359   1.000000\n",
      "\n",
      "Quantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "\n",
      "Quantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\John\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "nome_feature = 'MiscVal'\n",
    "\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Substituição de valores não válidos pela mediana da variável em ambos os data frames.\n",
    "dados_treino[nome_feature].fillna(dados_treino[nome_feature].median(), inplace = True)\n",
    "df_sem_outlier[nome_feature].fillna(df_sem_outlier[nome_feature].median(), inplace = True)\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target}\\n\")\n",
    "print(dados_treino[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}>\\n\")\n",
    "\n",
    "# df_ln[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln[nome_feature] = np.where(dados_treino[nome_feature] == 0, 1, np.log(dados_treino[nome_feature]))\n",
    "df_ln[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores maiores que mediana + 3 vezes o desvio padrão.\n",
    "med = df_sem_outlier[nome_feature].median()\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] >= (df_sem_outlier[nome_feature].median() + 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores MENOR que mediana - 3 vezes o desvio padrão.\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] <= (df_sem_outlier[nome_feature].median() - 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target} SEM OUTLIER\\n\")\n",
    "print(df_sem_outlier[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}> SEM OUTLIER\\n\")\n",
    "\n",
    "# df_ln_sem_outlier[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln_sem_outlier[nome_feature] = np.where(dados_treino[nome_feature] == 0, 1, np.log(dados_treino[nome_feature]))\n",
    "df_ln_sem_outlier[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln_sem_outlier[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# # ARMAZENAMENTO DAS FEATURES CASO SEJAM UTILIZADAS NO MODELO DE REGRESSÃO LINEAR.\n",
    "\n",
    "# # Armazenamento da feature não transformada.\n",
    "# features_numericas[nome_feature] = dados_treino[nome_feature]\n",
    "\n",
    "# # Armezenamento da feature transformada com ln.\n",
    "# features_ln_numericas[nome_feature] = df_ln[nome_feature]\n",
    "\n",
    "# # Armazenamento da feature não transformada.\n",
    "# features_numericas_sem_outlier[nome_feature] = df_sem_outlier[nome_feature]\n",
    "\n",
    "# # Armezenamento da feature transformada com ln.\n",
    "# features_ln_numericas_sem_outlier[nome_feature] = df_ln_sem_outlier[nome_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3229175",
   "metadata": {},
   "source": [
    "## MoSold (Numérica)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "39e33b73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "\n",
      "Correlação entre MoSold e SalePrice\n",
      "\n",
      "            MoSold  SalePrice\n",
      "MoSold     1.00000    0.04189\n",
      "SalePrice  0.04189    1.00000\n",
      "\n",
      "Correlação entre ln<MoSold> e ln<SalePrice>\n",
      "\n",
      "             MoSold  SalePrice\n",
      "MoSold     1.000000   0.045325\n",
      "SalePrice  0.045325   1.000000\n",
      "\n",
      "Correlação entre MoSold e SalePrice SEM OUTLIER\n",
      "\n",
      "            MoSold  SalePrice\n",
      "MoSold     1.00000    0.04189\n",
      "SalePrice  0.04189    1.00000\n",
      "\n",
      "Correlação entre ln<MoSold> e ln<SalePrice> SEM OUTLIER\n",
      "\n",
      "             MoSold  SalePrice\n",
      "MoSold     1.000000   0.045325\n",
      "SalePrice  0.045325   1.000000\n",
      "\n",
      "Quantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "\n",
      "Quantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nome_feature = 'MoSold'\n",
    "\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Substituição de valores não válidos pela mediana da variável em ambos os data frames.\n",
    "dados_treino[nome_feature].fillna(dados_treino[nome_feature].median(), inplace = True)\n",
    "df_sem_outlier[nome_feature].fillna(df_sem_outlier[nome_feature].median(), inplace = True)\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target}\\n\")\n",
    "print(dados_treino[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}>\\n\")\n",
    "\n",
    "# df_ln[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln[nome_feature] = np.where(dados_treino[nome_feature] == 0, 1, np.log(dados_treino[nome_feature]))\n",
    "df_ln[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores maiores que mediana + 3 vezes o desvio padrão.\n",
    "med = df_sem_outlier[nome_feature].median()\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] >= (df_sem_outlier[nome_feature].median() + 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores MENOR que mediana - 3 vezes o desvio padrão.\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] <= (df_sem_outlier[nome_feature].median() - 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target} SEM OUTLIER\\n\")\n",
    "print(df_sem_outlier[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}> SEM OUTLIER\\n\")\n",
    "\n",
    "# df_ln_sem_outlier[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln_sem_outlier[nome_feature] = np.where(dados_treino[nome_feature] == 0, 1, np.log(dados_treino[nome_feature]))\n",
    "df_ln_sem_outlier[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "\n",
    "print(df_ln_sem_outlier[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# # ARMAZENAMENTO DAS FEATURES CASO SEJAM UTILIZADAS NO MODELO DE REGRESSÃO LINEAR.\n",
    "\n",
    "# # Armazenamento da feature não transformada.\n",
    "# features_numericas[nome_feature] = dados_treino[nome_feature]\n",
    "\n",
    "# # Armezenamento da feature transformada com ln.\n",
    "# features_ln_numericas[nome_feature] = df_ln[nome_feature]\n",
    "\n",
    "# # Armazenamento da feature não transformada.\n",
    "# features_numericas_sem_outlier[nome_feature] = df_sem_outlier[nome_feature]\n",
    "\n",
    "# # Armezenamento da feature transformada com ln.\n",
    "# features_ln_numericas_sem_outlier[nome_feature] = df_ln_sem_outlier[nome_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a6bf1b",
   "metadata": {},
   "source": [
    "## YrSold (Numérica)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "36bb2ef2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores não válidos: 0\n",
      "\n",
      "\n",
      "Correlação entre YrSold e SalePrice\n",
      "\n",
      "             YrSold  SalePrice\n",
      "YrSold     1.000000  -0.009099\n",
      "SalePrice -0.009099   1.000000\n",
      "\n",
      "Correlação entre ln<YrSold> e ln<SalePrice>\n",
      "\n",
      "             YrSold  SalePrice\n",
      "YrSold     1.000000  -0.018459\n",
      "SalePrice -0.018459   1.000000\n",
      "\n",
      "Correlação entre YrSold e SalePrice SEM OUTLIER\n",
      "\n",
      "             YrSold  SalePrice\n",
      "YrSold     1.000000  -0.009099\n",
      "SalePrice -0.009099   1.000000\n",
      "\n",
      "Correlação entre ln<YrSold> e ln<SalePrice> SEM OUTLIER\n",
      "\n",
      "             YrSold  SalePrice\n",
      "YrSold     1.000000  -0.018459\n",
      "SalePrice -0.018459   1.000000\n",
      "\n",
      "Quantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "\n",
      "Quantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n",
      "Quantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nome_feature = 'YrSold'\n",
    "\n",
    "print(f'Número de valores não válidos: {dados_treino[nome_feature].isnull().sum()}\\n')\n",
    "\n",
    "# Substituição de valores não válidos pela mediana da variável em ambos os data frames.\n",
    "dados_treino[nome_feature].fillna(dados_treino[nome_feature].median(), inplace = True)\n",
    "df_sem_outlier[nome_feature].fillna(df_sem_outlier[nome_feature].median(), inplace = True)\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target}\\n\")\n",
    "print(dados_treino[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}>\\n\")\n",
    "\n",
    "# df_ln[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln[nome_feature] = np.where(dados_treino[nome_feature] == 0, 1, np.log(dados_treino[nome_feature]))\n",
    "# df_ln[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "df_ln[nome_target] = np.where(dados_treino[nome_target] == 0, 1, np.log(dados_treino[nome_target]))\n",
    "\n",
    "print(df_ln[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores maiores que mediana + 3 vezes o desvio padrão.\n",
    "med = df_sem_outlier[nome_feature].median()\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] >= (df_sem_outlier[nome_feature].median() + 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "# Eliminando Outlier da variável SEM TRANSFORMAÇÃO.\n",
    "# Verificação de valores MENOR que mediana - 3 vezes o desvio padrão.\n",
    "df_sem_outlier.loc[df_sem_outlier[nome_feature] <= (df_sem_outlier[nome_feature].median() - 3 * df_sem_outlier[nome_feature].std()), nome_feature] = med\n",
    "\n",
    "print(f\"\\nCorrelação entre {nome_feature} e {nome_target} SEM OUTLIER\\n\")\n",
    "print(df_sem_outlier[[nome_feature, nome_target]].corr())\n",
    "\n",
    "print(f\"\\nCorrelação entre ln<{nome_feature}> e ln<{nome_target}> SEM OUTLIER\\n\")\n",
    "\n",
    "# df_ln_sem_outlier[nome_feature] = dados_treino[nome_feature].apply(np.log)   # Aplicação de ln à feature e armazenamento no novo data frame\n",
    "df_ln_sem_outlier[nome_feature] = np.where(dados_treino[nome_feature] == 0, 1, np.log(dados_treino[nome_feature]))\n",
    "df_ln_sem_outlier[nome_target] = dados_treino[nome_target].apply(np.log)     # Aplicação de ln ao target e armazenamento no dataframe auxiliar\n",
    "df_ln_sem_outlier[nome_target] = np.where(dados_treino[nome_target] == 0, 1, np.log(dados_treino[nome_target]))\n",
    "\n",
    "print(df_ln_sem_outlier[[nome_feature, nome_target]].corr())      # Verificação da correlação entre as duas veriáveis quando aplicado ln.\n",
    "\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_ln' após a aplicação da transformação nas variáveis: {df_ln[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores -inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([-np.inf]).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nQuantidade de valores +inf em 'df_sem_outlier' após a aplicação da transformação nas variáveis: {df_sem_outlier[nome_feature].isin([np.inf]).sum().sum()}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# # ARMAZENAMENTO DAS FEATURES CASO SEJAM UTILIZADAS NO MODELO DE REGRESSÃO LINEAR.\n",
    "\n",
    "# # Armazenamento da feature não transformada.\n",
    "# features_numericas[nome_feature] = dados_treino[nome_feature]\n",
    "\n",
    "# # Armezenamento da feature transformada com ln.\n",
    "# features_ln_numericas[nome_feature] = df_ln[nome_feature]\n",
    "\n",
    "# # Armazenamento da feature não transformada.\n",
    "# features_numericas_sem_outlier[nome_feature] = df_sem_outlier[nome_feature]\n",
    "\n",
    "# # Armezenamento da feature transformada com ln.\n",
    "# features_ln_numericas_sem_outlier[nome_feature] = df_ln_sem_outlier[nome_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88e63dc",
   "metadata": {},
   "source": [
    "## SaleType (Categórica)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26ddaf2",
   "metadata": {},
   "source": [
    "## SaleCondition (Categórica)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9113a979",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbcc5fa",
   "metadata": {},
   "source": [
    "# Verificação da correlação entre as variáveis\n",
    "\n",
    "Para melhorar o modelo de regressão linear, serão avaliadas as variáveis que possuem um maior correlação entre si.\n",
    "\n",
    "Caso essa correlação, entre duas features, seja maior que 0.6, as duas variáveis serão analisadas semanticamente e verificada a possível relação entre elas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d1da49",
   "metadata": {},
   "source": [
    "### features_numericas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ab8ba3c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Construção do gráfico de autocorrelação\n",
    "sns.heatmap(features_numericas.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "29b51701",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " YearBuilt <--> GarageYrBlt  ----> 0.7719493056331049\n",
      " BsmtFinSF1 <--> BsmtFullBath  ----> 0.6084733883384751\n",
      " GrLivArea <--> TotRmsAbvGrd  ----> 0.7484074725012069\n",
      " BedroomAbvGr <--> TotRmsAbvGrd  ----> 0.6236044565649782\n"
     ]
    }
   ],
   "source": [
    "# Verificação das variáveis que possuem uma autocorrelação superior a 0.6\n",
    "\n",
    "df_autocorrelacao = features_numericas.corr()    # Armazena o data frame de valores de autocorralação\n",
    "resultado = np.where(df_autocorrelacao >= 0.6)                # Verificar as linhas e colunas dos valores em que é igual ou superior a 0.6\n",
    "linhas, colunas = resultado[0], resultado[1]                  # Como o resultado são dois duas matrizes, uma referente à linha e a outra referente à coluna, salva cada uma em novas variáveis.\n",
    "\n",
    "# Inicia um laço para a impressão dos conjutos em que o coeficiente é superior a 0.6 \n",
    "for linha, coluna in zip(linhas, colunas):                    # Prepara o laço para a quantidade de combinações possíveis  \n",
    "    if df_autocorrelacao.index[linha] == df_autocorrelacao.index[coluna]: # Verifica se os nomes são iguais para não imprimir, pois nesse o coeficiente será 1\n",
    "        pass\n",
    "    else:\n",
    "        if coluna > linha:\n",
    "            # Imprime as features que possuem um coeficiente de autocorrelação superior á 0.6\n",
    "            print(f' {df_autocorrelacao.index[linha]} <--> {df_autocorrelacao.index[coluna]}  ----> {df_autocorrelacao.iloc[linha,coluna]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2b1cbcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOÇÃO DE FEATURES AUTOCORRELATAS\n",
    "features_numericas.drop(columns=['GarageYrBlt', 'TotRmsAbvGrd'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808e2422",
   "metadata": {},
   "source": [
    "### features_ln_numericas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "48a06f63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Construção do gráfico de autocorrelação\n",
    "sns.heatmap(features_ln_numericas.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4ea6e57a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LotFrontage <--> LotArea  ----> 0.6432093861733416\n",
      " YearBuilt <--> GarageYrBlt  ----> 0.7663039071733068\n",
      " GrLivArea <--> FullBath  ----> 0.6360846030093457\n",
      " GrLivArea <--> TotRmsAbvGrd  ----> 0.8244265076005961\n",
      " BedroomAbvGr <--> TotRmsAbvGrd  ----> 0.6530837654631342\n"
     ]
    }
   ],
   "source": [
    "# Verificação das variáveis que possuem uma autocorrelação superior a 0.6\n",
    "\n",
    "df_autocorrelacao = features_ln_numericas.corr()       # Armazena o data frame de valores de autocorralação\n",
    "resultado = np.where(df_autocorrelacao >= 0.6)                # Verificar as linhas e colunas dos valores em que é igual ou superior a 0.6\n",
    "linhas, colunas = resultado[0], resultado[1]                  # Como o resultado são dois duas matrizes, uma referente à linha e a outra referente à coluna, salva cada uma em novas variáveis.\n",
    "\n",
    "# Inicia um laço para a impressão dos conjutos em que o coeficiente é superior a 0.6 \n",
    "for linha, coluna in zip(linhas, colunas):                    # Prepara o laço para a quantidade de combinações possíveis  \n",
    "    if df_autocorrelacao.index[linha] == df_autocorrelacao.index[coluna]: # Verifica se os nomes são iguais para não imprimir, pois nesse o coeficiente será 1\n",
    "        pass\n",
    "    else:\n",
    "        if coluna > linha:\n",
    "            # Imprime as features que possuem um coeficiente de autocorrelação superior á 0.6\n",
    "            print(f' {df_autocorrelacao.index[linha]} <--> {df_autocorrelacao.index[coluna]}  ----> {df_autocorrelacao.iloc[linha,coluna]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "18caec15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOÇÃO DE FEATURES AUTOCORRELATAS\n",
    "features_ln_numericas.drop(columns=['LotFrontage', 'GarageYrBlt', 'TotRmsAbvGrd'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe608ba",
   "metadata": {},
   "source": [
    "### features_numericas_sem_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b0bb2009",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Construção do gráfico de autocorrelação\n",
    "sns.heatmap(features_numericas_sem_outlier.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c2c365d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " YearBuilt <--> GarageYrBlt  ----> 0.7719493056331049\n",
      " BsmtFinSF1 <--> BsmtFullBath  ----> 0.6084733883384751\n",
      " GrLivArea <--> TotRmsAbvGrd  ----> 0.7484074725012069\n",
      " BedroomAbvGr <--> TotRmsAbvGrd  ----> 0.6236044565649782\n"
     ]
    }
   ],
   "source": [
    "# Verificação das variáveis que possuem uma autocorrelação superior a 0.6\n",
    "\n",
    "df_autocorrelacao = features_numericas_sem_outlier.corr()       # Armazena o data frame de valores de autocorralação\n",
    "resultado = np.where(df_autocorrelacao >= 0.6)                # Verificar as linhas e colunas dos valores em que é igual ou superior a 0.6\n",
    "linhas, colunas = resultado[0], resultado[1]                  # Como o resultado são dois duas matrizes, uma referente à linha e a outra referente à coluna, salva cada uma em novas variáveis.\n",
    "\n",
    "# Inicia um laço para a impressão dos conjutos em que o coeficiente é superior a 0.6 \n",
    "for linha, coluna in zip(linhas, colunas):                    # Prepara o laço para a quantidade de combinações possíveis  \n",
    "    if df_autocorrelacao.index[linha] == df_autocorrelacao.index[coluna]: # Verifica se os nomes são iguais para não imprimir, pois nesse o coeficiente será 1\n",
    "        pass\n",
    "    else:\n",
    "        if coluna > linha:\n",
    "            # Imprime as features que possuem um coeficiente de autocorrelação superior á 0.6\n",
    "            print(f' {df_autocorrelacao.index[linha]} <--> {df_autocorrelacao.index[coluna]}  ----> {df_autocorrelacao.iloc[linha,coluna]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f40f9ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOÇÃO DE FEATURES AUTOCORRELATAS\n",
    "features_numericas_sem_outlier.drop(columns=['GarageYrBlt', 'TotRmsAbvGrd'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44650492",
   "metadata": {},
   "source": [
    "### features_ln_numericas_sem_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "94763fcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Construção do gráfico de autocorrelação\n",
    "sns.heatmap(features_ln_numericas_sem_outlier.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2132f3df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LotFrontage <--> LotArea  ----> 0.684477410800538\n",
      " YearBuilt <--> GarageYrBlt  ----> 0.7687321942746068\n",
      " GrLivArea <--> FullBath  ----> 0.6211653200060199\n",
      " GrLivArea <--> TotRmsAbvGrd  ----> 0.7715395728594565\n",
      " BedroomAbvGr <--> TotRmsAbvGrd  ----> 0.6173557578408471\n"
     ]
    }
   ],
   "source": [
    "# Verificação das variáveis que possuem uma autocorrelação superior a 0.6\n",
    "\n",
    "df_autocorrelacao = features_ln_numericas_sem_outlier.corr()       # Armazena o data frame de valores de autocorralação\n",
    "resultado = np.where(df_autocorrelacao >= 0.6)                # Verificar as linhas e colunas dos valores em que é igual ou superior a 0.6\n",
    "linhas, colunas = resultado[0], resultado[1]                  # Como o resultado são dois duas matrizes, uma referente à linha e a outra referente à coluna, salva cada uma em novas variáveis.\n",
    "\n",
    "# Inicia um laço para a impressão dos conjutos em que o coeficiente é superior a 0.6 \n",
    "for linha, coluna in zip(linhas, colunas):                    # Prepara o laço para a quantidade de combinações possíveis  \n",
    "    if df_autocorrelacao.index[linha] == df_autocorrelacao.index[coluna]: # Verifica se os nomes são iguais para não imprimir, pois nesse o coeficiente será 1\n",
    "        pass\n",
    "    else:\n",
    "        if coluna > linha:\n",
    "            # Imprime as features que possuem um coeficiente de autocorrelação superior á 0.6\n",
    "            print(f' {df_autocorrelacao.index[linha]} <--> {df_autocorrelacao.index[coluna]}  ----> {df_autocorrelacao.iloc[linha,coluna]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "33128e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOÇÃO DE FEATURES AUTOCORRELATAS\n",
    "features_ln_numericas_sem_outlier.drop(columns=['LotFrontage', 'GarageYrBlt', 'TotRmsAbvGrd'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca78e72d",
   "metadata": {},
   "source": [
    "# Normalização das Features e Target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a69120",
   "metadata": {},
   "source": [
    "### features_numericas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "af801177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalização de máximo e mínino. Xnormalizado = (X - Xmin) / (Xmax -Xmin)\n",
    "features_numericas_parametro_normalizacao = MinMaxScaler(feature_range = (0,1))\n",
    "\n",
    "# Criando um df normalizado com os dados das features e target juntos\n",
    "features_numericas_normalizadas = pd.DataFrame(features_numericas_parametro_normalizacao.fit_transform(features_numericas), columns=features_numericas.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e247df2",
   "metadata": {},
   "source": [
    "### features_ln_numericas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b83d0c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalização de máximo e mínino. Xnormalizado = (X - Xmin) / (Xmax -Xmin)\n",
    "features_ln_numericas_parametro_normalizacao = MinMaxScaler(feature_range = (0,1))\n",
    "\n",
    "# Criando um df normalizado com os dados das features e target juntos\n",
    "features_ln_numericas_normalizadas = pd.DataFrame(features_ln_numericas_parametro_normalizacao.fit_transform(features_ln_numericas), columns=features_ln_numericas.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0cc5ac",
   "metadata": {},
   "source": [
    "### features_numericas_sem_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d0f76cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalização de máximo e mínino. Xnormalizado = (X - Xmin) / (Xmax -Xmin)\n",
    "features_numericas_sem_outlier_parametro_normalizacao = MinMaxScaler(feature_range = (0,1))\n",
    "\n",
    "# Criando um df normalizado com os dados das features e target juntos\n",
    "features_numericas_sem_outlier_normalizadas = pd.DataFrame(features_numericas_sem_outlier_parametro_normalizacao.fit_transform(features_numericas_sem_outlier), columns=features_numericas_sem_outlier.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548262fc",
   "metadata": {},
   "source": [
    "### features_ln_numericas_sem_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "317ec424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalização de máximo e mínino. Xnormalizado = (X - Xmin) / (Xmax -Xmin)\n",
    "features_ln_numericas_sem_outlier_parametro_normalizacao = MinMaxScaler(feature_range = (0,1))\n",
    "\n",
    "# Criando um df normalizado com os dados das features e target juntos\n",
    "features_ln_numericas_sem_outlier_normalizadas = pd.DataFrame(features_ln_numericas_sem_outlier_parametro_normalizacao.fit_transform(features_ln_numericas_sem_outlier), columns=features_ln_numericas_sem_outlier.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97875fb0",
   "metadata": {},
   "source": [
    "### Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dbc6a369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZAÇÃO DA VARIÁVEL DEPENDENTE (TARGET)\n",
    "target_parametro_normalizacao = MinMaxScaler(feature_range = (0,1))\n",
    "\n",
    "# CRIAÇÃO DE UM DF NORMALIZADO DA VARIÁVEL TARGET\n",
    "y_treinamento_normalizada = pd.DataFrame(target_parametro_normalizacao.fit_transform(y_treinamento.values.reshape(-1, 1)), columns= [nome_target])\n",
    "\n",
    "\n",
    "\n",
    "# NORMALIZAÇÃO DA VARIÁVEL DEPENDENTE (TARGET)\n",
    "target_ln_parametro_normalizacao = MinMaxScaler(feature_range = (0,1))\n",
    "\n",
    "# CRIAÇÃO DE UM DF NORMALIZADO DA VARIÁVEL TARGET\n",
    "y_treinamento_ln_normalizada = pd.DataFrame(target_ln_parametro_normalizacao.fit_transform(df_ln[nome_target].values.reshape(-1, 1)), columns= [nome_target])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c46ac3",
   "metadata": {},
   "source": [
    "# TREINAMENTO DOS MODELOS\n",
    "\n",
    "Serão montados três modelos de regressão linear e ao final escolheremos aquele de melhor resultado. \n",
    "\n",
    "Para isso iremos calcular o **Coeficiênte de Determinação Múltipla**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce32730",
   "metadata": {},
   "source": [
    "## Treinamento do modelo com features_numericas\n",
    "\n",
    "Será criado um modelo de Regressão Linear para as variáveis numéricas previamente separadas no data frame **\"features_numericas\"**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "91807d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TREINAMENTO PARA FEATURES TOTAIS, NUMÉRICAS + CATEGÓRICAS\n",
    "features_numericas_modelo = LinearRegression()\n",
    "features_numericas_modelo.fit(features_numericas_normalizadas,y_treinamento_normalizada)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dc178a",
   "metadata": {},
   "source": [
    "## Treinamento do modelo com features_ln_numericas\n",
    "\n",
    "Será criado um modelo de Regressão Linear para as variáveis numéricas que foram aplicadas a transformação ln. **\"features_ln_numericas\"**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2d4c8feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TREINAMENTO PARA FEATURES TRANSFORMADAS.\n",
    "features_ln_numericas_modelo = LinearRegression()\n",
    "features_ln_numericas_modelo.fit(features_ln_numericas_normalizadas,y_treinamento_ln_normalizada)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4574093",
   "metadata": {},
   "source": [
    "## Treinamento do modelo com features_numericas_sem_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ee5f720f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TREINAMENTO PARA FEATURES CATEGÓRICAS.\n",
    "features_numericas_sem_outlier_modelo = LinearRegression()\n",
    "features_numericas_sem_outlier_modelo.fit(features_numericas_sem_outlier_normalizadas,y_treinamento_normalizada)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ca3c0f",
   "metadata": {},
   "source": [
    "## Treinamento do modelo com features_ln_numericas_sem_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "23f065fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TREINAMENTO PARA FEATURES CATEGÓRICAS.\n",
    "features_ln_numericas_sem_outlier_modelo = LinearRegression()\n",
    "features_ln_numericas_sem_outlier_modelo.fit(features_ln_numericas_sem_outlier_normalizadas,y_treinamento_ln_normalizada)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60499828",
   "metadata": {},
   "source": [
    "# TRATAMENTO DOS DADOS DE VALIDAÇÃO\n",
    "\n",
    "Para que sejam utilizados os dados que foram separados como validação é necessário normaliza-los com as mesmas regras de normalizção que foram utilizadas nos dados de treinamento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f398f07",
   "metadata": {},
   "source": [
    "## Tratamento das variáveis de validação para o modelo de features_numericas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a028a09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação de um Data frame apenas para eliminação de linhas com valores não válidos.\n",
    "dados_validacao = pd.concat([X_validacao,y_validacao], axis = 1)\n",
    "\n",
    "# Separação das features que serão utilizadas no modelo.\n",
    "X_validacao_features_numericas = dados_validacao[features_numericas_normalizadas.columns].copy()\n",
    "X_validacao_features_numericas[nome_target] = dados_validacao[nome_target]\n",
    "\n",
    "# Eliminação de linhas que contenham valores não  valores não válidos\n",
    "X_validacao_features_numericas = X_validacao_features_numericas.dropna()\n",
    "\n",
    "# Separação das variáveis independentes e dependentes\n",
    "Y_validacao_features_numericas = X_validacao_features_numericas[nome_target]\n",
    "X_validacao_features_numericas = X_validacao_features_numericas.drop(columns=[nome_target])\n",
    "\n",
    "# Criando um df com os dados normalizado para as variáveis numéricas\n",
    "X_validacao_features_numericas_normalizado = pd.DataFrame(features_numericas_parametro_normalizacao.transform(X_validacao_features_numericas), columns=X_validacao_features_numericas.columns)\n",
    "\n",
    "# Criando um df com os dados normalizado para as variáveis numéricas\n",
    "Y_validacao_features_numericas_normalizado = pd.DataFrame(target_parametro_normalizacao.transform(Y_validacao_features_numericas.values.reshape(-1, 1)), columns=[nome_target])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beaf4149",
   "metadata": {},
   "source": [
    "## Tratamento das variáveis de validação para o modelo de features_ln_numericas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "72120dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação de um Data frame apenas para eliminação de linhas com valores não válidos.\n",
    "dados_validacao = pd.concat([X_validacao,y_validacao], axis = 1)\n",
    "\n",
    "# Separação das features que serão utilizadas no modelo.\n",
    "X_validacao_features_ln_numericas = dados_validacao[features_ln_numericas_normalizadas.columns].copy()\n",
    "X_validacao_features_ln_numericas[nome_target] = dados_validacao[nome_target]\n",
    "\n",
    "# Eliminação de linhas que contenham valores não  valores não válidos\n",
    "X_validacao_features_ln_numericas = X_validacao_features_ln_numericas.dropna()\n",
    "\n",
    "# Verificação se há valor iguais a 0 no data frame, caso exista, substitua por 1 para a aplicação do log.\n",
    "X_validacao_features_ln_numericas[X_validacao_features_ln_numericas == 0] = 1\n",
    "\n",
    "# Aplicacação do logarítmo neperiano à todas as features\n",
    "X_validacao_features_ln_numericas = X_validacao_features_ln_numericas.apply(np.log)\n",
    "# X_validacao_features_ln_numericas = np.where(X_validacao_features_ln_numericas == 0, 1, X_validacao_features_ln_numericas.apply(np.log))\n",
    "\n",
    "# Separação das variáveis independentes e dependentes\n",
    "Y_validacao_features_ln_numericas = X_validacao_features_ln_numericas[nome_target]\n",
    "X_validacao_features_ln_numericas = X_validacao_features_ln_numericas.drop(columns=[nome_target])\n",
    "\n",
    "# Criando um df com os dados normalizado para as variáveis numéricas\n",
    "X_validacao_features_ln_numericas_normalizado = pd.DataFrame(features_ln_numericas_parametro_normalizacao.transform(X_validacao_features_ln_numericas), columns=X_validacao_features_ln_numericas.columns)\n",
    "\n",
    "# Criando um df com os dados normalizado para as variáveis numéricas\n",
    "Y_validacao_features_ln_numericas_normalizado = pd.DataFrame(target_ln_parametro_normalizacao.transform(Y_validacao_features_ln_numericas.values.reshape(-1, 1)), columns=[nome_target])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711ded2b",
   "metadata": {},
   "source": [
    "## Tratamento das Features de validação para o modelo de features_numericas_sem_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ca74496e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação de um Data frame apenas para eliminação de linhas com valores não válidos.\n",
    "dados_validacao = pd.concat([X_validacao,y_validacao], axis = 1)\n",
    "\n",
    "# Separação das features que serão utilizadas no modelo.\n",
    "X_validacao_features_numericas_sem_outlier = dados_validacao[features_numericas_sem_outlier_normalizadas.columns].copy()\n",
    "X_validacao_features_numericas_sem_outlier[nome_target] = dados_validacao[nome_target]\n",
    "\n",
    "# Eliminação de linhas que contenham valores não  valores não válidos\n",
    "X_validacao_features_numericas_sem_outlier = X_validacao_features_numericas_sem_outlier.dropna()\n",
    "\n",
    "# Separação das variáveis independentes e dependentes\n",
    "Y_validacao_features_numericas_sem_outlier = X_validacao_features_numericas_sem_outlier[nome_target]\n",
    "X_validacao_features_numericas_sem_outlier = X_validacao_features_numericas_sem_outlier.drop(columns=[nome_target])\n",
    "\n",
    "# Criando um df com os dados normalizado para as variáveis numéricas\n",
    "X_validacao_features_numericas_sem_outlier_normalizado = pd.DataFrame(features_numericas_sem_outlier_parametro_normalizacao.transform(X_validacao_features_numericas_sem_outlier), columns=X_validacao_features_numericas_sem_outlier.columns)\n",
    "\n",
    "# Criando um df com os dados normalizado para as variáveis numéricas\n",
    "Y_validacao_features_numericas_sem_outlier_normalizado = pd.DataFrame(target_parametro_normalizacao.transform(Y_validacao_features_numericas_sem_outlier.values.reshape(-1, 1)), columns=[nome_target])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db21edb",
   "metadata": {},
   "source": [
    "## Tratamento das Features de validação para o modelo de features_ln_numericas_sem_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c02a31b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação de um Data frame apenas para eliminação de linhas com valores não válidos.\n",
    "dados_validacao = pd.concat([X_validacao,y_validacao], axis = 1)\n",
    "\n",
    "# Separação das features que serão utilizadas no modelo.\n",
    "X_validacao_features_ln_numericas_sem_outlier = dados_validacao[features_ln_numericas_sem_outlier_normalizadas.columns].copy()\n",
    "X_validacao_features_ln_numericas_sem_outlier[nome_target] = dados_validacao[nome_target]\n",
    "\n",
    "# Eliminação de linhas que contenham valores não  valores não válidos\n",
    "X_validacao_features_ln_numericas_sem_outlier = X_validacao_features_ln_numericas_sem_outlier.dropna()\n",
    "\n",
    "# Verificação de valores iguais a 0 no data frame e substituição por 1, caso exista.\n",
    "X_validacao_features_ln_numericas_sem_outlier[X_validacao_features_ln_numericas_sem_outlier == 0] = 1\n",
    "\n",
    "# Aplicacação do logarítmo neperiano à todas as features\n",
    "X_validacao_features_ln_numericas_sem_outlier = X_validacao_features_ln_numericas_sem_outlier.apply(np.log)\n",
    "\n",
    "# Separação das variáveis independentes e dependentes\n",
    "Y_validacao_features_ln_numericas_sem_outlier = X_validacao_features_ln_numericas_sem_outlier[nome_target]\n",
    "X_validacao_features_ln_numericas_sem_outlier = X_validacao_features_ln_numericas_sem_outlier.drop(columns=[nome_target])\n",
    "\n",
    "# Criando um df com os dados normalizado para as variáveis numéricas\n",
    "X_validacao_features_ln_numericas_sem_outlier_normalizado = pd.DataFrame(features_ln_numericas_sem_outlier_parametro_normalizacao.transform(X_validacao_features_ln_numericas_sem_outlier), columns=X_validacao_features_ln_numericas_sem_outlier.columns)\n",
    "\n",
    "# Criando um df com os dados normalizado para as variáveis numéricas\n",
    "Y_validacao_features_ln_numericas_sem_outlier_normalizado = pd.DataFrame(target_ln_parametro_normalizacao.transform(Y_validacao_features_ln_numericas_sem_outlier.values.reshape(-1, 1)), columns=[nome_target])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5357c2a3",
   "metadata": {},
   "source": [
    "# VALIDAÇÃO DOS MODELOS "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65164879",
   "metadata": {},
   "source": [
    "# Validação do moledo com features_numericas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3c9cba16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7856327671343192\n"
     ]
    }
   ],
   "source": [
    "# Coeficiente de determinação para as variáveis de treinamento\n",
    "score_df.at['Regressão Linear Teste','Numéricas'] = features_numericas_modelo.score(features_numericas_normalizadas,y_treinamento_normalizada)\n",
    "print(score_df.at['Regressão Linear Teste','Numéricas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ec6e7f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8241026680098618\n"
     ]
    }
   ],
   "source": [
    "# Coediciente de determinação para as variáveis de validação\n",
    "score_df.at['Regressão Linear Validação','Numéricas'] = features_numericas_modelo.score(X_validacao_features_numericas_normalizado,Y_validacao_features_numericas_normalizado)\n",
    "print(score_df.at['Regressão Linear Validação','Numéricas'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c24732",
   "metadata": {},
   "source": [
    "# Validação do moledo com features_ln_numericas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7d34fc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8435919649030754\n"
     ]
    }
   ],
   "source": [
    "# Coediciente de determinação para as variáveis de treinamento\n",
    "score_df.at['Regressão Linear Teste','Tranformada ln'] = features_ln_numericas_modelo.score(features_ln_numericas_normalizadas,y_treinamento_ln_normalizada)\n",
    "print(score_df.at['Regressão Linear Teste','Tranformada ln'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b153db34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8339184624816238\n"
     ]
    }
   ],
   "source": [
    "# Coediciente de determinação para as variáveis de validação\n",
    "score_df.at['Regressão Linear Validação','Tranformada ln'] = features_ln_numericas_modelo.score(X_validacao_features_ln_numericas_normalizado,Y_validacao_features_ln_numericas_normalizado)\n",
    "print(score_df.at['Regressão Linear Validação','Tranformada ln'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10277c7",
   "metadata": {},
   "source": [
    "# Validação do moledo com features_numericas_sem_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bc0f1b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7856327671343192\n"
     ]
    }
   ],
   "source": [
    "# Coediciente de determinação para as variáveis de validação\n",
    "score_df.at['Regressão Linear Teste','Numéricas sem Outlier'] = features_numericas_sem_outlier_modelo.score(features_numericas_sem_outlier_normalizadas,y_treinamento_normalizada)\n",
    "print(score_df.at['Regressão Linear Teste','Numéricas sem Outlier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ba90b0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8241026680098618\n"
     ]
    }
   ],
   "source": [
    "# Coediciente de determinação para as variáveis de validação\n",
    "score_df.at['Regressão Linear Validação','Numéricas sem Outlier'] = features_numericas_sem_outlier_modelo.score(X_validacao_features_numericas_sem_outlier_normalizado,Y_validacao_features_numericas_sem_outlier_normalizado)\n",
    "print(score_df.at['Regressão Linear Validação','Numéricas sem Outlier'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314c7b72",
   "metadata": {},
   "source": [
    "# Validação do moledo com features_ln_numericas_sem_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fbbf2b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8339075771940453\n"
     ]
    }
   ],
   "source": [
    "# Coediciente de determinação para as variáveis de treinamento\n",
    "score_df.at['Regressão Linear Teste','Transformada ln sem Outlier'] = features_ln_numericas_sem_outlier_modelo.score(features_ln_numericas_sem_outlier_normalizadas,y_treinamento_ln_normalizada)\n",
    "print(score_df.at['Regressão Linear Teste','Transformada ln sem Outlier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9741c715",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8388822676944472\n"
     ]
    }
   ],
   "source": [
    "# Coediciente de determinação para as variáveis de validação\n",
    "score_df.at['Regressão Linear Validação','Transformada ln sem Outlier'] = features_ln_numericas_sem_outlier_modelo.score(X_validacao_features_ln_numericas_sem_outlier_normalizado,Y_validacao_features_ln_numericas_sem_outlier_normalizado)\n",
    "print(score_df.at['Regressão Linear Validação','Transformada ln sem Outlier'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c898d1ff",
   "metadata": {},
   "source": [
    "# TREINAMENTO PARA O MODELO REGULARIZADO L1 (LASSO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f20595",
   "metadata": {},
   "source": [
    "## Treinamento do modelo com features_numericas\n",
    "\n",
    "Será criado um modelo de Regressão Linear regularizado L1 (Lasso) para as variáveis numéricas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e99356",
   "metadata": {},
   "source": [
    "Ante de iniciar o treinamento devemos verificar o melhor valor para o parâmetro alpha que controla a força da regularização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ed17eb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor valor de alpha: 0.0001\n"
     ]
    }
   ],
   "source": [
    "# Importa o método que faz pesquisa exaustiva sobre valores de parâmetros especificados para um estimador.\n",
    "from sklearn.model_selection import GridSearchCV  \n",
    "\n",
    "# Carrega um método de regularização.\n",
    "lasso = Lasso()\n",
    "# Constroi um dicionário para utilização como possíveis valores do parâmetro.\n",
    "parametro = {'alpha': [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "\n",
    "# Carrega o método de verificação do melhor parâmetro\n",
    "lasso_cv = GridSearchCV(lasso, parametro, cv=5)\n",
    "# Utiliza as variáveis reais para avaliar os melhores valores de alpha.\n",
    "lasso_cv.fit(features_numericas_normalizadas, y_treinamento_normalizada)\n",
    "\n",
    "# Salva o melhor valor de alpha dentre os disponíveis no dicionário.\n",
    "best_alpha = lasso_cv.best_params_['alpha']\n",
    "print(f'Melhor valor de alpha: {best_alpha}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "921415b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Lasso(alpha=0.0001)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso(alpha=0.0001)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Lasso(alpha=0.0001)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TREINAMENTO PARA FEATURES NUMÉRICAS\n",
    "features_numericas_modelo_l1 = Lasso(alpha=0.0001)\n",
    "features_numericas_modelo_l1.fit(features_numericas_normalizadas,y_treinamento_normalizada)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead9d8d6",
   "metadata": {},
   "source": [
    "## Treinamento do modelo com features_ln_numericas\n",
    "\n",
    "Será criado um modelo de Regressão Linear para as variáveis numéricas que foram aplicadas a transformação ln. **\"features_ln_numericas\"**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "098df7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor valor de alpha: 1e-05\n"
     ]
    }
   ],
   "source": [
    "# Carrega um método de regularização.\n",
    "lasso = Lasso()\n",
    "# Constroi um dicionário para utilização como possíveis valores do parâmetro.\n",
    "parametro = {'alpha': [0.0000001, 0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "\n",
    "# Carrega o método de verificação do melhor parâmetro\n",
    "lasso_cv = GridSearchCV(lasso, parametro, cv=5)\n",
    "# Utiliza as variáveis reais para avaliar os melhores valores de alpha.\n",
    "lasso_cv.fit(features_ln_numericas_normalizadas, y_treinamento_ln_normalizada)\n",
    "\n",
    "# Salva o melhor valor de alpha dentre os disponíveis no dicionário.\n",
    "best_alpha = lasso_cv.best_params_['alpha']\n",
    "print(f'Melhor valor de alpha: {best_alpha}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d04b7100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Lasso(alpha=1e-05)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso(alpha=1e-05)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Lasso(alpha=1e-05)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TREINAMENTO PARA FEATURES TRANSFORMADAS.\n",
    "features_ln_numericas_modelo_l1 = Lasso(alpha=0.00001)\n",
    "features_ln_numericas_modelo_l1.fit(features_ln_numericas_normalizadas,y_treinamento_ln_normalizada)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7ac1c1",
   "metadata": {},
   "source": [
    "## Treinamento do modelo com features_numericas_sem_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "73db4960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor valor de alpha: 0.0001\n"
     ]
    }
   ],
   "source": [
    "# Carrega um método de regularização.\n",
    "lasso = Lasso()\n",
    "# Constroi um dicionário para utilização como possíveis valores do parâmetro.\n",
    "parametro = {'alpha': [0.0000001, 0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "\n",
    "# Carrega o método de verificação do melhor parâmetro\n",
    "lasso_cv = GridSearchCV(lasso, parametro, cv=5)\n",
    "# Utiliza as variáveis reais para avaliar os melhores valores de alpha.\n",
    "lasso_cv.fit(features_numericas_sem_outlier_normalizadas, y_treinamento_normalizada)\n",
    "\n",
    "# Salva o melhor valor de alpha dentre os disponíveis no dicionário.\n",
    "best_alpha = lasso_cv.best_params_['alpha']\n",
    "print(f'Melhor valor de alpha: {best_alpha}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "68ec6b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Lasso(alpha=0.0001)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso(alpha=0.0001)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Lasso(alpha=0.0001)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TREINAMENTO PARA FEATURES CATEGÓRICAS.\n",
    "features_numericas_sem_outlier_modelo_l1 = Lasso(alpha=0.0001)\n",
    "features_numericas_sem_outlier_modelo_l1.fit(features_numericas_sem_outlier_normalizadas,y_treinamento_normalizada)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6461957",
   "metadata": {},
   "source": [
    "## Treinamento do modelo com features_ln_numericas_sem_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3925e02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor valor de alpha: 1e-05\n"
     ]
    }
   ],
   "source": [
    "# Carrega um método de regularização.\n",
    "lasso = Lasso()\n",
    "# Constroi um dicionário para utilização como possíveis valores do parâmetro.\n",
    "parametro = {'alpha': [0.0000001, 0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "\n",
    "# Carrega o método de verificação do melhor parâmetro\n",
    "lasso_cv = GridSearchCV(lasso, parametro, cv=5)\n",
    "# Utiliza as variáveis reais para avaliar os melhores valores de alpha.\n",
    "lasso_cv.fit(features_ln_numericas_sem_outlier_normalizadas, y_treinamento_ln_normalizada)\n",
    "\n",
    "# Salva o melhor valor de alpha dentre os disponíveis no dicionário.\n",
    "best_alpha = lasso_cv.best_params_['alpha']\n",
    "print(f'Melhor valor de alpha: {best_alpha}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0de3aac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Lasso(alpha=0.0001)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso(alpha=0.0001)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Lasso(alpha=0.0001)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TREINAMENTO PARA FEATURES CATEGÓRICAS.\n",
    "features_ln_numericas_sem_outlier_modelo_l1 = Lasso(alpha=0.0001)\n",
    "features_ln_numericas_sem_outlier_modelo_l1.fit(features_ln_numericas_sem_outlier_normalizadas,y_treinamento_ln_normalizada)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35488523",
   "metadata": {},
   "source": [
    "# VALIDAÇÃO DO MODELO REGULARIZADO L1 (Lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dce468",
   "metadata": {},
   "source": [
    "# Validação do moledo com features_numericas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "10a8c46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coeficiente de determinação para as variáveis de treinamento\n",
    "score_df.at['Regressão Linear L1 Teste','Numéricas'] = features_numericas_modelo_l1.score(features_numericas_normalizadas,y_treinamento_normalizada)\n",
    "# print(score_df.at['Regressão Linear L1 Teste','Numéricas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e843b286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coediciente de determinação para as variáveis de validação\n",
    "score_df.at['Regressão Linear L1 Validação','Numéricas'] = features_numericas_modelo_l1.score(X_validacao_features_numericas_normalizado,Y_validacao_features_numericas_normalizado)\n",
    "# print(score_df.at['Regressão Linear L1 Validação','Numéricas'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c48ba5",
   "metadata": {},
   "source": [
    "### Verificação das features igualadas a zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d1d5e161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features com coeficientes zero: Index(['BedroomAbvGr'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Coeficientes das features\n",
    "coeficientes = features_numericas_modelo_l1.coef_\n",
    "\n",
    "# Identificando as features com coeficientes iguais a zero\n",
    "features_zero_coef = features_numericas_normalizadas.columns[coeficientes == 0]\n",
    "print(\"Features com coeficientes zero:\", features_zero_coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65c5fbf",
   "metadata": {},
   "source": [
    "# Validação do moledo com features_ln_numericas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "aafab6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coediciente de determinação para as variáveis de treinamento\n",
    "score_df.at['Regressão Linear L1 Teste','Tranformada ln'] = features_ln_numericas_modelo_l1.score(features_ln_numericas_normalizadas,y_treinamento_ln_normalizada)\n",
    "# print(score_df.at['Regressão Linear L1 Teste','Tranformada ln'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c76bcd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coediciente de determinação para as variáveis de validação\n",
    "score_df.at['Regressão Linear L1 Validação','Tranformada ln'] = features_ln_numericas_modelo_l1.score(X_validacao_features_ln_numericas_normalizado,Y_validacao_features_ln_numericas_normalizado)\n",
    "# print(score_df.at['Regressão Linear L1 Validação','Tranformada ln'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ccbbb9",
   "metadata": {},
   "source": [
    "# Validação do moledo com features_numericas_sem_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1ecca8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coediciente de determinação para as variáveis de validação\n",
    "score_df.at['Regressão Linear L1 Teste','Numéricas sem Outlier'] = features_numericas_sem_outlier_modelo_l1.score(features_numericas_sem_outlier_normalizadas,y_treinamento_normalizada)\n",
    "# print(score_df.at['Regressão Linear L1 Teste','Numéricas sem Outlier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d1f0c4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coediciente de determinação para as variáveis de validação\n",
    "score_df.at['Regressão Linear L1 Validação','Numéricas sem Outlier'] = features_numericas_sem_outlier_modelo_l1.score(X_validacao_features_numericas_sem_outlier_normalizado,Y_validacao_features_numericas_sem_outlier_normalizado)\n",
    "# print(score_df.at['Regressão Linear L1 Validação','Numéricas sem Outlier'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9cddde",
   "metadata": {},
   "source": [
    "# Validação do moledo com features_ln_numericas_sem_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b8a42ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coediciente de determinação para as variáveis de treinamento\n",
    "score_df.at['Regressão Linear L1 Teste','Transformada ln sem Outlier'] = features_ln_numericas_sem_outlier_modelo_l1.score(features_ln_numericas_sem_outlier_normalizadas,y_treinamento_ln_normalizada)\n",
    "# print(score_df.at['Regressão Linear L1 Teste','Transformada ln sem Outlier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "59ec69de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Coediciente de determinação para as variáveis de validação\n",
    "score_df.at['Regressão Linear L1 Validação','Transformada ln sem Outlier'] = features_ln_numericas_sem_outlier_modelo_l1.score(X_validacao_features_ln_numericas_sem_outlier_normalizado,Y_validacao_features_ln_numericas_sem_outlier_normalizado)\n",
    "# print(score_df.at['Regressão Linear L1 Validação','Transformada ln sem Outlier'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab645d7",
   "metadata": {},
   "source": [
    "# TREINAMENTO PARA O MODELO REGULARIZADO L2 (RIDGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56bd366",
   "metadata": {},
   "source": [
    "## Treinamento do modelo com features_numericas\n",
    "\n",
    "Será criado um modelo de Regressão Linear regularizado L1 (Lasso) para as variáveis numéricas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9e3138",
   "metadata": {},
   "source": [
    "Ante de iniciar o treinamento devemos verificar o melhor valor para o parâmetro alpha que controla a força da regularização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c59badb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor valor de alpha: 1\n"
     ]
    }
   ],
   "source": [
    "# Importa o método que faz pesquisa exaustiva sobre valores de parâmetros especificados para um estimador.\n",
    "from sklearn.model_selection import GridSearchCV  \n",
    "\n",
    "# Carrega um método de regularização.\n",
    "ridge = Ridge()\n",
    "# Constroi um dicionário para utilização como possíveis valores do parâmetro.\n",
    "parametro = {'alpha': [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "\n",
    "# Carrega o método de verificação do melhor parâmetro\n",
    "ridge_cv = GridSearchCV(ridge, parametro, cv=5)\n",
    "# Utiliza as variáveis reais para avaliar os melhores valores de alpha.\n",
    "ridge_cv.fit(features_numericas_normalizadas, y_treinamento_normalizada)\n",
    "\n",
    "# Salva o melhor valor de alpha dentre os disponíveis no dicionário.\n",
    "best_alpha = ridge_cv.best_params_['alpha']\n",
    "print(f'Melhor valor de alpha: {best_alpha}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "654832b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge(alpha=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge(alpha=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Ridge(alpha=1)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TREINAMENTO PARA FEATURES NUMÉRICAS\n",
    "features_numericas_modelo_l2 = Ridge(alpha=1)\n",
    "features_numericas_modelo_l2.fit(features_numericas_normalizadas,y_treinamento_normalizada)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccd213e",
   "metadata": {},
   "source": [
    "## Treinamento do modelo com features_ln_numericas\n",
    "\n",
    "Será criado um modelo de Regressão Linear para as variáveis numéricas que foram aplicadas a transformação ln. **\"features_ln_numericas\"**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "cb37bae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor valor de alpha: 0.1\n"
     ]
    }
   ],
   "source": [
    "# Carrega um método de regularização.\n",
    "ridge = Ridge()\n",
    "# Constroi um dicionário para utilização como possíveis valores do parâmetro.\n",
    "parametro = {'alpha': [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "\n",
    "# Carrega o método de verificação do melhor parâmetro\n",
    "ridge_cv = GridSearchCV(ridge, parametro, cv=5)\n",
    "# Utiliza as variáveis reais para avaliar os melhores valores de alpha.\n",
    "ridge_cv.fit(features_ln_numericas_normalizadas, y_treinamento_ln_normalizada)\n",
    "\n",
    "# Salva o melhor valor de alpha dentre os disponíveis no dicionário.\n",
    "best_alpha = ridge_cv.best_params_['alpha']\n",
    "print(f'Melhor valor de alpha: {best_alpha}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a34b81be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge(alpha=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge(alpha=0.1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Ridge(alpha=0.1)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TREINAMENTO PARA FEATURES TRANSFORMADAS.\n",
    "features_ln_numericas_modelo_l2 = Ridge(alpha=0.1)\n",
    "features_ln_numericas_modelo_l2.fit(features_ln_numericas_normalizadas,y_treinamento_ln_normalizada)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55425c2b",
   "metadata": {},
   "source": [
    "## Treinamento do modelo com features_numericas_sem_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c96943aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor valor de alpha: 1\n"
     ]
    }
   ],
   "source": [
    "# Carrega um método de regularização.\n",
    "ridge = Ridge()\n",
    "# Constroi um dicionário para utilização como possíveis valores do parâmetro.\n",
    "parametro = {'alpha': [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "\n",
    "# Carrega o método de verificação do melhor parâmetro\n",
    "ridge_cv = GridSearchCV(ridge, parametro, cv=5)\n",
    "# Utiliza as variáveis reais para avaliar os melhores valores de alpha.\n",
    "ridge_cv.fit(features_numericas_sem_outlier_normalizadas, y_treinamento_normalizada)\n",
    "\n",
    "# Salva o melhor valor de alpha dentre os disponíveis no dicionário.\n",
    "best_alpha = ridge_cv.best_params_['alpha']\n",
    "print(f'Melhor valor de alpha: {best_alpha}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "82c11f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge(alpha=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge(alpha=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Ridge(alpha=1)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TREINAMENTO PARA FEATURES CATEGÓRICAS.\n",
    "features_numericas_sem_outlier_modelo_l2 = Ridge(alpha=1)\n",
    "features_numericas_sem_outlier_modelo_l2.fit(features_numericas_sem_outlier_normalizadas,y_treinamento_normalizada)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35588c67",
   "metadata": {},
   "source": [
    "## Treinamento do modelo com features_ln_numericas_sem_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f41968af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor valor de alpha: 0.1\n"
     ]
    }
   ],
   "source": [
    "# Carrega um método de regularização.\n",
    "ridge = Ridge()\n",
    "# Constroi um dicionário para utilização como possíveis valores do parâmetro.\n",
    "parametro = {'alpha': [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "\n",
    "# Carrega o método de verificação do melhor parâmetro\n",
    "ridge_cv = GridSearchCV(ridge, parametro, cv=5)\n",
    "# Utiliza as variáveis reais para avaliar os melhores valores de alpha.\n",
    "ridge_cv.fit(features_ln_numericas_sem_outlier_normalizadas, y_treinamento_ln_normalizada)\n",
    "\n",
    "# Salva o melhor valor de alpha dentre os disponíveis no dicionário.\n",
    "best_alpha = ridge_cv.best_params_['alpha']\n",
    "print(f'Melhor valor de alpha: {best_alpha}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3ee143d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge(alpha=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge(alpha=0.1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Ridge(alpha=0.1)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TREINAMENTO PARA FEATURES CATEGÓRICAS.\n",
    "features_ln_numericas_sem_outlier_modelo_l2 = Ridge(alpha=0.1)\n",
    "features_ln_numericas_sem_outlier_modelo_l2.fit(features_ln_numericas_sem_outlier_normalizadas,y_treinamento_ln_normalizada)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d7c26c",
   "metadata": {},
   "source": [
    "# VALIDAÇÃO DO MODELO REGULARIZADO L2 (RIDGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfb7a4c",
   "metadata": {},
   "source": [
    "# Validação do moledo com features_numericas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b4280dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coeficiente de determinação para as variáveis de treinamento\n",
    "score_df.at['Regressão Linear L2 Teste','Numéricas'] = features_numericas_modelo_l2.score(features_numericas_normalizadas,y_treinamento_normalizada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a3a2c457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coediciente de determinação para as variáveis de validação\n",
    "score_df.at['Regressão Linear L2 Validação','Numéricas'] = features_numericas_modelo_l2.score(X_validacao_features_numericas_normalizado,Y_validacao_features_numericas_normalizado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92fe95f",
   "metadata": {},
   "source": [
    "# Validação do moledo com features_ln_numericas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "136ccb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coediciente de determinação para as variáveis de treinamento\n",
    "score_df.at['Regressão Linear L2 Teste','Tranformada ln'] = features_ln_numericas_modelo_l2.score(features_ln_numericas_normalizadas,y_treinamento_ln_normalizada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "fbd548bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coediciente de determinação para as variáveis de validação\n",
    "score_df.at['Regressão Linear L2 Validação','Tranformada ln'] = features_ln_numericas_modelo_l2.score(X_validacao_features_ln_numericas_normalizado,Y_validacao_features_ln_numericas_normalizado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7315b877",
   "metadata": {},
   "source": [
    "# Validação do moledo com features_numericas_sem_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3ee1fd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coediciente de determinação para as variáveis de validação\n",
    "score_df.at['Regressão Linear L2 Teste','Numéricas sem Outlier'] = features_numericas_sem_outlier_modelo_l2.score(features_numericas_sem_outlier_normalizadas,y_treinamento_normalizada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "16a871fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coediciente de determinação para as variáveis de validação\n",
    "score_df.at['Regressão Linear L2 Validação','Numéricas sem Outlier'] = features_numericas_sem_outlier_modelo_l2.score(X_validacao_features_numericas_sem_outlier_normalizado,Y_validacao_features_numericas_sem_outlier_normalizado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c56d19",
   "metadata": {},
   "source": [
    "# Validação do moledo com features_ln_numericas_sem_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6cf3e893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coediciente de determinação para as variáveis de treinamento\n",
    "score_df.at['Regressão Linear L2 Teste','Transformada ln sem Outlier'] = features_ln_numericas_sem_outlier_modelo_l2.score(features_ln_numericas_sem_outlier_normalizadas,y_treinamento_ln_normalizada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2fad3873",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Coediciente de determinação para as variáveis de validação\n",
    "score_df.at['Regressão Linear L2 Validação','Transformada ln sem Outlier'] = features_ln_numericas_sem_outlier_modelo_l2.score(X_validacao_features_ln_numericas_sem_outlier_normalizado,Y_validacao_features_ln_numericas_sem_outlier_normalizado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "872a5112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Numéricas</th>\n",
       "      <th>Tranformada ln</th>\n",
       "      <th>Numéricas sem Outlier</th>\n",
       "      <th>Transformada ln sem Outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Regressão Linear Teste</th>\n",
       "      <td>0.785633</td>\n",
       "      <td>0.843592</td>\n",
       "      <td>0.785633</td>\n",
       "      <td>0.833908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regressão Linear Validação</th>\n",
       "      <td>0.824103</td>\n",
       "      <td>0.833918</td>\n",
       "      <td>0.824103</td>\n",
       "      <td>0.838882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regressão Linear L1 Teste</th>\n",
       "      <td>0.785437</td>\n",
       "      <td>0.843588</td>\n",
       "      <td>0.785437</td>\n",
       "      <td>0.833747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regressão Linear L1 Validação</th>\n",
       "      <td>0.823026</td>\n",
       "      <td>0.833815</td>\n",
       "      <td>0.823026</td>\n",
       "      <td>0.83701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regressão Linear L2 Teste</th>\n",
       "      <td>0.785293</td>\n",
       "      <td>0.843509</td>\n",
       "      <td>0.785293</td>\n",
       "      <td>0.8339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regressão Linear L2 Validação</th>\n",
       "      <td>0.824468</td>\n",
       "      <td>0.833773</td>\n",
       "      <td>0.824468</td>\n",
       "      <td>0.838113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Numéricas Tranformada ln Numéricas sem Outlier  \\\n",
       "Regressão Linear Teste         0.785633       0.843592              0.785633   \n",
       "Regressão Linear Validação     0.824103       0.833918              0.824103   \n",
       "Regressão Linear L1 Teste      0.785437       0.843588              0.785437   \n",
       "Regressão Linear L1 Validação  0.823026       0.833815              0.823026   \n",
       "Regressão Linear L2 Teste      0.785293       0.843509              0.785293   \n",
       "Regressão Linear L2 Validação  0.824468       0.833773              0.824468   \n",
       "\n",
       "                              Transformada ln sem Outlier  \n",
       "Regressão Linear Teste                           0.833908  \n",
       "Regressão Linear Validação                       0.838882  \n",
       "Regressão Linear L1 Teste                        0.833747  \n",
       "Regressão Linear L1 Validação                     0.83701  \n",
       "Regressão Linear L2 Teste                          0.8339  \n",
       "Regressão Linear L2 Validação                    0.838113  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(score_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3736a09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
